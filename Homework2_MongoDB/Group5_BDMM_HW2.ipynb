{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\"><b>Homework 2: AirBnB Document Database</b></font>\n",
    "\n",
    "**Group number:** **`5`**\n",
    "\n",
    "**Group members:**\n",
    "\n",
    "<center>\n",
    "\n",
    "|STUDENT NAME|STUDENT NUMBER|\n",
    "|:---:|:---:|\n",
    "|Alexandre Gonçalves|20240738|\n",
    "|André Silvestre|20240502|\n",
    "|Filipa Pereira|20240509|\n",
    "|João Henriques|20240499|\n",
    "|Umeima Mahomed|20240543|\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "**The Homework 2 is comprised of two parts:**\n",
    "1. Data modelling (15 points - $37.5\\%$).\n",
    "2. Queries to database to answer the questions (25 points - $62.5\\%$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- AirBnB Logo  -->\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Airbnb_Logo_B%C3%A9lo.svg/1280px-Airbnb_Logo_B%C3%A9lo.svg.png\" style=\"height: 100px !important;\">\n",
    "    <br>\n",
    "    <!-- Style Text with same style as AirBnB -->\n",
    "    <span style=\"color: #FF5A5F !important; font-size: 30px !important; font-weight: bold !important;\">Document Database</span><span style=\"color: #484848 !important; font-size: 30px !important; font-weight: bold !important;\"> MongoDB - Group 5</span>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>1. Data Modelling</b></font>\n",
    "\n",
    "<font size=\"4\">Congratulations! You’ve been hired as part of the new Data Engineering and Management team in the AirBNB Business Intelligence department. The company is restructuring due to unsatisfactory performance from the previous teams.\n",
    "\n",
    "Before leaving, the head of the Data Modelling department highlighted several issues:\n",
    "\n",
    "**Data Storage**: A lot of data about AirBNB listings is stored in a single document. While this approach has some advantages, it has also caused performance issues. Queries are slow, and the team didn’t apply patterns, which could improve performance by optimizing the data model. Indexes were also not used.\n",
    "\n",
    "**Reviews Growth**: The number of reviews for AirBNB is growing rapidly. Currently, we overwrite reviews regularly, but the Business Intelligence department will benefit from storing all reviews and analyzing them over time.\n",
    "\n",
    "**Data Errors**: There are errors in the data collection, such as duplicate data entries and incorrect timestamps for transactions. The new team will need to decide how to fix these issues.\n",
    "\n",
    "**Your Role**: In your new role, you’ll need to consider how each database query is used, how often it is needed, and its impact on reads and writes. You should update the database schema to optimize for business use cases. Use tools like embedding, linking, indexes, and patterns to improve the data model. You may need to create new fields, documents, or collections. Be sure to document the pattern you’re applying and the reasons behind your decisions, especially when dealing with duplication and risks of outdated data.\n",
    "\n",
    "**Key tasks include**:\n",
    "\n",
    "1. Streamlining the data collection process.\n",
    "2. Cleaning up the data and optimizing what will be returned for each use case.\n",
    "3. Applying the correct patterns to speed up common queries.\n",
    "4. Ensuring departments get accurate and relevant information from the database.\n",
    "5. Sharing the updated data model schema with other departments.\n",
    "\n",
    "**Good Practices**: [Check Chapter 6, Mastering MongoDB]\n",
    "\n",
    "1. All newly created fields should have capitalized names.\n",
    "2. New queries should work with the most up-to-date database version. If you make multiple changes, all queries should still work after the final updates.\n",
    "3. For some queries, you may need to change the database schema.\n",
    "4. When you are applying specific patterns, like polymorphic, subset, or bucket, name them accordingly. \n",
    "5. Document each major transformation using this format:\n",
    "*“We applied {transformation name} because {reasoning behind it}. We expect {change/result} based on {observable measure, such as query speed, number of documents returned, index use, etc.}.”*\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleanup and Schema Adjustments:** [9 points in total]\n",
    "\n",
    "1) Before working on the queries below, review the data and adjust the schema based on the typical use case described.\n",
    "\n",
    "**Typical Use Case**: The most common use of the database is to show property listing information to customers. A query retrieves a listing document from the database. Currently, retrieving a listing takes too long. Decide what information should be included in a typical query and optimize the structure accordingly. For example, customers usually only need a sample of reviews, not all reviews (even though all reviews are stored). They also don’t need past transaction data. Update the document schema to fit this use case. This might involve creating new collections or documents.\n",
    "\n",
    "**Data Cleanup**: Review the data for any errors (such as transactions that don’t belong to the listing) or unnecessary duplication, and clean it up where needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>2. Uses for the database</b></font>\n",
    "\n",
    "<font size=\"4\">Different AirBNB departments require different analytics from our common database.\n",
    "Below are the specific questions from various departments: \n",
    "\n",
    "**Standard Difficulty Questions:** [2 points per question]\n",
    "\n",
    "2)\tOnce a month, we reward hosts with recognition. Select three superhosts with at least two listings that can accommodate more than four people.\n",
    "\n",
    "3)\tThe company considers inevsting into property to rent. Which bed type is most common in listings with a waterfront and a dishwasher in New York?\n",
    "\n",
    "4)\tWe're considering hiring someone to write reviews professionally. Who wrote the longest review in New York?\n",
    "\n",
    "5)\tTo assess the security of different areas, what is the biggest and smallest (price-security deposit) difference per number of visitors at a property?\n",
    "\n",
    "6)  Identify areas by whether they are typically used for short breaks, like weekend mini breaks, or whether they are more suitable for long trips. This information support targeted advertising of different customer types. It is not expected to change much over time so we won’t look to update it, we just require current view. What is the average duration of stay (in nights) per type of property per city (you can use the maximum_nights to measure length of stays)? For each property type return the city with the highest and lowest average value.\n",
    "\n",
    "**Advanced Difficulty Questions (Consider database optimization for these queries):** [3 points per question]\n",
    "\n",
    "7)\tWe are creating a new webpage for hosts when setting up their account. It will list suggested typical amenities. This data will need to be available every time a host registers a property but is not expected to change very much. The starting point for the list will be all unique amenities currently listed in properties (across all documents). Optimise the database for this use case and show how the data should be queried.\n",
    "\n",
    "8)\tWe plan to rtack our reviewers better. We want to create a webpage that shows the top 20 reviewers and the count of the number of reviews of each of these reviewers. This webpage should be kept up to date. It should also have a link to return the number of reviews for a given reviewer ID or Name (show how to query for number of reviews by ID or query quickly).\n",
    "\n",
    "9)\tFor each property we store review scores across different metrics (accuracy, check-in, cleanliness etc). We consider adding more metrics, although there is no clarity on what these will be. We want to be able to easily query the average score across all of these metrics, including any new metrics that might be added without changing the query. Adjust the data model so this can be done and show the query for an example property.\n",
    "\n",
    "10)\tWe aim to have better access to information about transaction, we wish to develop a search engine that can calculate the average value of transactions in a given period of time quickly for a given property.\n",
    "\n",
    "11)\tWe wish to have a summary webpage that displays information about our top destinations. This webpage should display for each of the top 10 cities some basic information about our operations in the area (number of properties by type for example, average price by type) but you can choose the metrics. For each of the top 10 cities it should also provide some basic information about the top 3 properties in each city (price, number of review, whatever you think useful) to show an example of the properties available in the area. We would like to keep this webpage up to date as information changes.\n",
    "\n",
    "**Database updates:** [2 points per question]\n",
    "\n",
    "After optimizing the database, show how to complete the following updates. You can create fictional data. Ensure that previous data does not become stale:\n",
    "\n",
    "12) Add a new property with a new host in one of the top 10 cities. The host selects the top 10 most common amenities to list.\n",
    "\n",
    "13) Add a new review from one of our top 20 reviewers for this new property.\n",
    "\n",
    "14) Add a new review metric called 'x_factor' with a score of 10. Show that the average score across all metrics is correctly calculated for this listing, using the previously developed query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### **Setup**\n",
    "\n",
    "1. run Jupyter \n",
    "2. run Docker\n",
    "3. create MongoDB container in Command Prompt: make sure you don't have 'leftover' container from previous runs\n",
    "\n",
    "        docker run --name mongodb -d -e MONGO_INITDB_ROOT_USERNAME=AzureDiamond -e MONGO_INITDB_ROOT_PASSWORD=hunter2 -p 27017:27017 mongo\n",
    "\n",
    "4. run Studio3T\n",
    "\n",
    "5. create New Connection OR reconnect to existing Connection:\n",
    "\n",
    "    5.A\tIn Studio3T create Connection:\n",
    "            a.\tPress Connection -> New Connection\n",
    "            b.\tInsert credentials into URI field: mongodb://AzureDiamond:hunter2@localhost:27017\n",
    "            c.\tPress Test Connection\n",
    "            d.\tAssign a name to the Connection (top empty line) -> Save\n",
    "            e.\tPress Connect\n",
    "            \n",
    "    5.B In Studio3T reconnect to Connection:\n",
    "            a. press Connect (top left corner)\n",
    "            b. choose MongoDB connection  -> press Connect (MongoDB container must be runnning by this time)\n",
    "            \n",
    "6.\tIn Studio3T import the Database:\n",
    "            a.\tPress Import\n",
    "            b.\tChoose BSON mongodump archive \n",
    "            c.\tFind your database path\n",
    "            d.\tSelect All file formats and choose the database file ‘sampledata.archive’\n",
    "            e.\tPress Run: be patient while the database loads\n",
    "            f.\tInspect the collections and documents\n",
    "\n",
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## **Important**\n",
    "\n",
    "**NOTE** To avoid confusion between the **`sample_airbnb`** dataset from class and the one from **HW2**, we rename this collection to **`listingsAndReviews_HW2`** in **Studio 3T**.\n",
    "\n",
    "\n",
    "Left Side Menu > Open the *sample_airbnb* database > Click on the collections (you should see **`(2)`**) > Right-click on the **`listingsAndReviews_HW2`** collection > Right-click > ***Rename Collection*** > **`listingsAndReviews_HW2`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T06:00:23.357459Z",
     "start_time": "2023-03-17T06:00:18.165529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database info: Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'sample_airbnb')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample_airbnb'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Connector\n",
    "\n",
    "# !pip install pymongo\n",
    "# or #!conda install -y pymongo\n",
    "\n",
    "import re                                       # Regular Expressions\n",
    "import time                                     # For calculating time of execution\n",
    "import json                                     # For JSON operations\n",
    "import numpy as np                              # For numerical operations\n",
    "import pandas as pd                             # For data manipulation\n",
    "pd.set_option('display.max_rows', None)         # Display all rows\n",
    "\n",
    "# Disable FutureWarning messages\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from tqdm import tqdm                           # Progress bar\n",
    "from pprint import pprint                       # Pretty print\n",
    "from datetime import datetime                   # Datetime operations\n",
    "\n",
    "# MongoDB\n",
    "import bson\n",
    "from bson.objectid import ObjectId\n",
    "from bson.decimal128 import Decimal128\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection\n",
    "user=\"AzureDiamond\"\n",
    "password=\"hunter2\"\n",
    "host=\"localhost\"\n",
    "port=\"27017\"\n",
    "protocol=\"mongodb\"\n",
    "client = MongoClient(f\"{protocol}://{user}:{password}@{host}:{port}\")\n",
    "\n",
    "# Database check\n",
    "db = client.sample_airbnb \n",
    "print(f\"Database info: {db}\\n\")\n",
    "db.name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Loading and Inspecting database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T22:26:35.207080Z",
     "start_time": "2023-03-16T22:26:34.475720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database contains 1 collections\n",
      "All collections: ['listingsAndReviews_HW2']\n",
      "Collection listingsAndReviews_HW2 contains 5555 documents\n"
     ]
    }
   ],
   "source": [
    "# Collections are inside our Database 'sample_analytics'\n",
    "\n",
    "collection_list = db.list_collection_names()\n",
    "\n",
    "print(f\"The database contains {len(collection_list)} collections\")\n",
    "print(f\"All collections: {collection_list[0:]}\")\n",
    "print(f\"Collection {collection_list[0]} contains {db[collection_list[0]].count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[PyMongo documentation](https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAverage document size:\u001b[0m 67.09 KB\n"
     ]
    }
   ],
   "source": [
    "# Estimate average document size\n",
    "cursor = db.listingsAndReviews_HW2.find()                   # Cursor to iterate over documents\n",
    "sizes = [len(bson.BSON.encode(doc)) for doc in cursor]      # Calculate size of each document\n",
    "avg_size_kb = sum(sizes) / len(sizes) / 1024                # Average size in KB\n",
    "print(f\"\\033[1mAverage document size:\\033[0m {avg_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **📚 Database Schema**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Data Cleanup and Schema Adjustments:** [9 points in total]\n",
    "\n",
    "# 1) Before working on the queries below, review the data and adjust the schema based on the typical use case described.\n",
    "\n",
    "# **Typical Use Case**: The most common use of the database is to show property listing information to customers. \n",
    "#                       A query retrieves a listing document from the database. Currently, retrieving a listing takes too long. \n",
    "#                       Decide what information should be included in a typical query and optimize the structure accordingly.  \n",
    "#                       For example, customers usually only need a sample of reviews, not all reviews (even though all reviews are stored). \n",
    "#                       They also don’t need past transaction data. \n",
    "#                       Update the document schema to fit this use case. \n",
    "#                       This might involve creating new collections or documents.\n",
    "\n",
    "# **Data Cleanup**: Review the data for any errors (such as transactions that don't belong to the listing) or unnecessary duplication, and clean it up where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In total, the first document contains 64 top-level fields\n"
     ]
    }
   ],
   "source": [
    "# Find one document in the collection 'listingsAndReviews'\n",
    "document = db.listingsAndReviews_HW2.find_one()\n",
    "# pprint(document)                                                                     # Large output, uncomment to see or open \"airbnb_document.json\" file\n",
    "print(f\"\\nIn total, the first document contains {len(document)} top-level fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA: Save the document to a JSON file (to see the structure more clearly)\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"\n",
    "    Converts non-serializable objects (like Decimal128 and datetime) to strings.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, Decimal128):\n",
    "        return str(obj)\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type '{obj.__class__.__name__}' is not JSON serializable\")\n",
    "\n",
    "def save_to_json_file(document, filename=\"airbnb_document.json\"):\n",
    "    \"\"\"\n",
    "    Saves a MongoDB document to a JSON file, handling non-serializable data types.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(document, f, ensure_ascii=False, indent=4, default=convert_to_serializable)\n",
    "        print(f\"Document saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to airbnb_document.json\n"
     ]
    }
   ],
   "source": [
    "# Save the document from 'listingsAndReviews_HW2' Collection to a JSON file\n",
    "save_to_json_file(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'reviews',\n",
      " 'reviews_copy1',\n",
      " 'reviews_copy2',\n",
      " 'reviews_copy3',\n",
      " 'reviews_copy4',\n",
      " 'reviews_per_month',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transit',\n",
      " 'weekly_price']\n",
      "\n",
      "In total, the collection contains 67 unique top-level fields\n"
     ]
    }
   ],
   "source": [
    "# Query to retrieve all fields names from the collection 'listingsAndReviews' (Using aggregation)\n",
    "# Define the aggregation pipeline\n",
    "pipeline = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},  # Convert document to key-value pairs          | Source: https://www.mongodb.com/docs/manual/reference/aggregation-variables/#mongodb-variable-variable.ROOT\n",
    "    {\"$unwind\": \"$fields\"},                                  # Flatten the fields array                     | Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}                         # Group by field names to get distinct fields  | Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "]\n",
    "\n",
    "# Execute the aggregation\n",
    "result = db.listingsAndReviews_HW2.aggregate(pipeline)\n",
    "\n",
    "# Extract distinct fields from the result\n",
    "fields = [doc[\"_id\"] for doc in result]\n",
    "\n",
    "# Print the list of unique fields\n",
    "pprint(sorted(fields))\n",
    "print(f\"\\nIn total, the collection contains {len(fields)} unique top-level fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code above just return the **\"top-level\" fields** of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'address.country',\n",
      " 'address.country_code',\n",
      " 'address.government_area',\n",
      " 'address.location',\n",
      " 'address.location.coordinates',\n",
      " 'address.location.is_location_exact',\n",
      " 'address.location.type',\n",
      " 'address.market',\n",
      " 'address.street',\n",
      " 'address.suburb',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'availability.availability_30',\n",
      " 'availability.availability_365',\n",
      " 'availability.availability_60',\n",
      " 'availability.availability_90',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'images.medium_url',\n",
      " 'images.picture_url',\n",
      " 'images.thumbnail_url',\n",
      " 'images.xl_picture_url',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'reviews',\n",
      " 'reviews._id',\n",
      " 'reviews.comments',\n",
      " 'reviews.date',\n",
      " 'reviews.listing_id',\n",
      " 'reviews.reviewer_id',\n",
      " 'reviews.reviewer_name',\n",
      " 'reviews_copy1',\n",
      " 'reviews_copy1._id',\n",
      " 'reviews_copy1.comments',\n",
      " 'reviews_copy1.date',\n",
      " 'reviews_copy1.listing_id',\n",
      " 'reviews_copy1.reviewer_id',\n",
      " 'reviews_copy1.reviewer_name',\n",
      " 'reviews_copy2',\n",
      " 'reviews_copy2._id',\n",
      " 'reviews_copy2.comments',\n",
      " 'reviews_copy2.date',\n",
      " 'reviews_copy2.listing_id',\n",
      " 'reviews_copy2.reviewer_id',\n",
      " 'reviews_copy2.reviewer_name',\n",
      " 'reviews_copy3',\n",
      " 'reviews_copy3._id',\n",
      " 'reviews_copy3.comments',\n",
      " 'reviews_copy3.date',\n",
      " 'reviews_copy3.listing_id',\n",
      " 'reviews_copy3.reviewer_id',\n",
      " 'reviews_copy3.reviewer_name',\n",
      " 'reviews_copy4',\n",
      " 'reviews_copy4._id',\n",
      " 'reviews_copy4.comments',\n",
      " 'reviews_copy4.date',\n",
      " 'reviews_copy4.listing_id',\n",
      " 'reviews_copy4.reviewer_id',\n",
      " 'reviews_copy4.reviewer_name',\n",
      " 'reviews_per_month',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transactions.bucket_end_date',\n",
      " 'transactions.bucket_start_date',\n",
      " 'transactions.transaction_count',\n",
      " 'transactions.transactions',\n",
      " 'transactions.transactions.date',\n",
      " 'transactions.transactions.price',\n",
      " 'transit',\n",
      " 'weekly_price']\n",
      "In total, there are \u001b[1m121 unique fields\u001b[0m in the collection 'listingsAndReviews_HW2'\n"
     ]
    }
   ],
   "source": [
    "# Function to recursively extract all fields from a document (nested dictionaries and lists)\n",
    "def extract_fields(obj, prefix=\"\"):\n",
    "    \"\"\"Recursively extract all fields from a document.\n",
    "\n",
    "    Args:\n",
    "        obj: The object to process (dict, list, or other type). \n",
    "        prefix (str, optional): String prefix for nested fields (e.g., \"address\" becomes \"address.country\"). Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        fields: A set of unique field names found in the document.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty set to store unique fields\n",
    "    fields = set()\n",
    "    \n",
    "    # Check if the object is a dictionary (e.g., a MongoDB document or subdocument)\n",
    "    if isinstance(obj, dict):\n",
    "        # Iterate over field:value pairs in the dictionary\n",
    "        for k, v in obj.items():\n",
    "            # Construct the full field name; no dot if prefix is empty, otherwise add dot separator\n",
    "            full_field = f\"{prefix}{k}\" if not prefix else f\"{prefix}.{k}\"\n",
    "            fields.add(full_field)                                                      # Add the full field to the set\n",
    "            fields.update(extract_fields(v, full_field))                                # Recursively extract fields from the value, using the current field as prefix\n",
    "            \n",
    "    # Check if the object is a list (e.g., an array like 'reviews' or 'amenities')\n",
    "    elif isinstance(obj, list):\n",
    "        # Iterate over each item in the list\n",
    "        for item in obj:\n",
    "            # Recursively extract fields from the item, keeping the same prefix\n",
    "            fields.update(extract_fields(item, prefix))\n",
    "            \n",
    "    return fields\n",
    "\n",
    "# Aggregate to get all documents and process them\n",
    "all_fields = set()\n",
    "for doc in db.listingsAndReviews_HW2.find():\n",
    "    doc_fields = extract_fields(doc)\n",
    "    all_fields.update(doc_fields)\n",
    "\n",
    "# Convert to sorted list for readability\n",
    "unique_fields = sorted(list(all_fields))\n",
    "\n",
    "# Print the list of unique fields\n",
    "pprint(unique_fields)\n",
    "print(f\"In total, there are \\033[1m{len(unique_fields)} unique fields\\033[0m in the collection 'listingsAndReviews_HW2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Initial Data Inspection and Findings**\n",
    "\n",
    "The initial inspection of a sample document and the extraction of all unique field paths (both top-level and nested) reveal a complex structure within the `listingsAndReviews_HW2` collection. We identified **121 unique field paths**, indicating potentially large documents and complexity.\n",
    "\n",
    "Key findings align with the issues mentioned in the homework brief:\n",
    "\n",
    "1.  **Embedded Data & Large Documents:** Significant data is embedded:\n",
    "    *   **Host Information:** Details like `host_name`, `host_about`, `host_location` are repeated for every listing by the same host.\n",
    "    *   **Reviews:** The `reviews` array (and redundant `reviews_copy*` fields) can be very large, directly contributing to the identified performance issues (slow queries) and violating MongoDB's recommendation against unbounded arrays. The average document size is initially ~67 KB, but listings with many reviews are likely much larger.\n",
    "    *   **Transactions:** Transaction data is also embedded within a subdocument.\n",
    "2.  **Redundancy:** The `reviews_copy1` through `reviews_copy4` fields are clear indicators of unnecessary data duplication, wasting storage and complicating updates.\n",
    "3.  **Potential Data Type Issues:** Initial inspection suggests potential inconsistencies (e.g., numbers stored as strings, inconsistent use of `Decimal128`).\n",
    "4.  **Lack of Indexing:** Only the default `_id` index exists, meaning queries filtering or sorting on other fields will require inefficient collection scans.\n",
    "\n",
    "These points confirm the need for schema refactoring to improve performance, scalability, and data integrity. We will address redundancy, data types, and then apply appropriate modeling patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 listings with the most reviews:\n",
      "[{'_id': '4069429', 'reviewCount': 533},\n",
      " {'_id': '12954762', 'reviewCount': 469},\n",
      " {'_id': '95560', 'reviewCount': 463},\n",
      " {'_id': '476983', 'reviewCount': 420},\n",
      " {'_id': '5283892', 'reviewCount': 408}]\n"
     ]
    }
   ],
   "source": [
    "# Count listings with large number of reviews\n",
    "results = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True}}},                                         # Filter documents with 'reviews' field\n",
    "    {\"$project\": {\"reviewCount\": {\"$size\": \"$reviews\"}}},                               # Project the size of 'reviews' array\n",
    "    {\"$sort\": {\"reviewCount\": -1}},                                                     # Sort by review count\n",
    "    {\"$limit\": 5}                                                                       # Limit to top 5\n",
    "])\n",
    "print(\"\\nTop 5 listings with the most reviews:\")\n",
    "pprint(list(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current indexes\n",
    "# Source: https://pymongo.readthedocs.io/en/stable/tutorial.html#indexing\n",
    "db.listingsAndReviews_HW2.index_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No fields indexed besides the key `_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **💬 1.1 | Confirm if All **`Reviews`** are in the same collection**\n",
    "\n",
    "We first address the obvious data redundancy issue. We suspect the `reviews_copy*` fields are duplicates of the main `reviews` array. We will verify this and then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing reviews per document: 5555it [00:02, 2132.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "{'execution_time_seconds': 2.7174055576324463,\n",
      " 'mismatches_found': 0,\n",
      " 'total_documents': 5555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify if all copies of reviews contain the same data as 'reviews'\n",
    "def compare_reviews_per_document(verbose=True):\n",
    "    \"\"\"\n",
    "    Compares the 'reviews' array with all 'reviews_copy*' arrays for each document in the collection.\n",
    "    Checks if 'reviews' contains all reviews from the copies (by content) on a per-document basis.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool): If True, prints detailed results for each document as they are processed.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary of the comparison, including counts of mismatches and execution time.\n",
    "\n",
    "    Notes:\n",
    "        - Dynamically detects all fields matching 'reviews_copy*' using $objectToArray.\n",
    "        - Compares full review content (e.g., _id, date, comments) using $setEquals.\n",
    "        - Retains counts for additional insight.\n",
    "        - Uses tqdm for progress tracking.\n",
    "\n",
    "    Sources:\n",
    "        - $group: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "        - $project: https://www.mongodb.com/docs/manual/reference/operator/aggregation/project/\n",
    "        - $unwind: https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/\n",
    "        - $objectToArray: https://www.mongodb.com/docs/manual/reference/operator/aggregation/objectToArray/\n",
    "        - $setEquals: https://www.mongodb.com/docs/manual/reference/operator/aggregation/setEquals/\n",
    "        - $filter: https://www.mongodb.com/docs/manual/reference/operator/aggregation/filter/\n",
    "        - $map: https://www.mongodb.com/docs/manual/reference/operator/aggregation/map/\n",
    "        - $reduce: https://www.mongodb.com/docs/manual/reference/operator/aggregation/reduce/\n",
    "        - $concatArrays: https://www.mongodb.com/docs/manual/reference/operator/aggregation/concatArrays/\n",
    "        - $regexMatch: https://www.mongodb.com/docs/manual/reference/operator/aggregation/regexMatch/\n",
    "        - $size: https://www.mongodb.com/docs/manual/reference/operator/aggregation/size/\n",
    "        - $ifNull: https://www.mongodb.com/docs/manual/reference/operator/aggregation/ifNull/\n",
    "    \"\"\"\n",
    "    # Start timing the entire process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Count total documents for tqdm progress bar\n",
    "    total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "    # Pipeline to process each document individually\n",
    "    pipeline = [\n",
    "        \n",
    "        # Step 1: Group by _id to process each document separately\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$_id\",\n",
    "            \"all_fields\": {\"$first\": \"$$ROOT\"}  # Keep the entire document\n",
    "        }},\n",
    "        \n",
    "        # Step 2: Convert document fields to an array to find reviews_copy* dynamically\n",
    "        {\"$project\": {\n",
    "            \"_id\": 1,\n",
    "            \"reviews\": {\"$ifNull\": [\"$all_fields.reviews\", []]},\n",
    "            \"copy_fields\": {\n",
    "                \"$filter\": {                                                       # Filter fields that start with 'reviews_copy'\n",
    "                    \"input\": {\"$objectToArray\": \"$all_fields\"},\n",
    "                    \"cond\": {\"$regexMatch\": {\"input\": \"$$this.k\", \"regex\": \"^reviews_copy\"}}\n",
    "                }\n",
    "            }\n",
    "        }},\n",
    "        \n",
    "        # Step 3: Extract and compare content\n",
    "        {\"$project\": {\n",
    "            \"reviews_content\": \"$reviews\",                                          # Full content of reviews\n",
    "            \"copy_contents\": {\n",
    "                \"$map\": {                                                           # Extract the value (array) from each reviews_copy* field\n",
    "                    \"input\": \"$copy_fields\", \"in\": {\"$ifNull\": [\"$$this.v\", []]}\n",
    "                }\n",
    "            },\n",
    "            \"reviews_count\": {\"$size\": {\"$ifNull\": [\"$reviews\", []]}},\n",
    "            \"copy_counts\": {\n",
    "                \"$map\": {                                                           # Count reviews in each copy\n",
    "                    \"input\": \"$copy_fields\",\n",
    "                    \"in\": {\"name\": \"$$this.k\", \"count\": {\"$size\": {\"$ifNull\": [\"$$this.v\", []]}}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }},\n",
    "        \n",
    "        # Step 4: Compare content and check containment \n",
    "        {\"$project\": {\n",
    "            \"all_copies_match_reviews\": {\n",
    "                \"$reduce\": {                                                         # Iterate over all copy arrays to compare with reviews\n",
    "                    \"input\": \"$copy_contents\",\n",
    "                    \"initialValue\": True,\n",
    "                    \"in\": {\n",
    "                        \"$and\": [\n",
    "                            \"$$value\",                                               # Previous comparison result\n",
    "                            {\"$setEquals\": [                                         # Compare full content\n",
    "                                \"$reviews_content\",\n",
    "                                {\"$concatArrays\": [\"$reviews_content\", \"$$this\"]}\n",
    "                            ]}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"reviews_count\": 1,                                                     # Return/Project counts for additional insight\n",
    "            \"copy_counts\": 1\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    # Execute pipeline and iterate with tqdm\n",
    "    mismatches = 0                                              # Initialize mismatch counter\n",
    "    cursor = db.listingsAndReviews_HW2.aggregate(pipeline)      # Execute the aggregation pipeline\n",
    "\n",
    "    for doc in tqdm(cursor, desc=\"Comparing reviews per document\"):\n",
    "        doc_id = doc[\"_id\"]\n",
    "        all_match = doc[\"all_copies_match_reviews\"]\n",
    "        reviews_count = doc[\"reviews_count\"]\n",
    "        copy_counts = {item[\"name\"]: item[\"count\"] for item in doc[\"copy_counts\"]}\n",
    "\n",
    "        if not all_match:\n",
    "            mismatches += 1\n",
    "            if verbose:\n",
    "                print(f\"\\nMismatch found in document _id: {doc_id}\")\n",
    "                print(f\"Review counts - reviews: {reviews_count}, copies: {copy_counts}\")\n",
    "                print(\"Content in 'reviews' does not fully match all 'reviews_copy*' arrays.\")\n",
    "        elif verbose:\n",
    "            print(f\"\\nDocument _id: {doc_id} - All 'reviews_copy*' arrays match 'reviews'.\")\n",
    "            print(f\"Review counts - reviews: {reviews_count}, copies: {copy_counts}\")\n",
    "\n",
    "\n",
    "    # Calculate total execution time\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    # Summary of results\n",
    "    summary = {\n",
    "        \"total_documents\": total_docs,\n",
    "        \"mismatches_found\": mismatches,\n",
    "        \"execution_time_seconds\": execution_time\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Run the function\n",
    "result = compare_reviews_per_document(verbose=False)\n",
    "print(\"\\nSummary:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Result:** The query confirms that for all documents, the content within `reviews_copy*` arrays is identical to the main `reviews` array. This confirms they are redundant.\n",
    "    - **Action:** We will remove the `reviews_copy*` fields from all documents in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents matched: 5555\n",
      "Number of documents modified (fields eliminated): 5555\n",
      "Fields deleted: ['reviews_copy1', 'reviews_copy2', 'reviews_copy3', 'reviews_copy4']\n",
      "Execution time: 0.764 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1.1.1. Delete all 'reviews_copy*' fields from the collection 'listingsAndReviews_HW2'\n",
    "\n",
    "# MongoDB update operation to remove specific 'reviews_copy*' fields\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/method/db.collection.updateMany/\n",
    "\n",
    "# Update operation to unset the specified fields\n",
    "start_time = time.time()                                    # Record start time\n",
    "update_result = db.listingsAndReviews_HW2.update_many(\n",
    "    filter={},                                              # Apply to all documents\n",
    "    update={\"$unset\": {                                     # Unset the specified fields\n",
    "        \"reviews_copy1\": \"\",\n",
    "        \"reviews_copy2\": \"\",\n",
    "        \"reviews_copy3\": \"\",\n",
    "        \"reviews_copy4\": \"\"\n",
    "    }}\n",
    ")\n",
    "execution_time = time.time() - start_time                   # Calculate execution time\n",
    "\n",
    "# Print the update result\n",
    "print(f\"Number of documents matched: {update_result.matched_count}\")\n",
    "print(f\"Number of documents modified (fields eliminated): {update_result.modified_count}\")\n",
    "print(f\"Fields deleted: ['reviews_copy1', 'reviews_copy2', 'reviews_copy3', 'reviews_copy4']\")\n",
    "print(f\"Execution time: {execution_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied **data cleanup by removing redundant fields** (`reviews_copy1` to `reviews_copy4`) because the verification query confirmed they contained identical data to the `reviews` field, leading to unnecessary storage consumption and potential update anomalies. We expect a **reduction in the total collection size and average document size**, leading to **faster reads and writes** when accessing listing documents, as less data needs to be processed or transferred.\n",
    "\n",
    "- The successful removal of these fields is confirmed by the verification query showing **0 documents containing them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with any 'reviews_copy1-4' fields remaining: 0\n",
      "Success: All specified 'reviews_copy*' fields were eliminated.\n"
     ]
    }
   ],
   "source": [
    "# Check to confirm removal\n",
    "remaining = db.listingsAndReviews_HW2.count_documents({\n",
    "    \"$or\": [\n",
    "        {\"reviews_copy1\": {\"$exists\": True}},\n",
    "        {\"reviews_copy2\": {\"$exists\": True}},\n",
    "        {\"reviews_copy3\": {\"$exists\": True}},\n",
    "        {\"reviews_copy4\": {\"$exists\": True}}\n",
    "    ]\n",
    "})\n",
    "print(f\"Documents with any 'reviews_copy1-4' fields remaining: {remaining}\")\n",
    "if remaining == 0:\n",
    "    print(\"Success: All specified 'reviews_copy*' fields were eliminated.\")\n",
    "else:\n",
    "    print(\"Warning: Some 'reviews_copy1-4' fields may still exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **🔢🔠 1.2 | Inconsistent Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'access', 'accommodates', 'address', 'address.country', 'address.country_code', 'address.government_area', 'address.location', 'address.location.coordinates', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb', 'amenities', 'availability', 'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90', 'bathrooms', 'bed_type', 'bedrooms', 'beds', 'calendar_last_scraped', 'cancellation_policy', 'cleaning_fee', 'description', 'extra_people', 'first_review', 'guests_included', 'host_about', 'host_has_profile_pic', 'host_id', 'host_identity_verified', 'host_is_superhost', 'host_listings_count', 'host_location', 'host_name', 'host_neighbourhood', 'host_picture_url', 'host_response_rate', 'host_response_time', 'host_thumbnail_url', 'host_total_listings_count', 'host_url', 'host_verifications', 'house_rules', 'images', 'images.medium_url', 'images.picture_url', 'images.thumbnail_url', 'images.xl_picture_url', 'interaction', 'last_review', 'last_scraped', 'listing_url', 'maximum_nights', 'minimum_nights', 'monthly_price', 'name', 'neighborhood_overview', 'notes', 'number_of_reviews', 'price', 'property_type', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value', 'reviews', 'reviews._id', 'reviews.comments', 'reviews.date', 'reviews.listing_id', 'reviews.reviewer_id', 'reviews.reviewer_name', 'reviews_per_month', 'room_type', 'security_deposit', 'space', 'summary', 'transactions', 'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count', 'transactions.transactions', 'transactions.transactions.date', 'transactions.transactions.price', 'transit', 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "# Check data types of all fields in the collection 'listingsAndReviews_HW2'\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Extract all top-level fields and their data types (reuse the 'extract_fields' function)\n",
    "\n",
    "# Aggregate to get all documents and process them\n",
    "all_fields = set()\n",
    "for doc in db.listingsAndReviews_HW2.find():\n",
    "    doc_fields = extract_fields(doc)\n",
    "    all_fields.update(doc_fields)\n",
    "\n",
    "# Convert to sorted list for readability\n",
    "unique_fields = sorted(list(all_fields))\n",
    "print(unique_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing types across \u001b[1m5555\u001b[0m documents...\n",
      "Found \u001b[1m93 unique field paths\u001b[0m. DataFrame created with data types.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatypes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.coordinates</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_end_date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_start_date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transaction_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     datatypes\n",
       "field                                         \n",
       "_id                                        str\n",
       "access                                     str\n",
       "accommodates                               int\n",
       "address                                   dict\n",
       "address.country                            str\n",
       "address.country_code                       str\n",
       "address.government_area                    str\n",
       "address.location                          dict\n",
       "address.location.coordinates              list\n",
       "address.location.is_location_exact        bool\n",
       "address.location.type                      str\n",
       "address.market                             str\n",
       "address.street                             str\n",
       "address.suburb                             str\n",
       "amenities                                 list\n",
       "availability                              dict\n",
       "availability.availability_30               int\n",
       "availability.availability_365              int\n",
       "availability.availability_60               int\n",
       "availability.availability_90               int\n",
       "bathrooms                           Decimal128\n",
       "bed_type                                   str\n",
       "bedrooms                                   int\n",
       "beds                                       int\n",
       "calendar_last_scraped                 datetime\n",
       "cancellation_policy                        str\n",
       "cleaning_fee                        Decimal128\n",
       "description                                str\n",
       "extra_people                        Decimal128\n",
       "first_review                          datetime\n",
       "guests_included                     Decimal128\n",
       "host_about                                 str\n",
       "host_has_profile_pic                      bool\n",
       "host_id                                    str\n",
       "host_identity_verified                    bool\n",
       "host_is_superhost                         bool\n",
       "host_listings_count                        int\n",
       "host_location                              str\n",
       "host_name                                  str\n",
       "host_neighbourhood                         str\n",
       "host_picture_url                           str\n",
       "host_response_rate                         int\n",
       "host_response_time                         str\n",
       "host_thumbnail_url                         str\n",
       "host_total_listings_count                  int\n",
       "host_url                                   str\n",
       "host_verifications                        list\n",
       "house_rules                                str\n",
       "images                                    dict\n",
       "images.medium_url                          str\n",
       "images.picture_url                         str\n",
       "images.thumbnail_url                       str\n",
       "images.xl_picture_url                      str\n",
       "interaction                                str\n",
       "last_review                           datetime\n",
       "last_scraped                          datetime\n",
       "listing_url                                str\n",
       "maximum_nights                             str\n",
       "minimum_nights                             str\n",
       "monthly_price                       Decimal128\n",
       "name                                       str\n",
       "neighborhood_overview                      str\n",
       "notes                                      str\n",
       "number_of_reviews                          int\n",
       "price                               Decimal128\n",
       "property_type                              str\n",
       "review_scores_checkin                      int\n",
       "review_scores_cleanliness                  int\n",
       "review_scores_communication                int\n",
       "review_scores_location                     int\n",
       "review_scores_rating                       int\n",
       "review_scores_value                        int\n",
       "reviews                                   list\n",
       "reviews._id                                str\n",
       "reviews.comments                           str\n",
       "reviews.date                          datetime\n",
       "reviews.listing_id                         str\n",
       "reviews.reviewer_id                        str\n",
       "reviews.reviewer_name                      str\n",
       "reviews_per_month                          int\n",
       "room_type                                  str\n",
       "security_deposit                    Decimal128\n",
       "space                                      str\n",
       "summary                                    str\n",
       "transactions                              dict\n",
       "transactions.bucket_end_date          datetime\n",
       "transactions.bucket_start_date        datetime\n",
       "transactions.transaction_count             int\n",
       "transactions.transactions                 list\n",
       "transactions.transactions.date        datetime\n",
       "transactions.transactions.price            str\n",
       "transit                                    str\n",
       "weekly_price                        Decimal128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Function to Recursively Extract Paths and Types ---\n",
    "# Source: X. (2025). Grok 3 Beta — The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "#         Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_paths_and_types_simple(data, prefix=\"\", path_types_dict=None):\n",
    "    \"\"\"\n",
    "    Recursively finds all field paths and their Python types in a document.\n",
    "    \"\"\"\n",
    "    if path_types_dict is None:\n",
    "        path_types_dict = defaultdict(set)\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Handle dictionary (subdocument)\n",
    "        for key, value in data.items():\n",
    "            current_path = f\"{prefix}.{key}\" if prefix else key\n",
    "            # Add the Python type name to the set for this path\n",
    "            path_types_dict[current_path].add(type(value).__name__)\n",
    "            # Recurse if the value is complex (dict or list)\n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_paths_and_types_simple(value, current_path, path_types_dict)\n",
    "                \n",
    "    elif isinstance(data, list):\n",
    "        # Handle list (array)\n",
    "        # Indicate the path exists and contains a list\n",
    "        path_types_dict[prefix].add('list') # Add 'list' type for the path itself\n",
    "        # Recurse into list elements if they are complex\n",
    "        for item in data:\n",
    "            if isinstance(item, (dict, list)):\n",
    "                # Pass the array's prefix to find types *within* its elements\n",
    "                get_paths_and_types_simple(item, prefix, path_types_dict)\n",
    "\n",
    "# --- Process All Documents ---\n",
    "all_field_types_summary = defaultdict(set)\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "print(f\"Analyzing types across \\033[1m{total_docs}\\033[0m documents...\")\n",
    "\n",
    "# Using find() iterates through documents directly\n",
    "# Add tqdm progress bar if desired: from tqdm import tqdm\n",
    "# for document in tqdm(db.listingsAndReviews_HW2.find(), total=total_docs, desc=\"Analyzing docs\"):\n",
    "for document in db.listingsAndReviews_HW2.find():\n",
    "    get_paths_and_types_simple(document, path_types_dict=all_field_types_summary)\n",
    "\n",
    "# --- Create DataFrame ---\n",
    "df_data_list_simple = []\n",
    "\n",
    "# Sort fields alphabetically for consistent output\n",
    "for field in sorted(all_field_types_summary.keys()):\n",
    "    # Join multiple types found for a field into a single string\n",
    "    type_str = \", \".join(sorted(list(all_field_types_summary[field])))\n",
    "    df_data_list_simple.append({\"field\": field, \"datatypes\": type_str})\n",
    "\n",
    "df_types_simple = pd.DataFrame(df_data_list_simple)\n",
    "df_types_simple.set_index(\"field\", inplace=True)\n",
    "print(f\"Found \\033[1m{len(df_types_simple)} unique field paths\\033[0m. DataFrame created with data types.\\n\")\n",
    "df_types_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data Types Adjustments**\n",
    "\n",
    "Based on the data inspection (**code above** and **Studio3T**), we will make the following adjustments to ensure data consistency and improve query performance:\n",
    "\n",
    "- **`maximum_nights`** and **`minimum_nights`**: Convert from `string` to `int` if they represent numerical values.\n",
    "- **`bathrooms`**: Ensure it is consistently typed as `int`.\n",
    "- **`accommodates`**: Ensure it is consistently typed as `int`.\n",
    "- **`price`**, **`security_deposit`**, **`cleaning_fee`**, **`extra_people`**, **`guests_included`**, **`weekly_price`**, **`monthly_price`**: Ensure these are consistently typed as `decimal`.\n",
    "- **`transactions.transactions.price`**: Convert from `string` to `decimal`.\n",
    "- **`transit`**: If it always contains multiple values that can be separated by a delimiter, we can split it into an array of strings for easier querying.\n",
    "\n",
    ".\n",
    "\n",
    "- **`reviews._id`**, **`reviews.listing_id`**, **`reviews.reviewer_id`**: Ensure these are consistently typed as `ObjectId`.\n",
    "- **`address.location.coordinates`**: Confirm `array`, subfields `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1.2. Convert all fields to the correct data types in the collection 'listingsAndReviews_HW2'\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/convert/\n",
    "#         https://stackoverflow.com/a/56570099\n",
    "\n",
    "# Convert 'maximum_nights' and 'minimum_nights' to int\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},                                                                                         # Update all documents\n",
    "    [{\"$set\": {\"maximum_nights\": { \"$convert\": { \"input\": \"$maximum_nights\", \"to\": \"int\" } }}},\n",
    "     {\"$set\": {\"minimum_nights\": { \"$convert\": { \"input\": \"$minimum_nights\", \"to\": \"int\" } }}}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minimum_nights': 2, 'maximum_nights': 30}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"maximum_nights\": 1, \"minimum_nights\": 1}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None,\n",
      "  'bathrooms': [Decimal128('4.5'),\n",
      "                Decimal128('5.0'),\n",
      "                Decimal128('3.0'),\n",
      "                Decimal128('9.0'),\n",
      "                Decimal128('4.0'),\n",
      "                Decimal128('0.5'),\n",
      "                Decimal128('1.5'),\n",
      "                Decimal128('5.5'),\n",
      "                Decimal128('3.5'),\n",
      "                Decimal128('6.0'),\n",
      "                Decimal128('0.0'),\n",
      "                Decimal128('8.0'),\n",
      "                Decimal128('2.0'),\n",
      "                Decimal128('7.0'),\n",
      "                Decimal128('1.0'),\n",
      "                Decimal128('16.0'),\n",
      "                Decimal128('2.5')]}]\n"
     ]
    }
   ],
   "source": [
    "# Check if all 'bathrooms' are integers\n",
    "bathrooms_all = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    # Return all 'bathrooms' values\n",
    "    {\"$group\": {\"_id\": None, \"bathrooms\": {\"$addToSet\": \"$bathrooms\"}}}\n",
    "]))\n",
    "\n",
    "# Extract the result\n",
    "pprint(bathrooms_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `bathrooms` field contains `Decimal128` values, including halves (e.g., $0.5$, $1.5$, $2.5$). \n",
    "    - According to Airbnb's help center and community discussions (e.g, https://community.withairbnb.com/t5/Advice-on-your-space/How-to-calculate-Bathrooms/td-p/1437848), a value of $0.5$ typically represents a half-bath (toilet only, no shower/bath).\n",
    "\n",
    "- **Decision:** We will **keep `bathrooms` as `Decimal128`** as the fractional values hold specific meaning within the Airbnb context and represent valid data points. We will not convert it to `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None,\n",
      "  'extra_people': [Decimal128('968.00'),\n",
      "                   Decimal128('4.00'),\n",
      "                   Decimal128('35.00'),\n",
      "                   Decimal128('314.00'),\n",
      "                   Decimal128('97.00'),\n",
      "                   Decimal128('66.00'),\n",
      "                   Decimal128('500.00'),\n",
      "                   Decimal128('49.00'),\n",
      "                   Decimal128('18.00'),\n",
      "                   Decimal128('80.00'),\n",
      "                   Decimal128('100.00'),\n",
      "                   Decimal128('7.00'),\n",
      "                   Decimal128('255.00'),\n",
      "                   Decimal128('131.00'),\n",
      "                   Decimal128('83.00'),\n",
      "                   Decimal128('393.00'),\n",
      "                   Decimal128('52.00'),\n",
      "                   Decimal128('300.00'),\n",
      "                   Decimal128('900.00'),\n",
      "                   Decimal128('542.00'),\n",
      "                   Decimal128('145.00'),\n",
      "                   Decimal128('21.00'),\n",
      "                   Decimal128('277.00'),\n",
      "                   Decimal128('29.00'),\n",
      "                   Decimal128('60.00'),\n",
      "                   Decimal128('198.00'),\n",
      "                   Decimal128('2346.00'),\n",
      "                   Decimal128('12.00'),\n",
      "                   Decimal128('105.00'),\n",
      "                   Decimal128('187.00'),\n",
      "                   Decimal128('280.00'),\n",
      "                   Decimal128('32.00'),\n",
      "                   Decimal128('125.00'),\n",
      "                   Decimal128('63.00'),\n",
      "                   Decimal128('590.00'),\n",
      "                   Decimal128('170.00'),\n",
      "                   Decimal128('15.00'),\n",
      "                   Decimal128('77.00'),\n",
      "                   Decimal128('46.00'),\n",
      "                   Decimal128('264.00'),\n",
      "                   Decimal128('30.00'),\n",
      "                   Decimal128('560.00'),\n",
      "                   Decimal128('140.00'),\n",
      "                   Decimal128('44.00'),\n",
      "                   Decimal128('13.00'),\n",
      "                   Decimal128('112.00'),\n",
      "                   Decimal128('16.00'),\n",
      "                   Decimal128('157.00'),\n",
      "                   Decimal128('95.00'),\n",
      "                   Decimal128('250.00'),\n",
      "                   Decimal128('72.00'),\n",
      "                   Decimal128('134.00'),\n",
      "                   Decimal128('506.00'),\n",
      "                   Decimal128('24.00'),\n",
      "                   Decimal128('55.00'),\n",
      "                   Decimal128('179.00'),\n",
      "                   Decimal128('117.00'),\n",
      "                   Decimal128('27.00'),\n",
      "                   Decimal128('75.00'),\n",
      "                   Decimal128('230.00'),\n",
      "                   Decimal128('199.00'),\n",
      "                   Decimal128('10.00'),\n",
      "                   Decimal128('120.00'),\n",
      "                   Decimal128('89.00'),\n",
      "                   Decimal128('58.00'),\n",
      "                   Decimal128('11.00'),\n",
      "                   Decimal128('42.00'),\n",
      "                   Decimal128('73.00'),\n",
      "                   Decimal128('25.00'),\n",
      "                   Decimal128('149.00'),\n",
      "                   Decimal128('87.00'),\n",
      "                   Decimal128('600.00'),\n",
      "                   Decimal128('118.00'),\n",
      "                   Decimal128('45.00'),\n",
      "                   Decimal128('14.00'),\n",
      "                   Decimal128('200.00'),\n",
      "                   Decimal128('107.00'),\n",
      "                   Decimal128('76.00'),\n",
      "                   Decimal128('28.00'),\n",
      "                   Decimal128('59.00'),\n",
      "                   Decimal128('90.00'),\n",
      "                   Decimal128('1119.00'),\n",
      "                   Decimal128('270.00'),\n",
      "                   Decimal128('5.00'),\n",
      "                   Decimal128('36.00'),\n",
      "                   Decimal128('98.00'),\n",
      "                   Decimal128('208.00'),\n",
      "                   Decimal128('1000.00'),\n",
      "                   Decimal128('19.00'),\n",
      "                   Decimal128('50.00'),\n",
      "                   Decimal128('160.00'),\n",
      "                   Decimal128('8.00'),\n",
      "                   Decimal128('39.00'),\n",
      "                   Decimal128('70.00'),\n",
      "                   Decimal128('101.00'),\n",
      "                   Decimal128('211.00'),\n",
      "                   Decimal128('180.00'),\n",
      "                   Decimal128('132.00'),\n",
      "                   Decimal128('22.00'),\n",
      "                   Decimal128('84.00'),\n",
      "                   Decimal128('53.00'),\n",
      "                   Decimal128('769.00'),\n",
      "                   Decimal128('800.00'),\n",
      "                   Decimal128('85.00'),\n",
      "                   Decimal128('350.00'),\n",
      "                   Decimal128('240.00'),\n",
      "                   Decimal128('54.00'),\n",
      "                   Decimal128('23.00'),\n",
      "                   Decimal128('130.00'),\n",
      "                   Decimal128('68.00'),\n",
      "                   Decimal128('223.00'),\n",
      "                   Decimal128('37.00'),\n",
      "                   Decimal128('550.00'),\n",
      "                   Decimal128('6.00'),\n",
      "                   Decimal128('150.00'),\n",
      "                   Decimal128('119.00'),\n",
      "                   Decimal128('26.00'),\n",
      "                   Decimal128('102.00'),\n",
      "                   Decimal128('9.00'),\n",
      "                   Decimal128('40.00'),\n",
      "                   Decimal128('79.00'),\n",
      "                   Decimal128('48.00'),\n",
      "                   Decimal128('110.00'),\n",
      "                   Decimal128('584.00'),\n",
      "                   Decimal128('530.00'),\n",
      "                   Decimal128('17.00'),\n",
      "                   Decimal128('31.00'),\n",
      "                   Decimal128('93.00'),\n",
      "                   Decimal128('186.00'),\n",
      "                   Decimal128('0.00'),\n",
      "                   Decimal128('175.00'),\n",
      "                   Decimal128('20.00'),\n",
      "                   Decimal128('34.00'),\n",
      "                   Decimal128('65.00'),\n",
      "                   Decimal128('220.00'),\n",
      "                   Decimal128('158.00'),\n",
      "                   Decimal128('127.00'),\n",
      "                   Decimal128('392.00')],\n",
      "  'guests_included': [Decimal128('8'),\n",
      "                      Decimal128('6'),\n",
      "                      Decimal128('5'),\n",
      "                      Decimal128('2'),\n",
      "                      Decimal128('1'),\n",
      "                      Decimal128('4'),\n",
      "                      Decimal128('7'),\n",
      "                      Decimal128('12'),\n",
      "                      Decimal128('9'),\n",
      "                      Decimal128('10'),\n",
      "                      Decimal128('13'),\n",
      "                      Decimal128('15'),\n",
      "                      Decimal128('16'),\n",
      "                      Decimal128('3')]}]\n"
     ]
    }
   ],
   "source": [
    "# Check if all 'guests_included' and 'extra_people' are integers\n",
    "guests_extra_all = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    # Return all 'guests_included' and 'extra_people' values\n",
    "    {\"$group\": {\"_id\": None, \"guests_included\": {\"$addToSet\": \"$guests_included\"}, \"extra_people\": {\"$addToSet\": \"$extra_people\"}}}\n",
    "]))\n",
    "pprint(guests_extra_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'guests_included' and 'extra_people' to int (since they are all integers but in wrong format - Decimal128)\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},                                                                                         # Update all documents\n",
    "    [{\"$set\": {\"guests_included\": { \"$convert\": { \"input\": \"$guests_included\", \"to\": \"int\" } }}},\n",
    "    #  {\"$set\": {\"extra_people\": { \"$convert\": { \"input\": \"$extra_people\", \"to\": \"int\" } }}}    # If u want to convert 'extra_people' as well\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `guests_included` field represents the number of guests included in the base price, which should logically be an integer. The `extra_people` field represents the *monetary charge* for additional guests, making `Decimal128` the appropriate type to handle currency values precisely.\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data type conversion** to the `guests_included` field, changing it from `Decimal128` to `int`, because it represents a count of people, which is inherently an integer. We expect **improved type consistency and potentially slightly more efficient storage and querying** for this field. \n",
    "    - The `extra_people` field remains `Decimal128` as it can represents a monetary value, although in the observations in this database they are coincidentally all integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 2084 documents have 'security_deposit' not as decimal.\n",
      "Warning: 1531 documents have 'cleaning_fee' not as decimal.\n",
      "Warning: 4841 documents have 'weekly_price' not as decimal.\n",
      "Warning: 4899 documents have 'monthly_price' not as decimal.\n"
     ]
    }
   ],
   "source": [
    "# Confirm price-related fields are decimal\n",
    "price_fields = [\"price\", \"security_deposit\", \"cleaning_fee\", \"weekly_price\", \"monthly_price\"]\n",
    "for field in price_fields:\n",
    "    non_decimal = db.listingsAndReviews_HW2.count_documents({field: {\"$not\": {\"$type\": \"decimal\"}}})\n",
    "    if non_decimal > 0:\n",
    "        print(f\"Warning: {non_decimal} documents have '{field}' not as decimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price': Decimal128('80.00'),\n",
       " 'security_deposit': Decimal128('200.00'),\n",
       " 'cleaning_fee': Decimal128('35.00'),\n",
       " 'weekly_price': None,\n",
       " 'monthly_price': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert price-related fields to decimal\n",
    "for field in price_fields:\n",
    "    db.listingsAndReviews_HW2.update_many(\n",
    "        {},                                                                                     # Update all documents\n",
    "        [{\"$set\": {field: { \"$convert\": { \"input\": f\"${field}\", \"to\": \"decimal\" } }}}]\n",
    "    )\n",
    "    \n",
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"price\": 1, \"security_deposit\": 1, \"cleaning_fee\": 1, \"weekly_price\": 1, \"monthly_price\": 1}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We applied **data type conversion** to the price-related fields (`price`, `security_deposit`, `cleaning_fee`, `weekly_price`, `monthly_price`), ensuring they are consistently stored as `Decimal128` (or `double`), because these represent monetary values. Handling `null` or missing values appropriately during conversion (e.g., defaulting to `null` or `0.0` if applicable) ensures accurate financial calculations. We expect **improved query performance for range/comparison queries on prices and reliable aggregation results (like averages)**.\n",
    "\n",
    "**Note:** `weekly_price` and `monthly_price` often appear as `None` after conversion, indicating they were originally missing or `null`, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transactions': {'transactions': [{'date': datetime.datetime(2008, 8, 12, 0, 0),\n",
       "    'price': Decimal128('132.1063781684291313922585686668753')}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'transactions.transactions.price' to decimal\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},\n",
    "    [{\"$set\": {\n",
    "        # Update the 'transactions.transactions.price' field\n",
    "        \"transactions.transactions\": {\n",
    "            # Check if 'transactions.transactions' is an array\n",
    "            \"$cond\": {\n",
    "                # If it is an array, convert the 'price' field to decimal\n",
    "                \"if\": {\"$isArray\": \"$transactions.transactions\"},\n",
    "                \"then\": {\n",
    "                    # Map over the array and convert the 'price' field to decimal\n",
    "                    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/map/\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$transactions.transactions\",\n",
    "                        \"as\": \"t\",\n",
    "                        \"in\": {\n",
    "                            \"date\": \"$$t.date\",\n",
    "                            \"price\": {\"$convert\": {\"input\": \"$$t.price\", \"to\": \"decimal\"}}\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                # If not an array, set to empty array\n",
    "                \"else\": []\n",
    "            }\n",
    "        }}}])\n",
    "\n",
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"transactions.transactions\": {\"$slice\": [\"$transactions.transactions\", 1]}}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We applied **data type conversion** within the nested `transactions.transactions` array, converting the `price` field from `string` to `Decimal128`, because it represents a monetary value. This requires iterating through the array using `$map` within an update pipeline. We expect **accurate financial aggregations (like averages in Q10) and consistent data types** across all transaction records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`transit`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Facilidade de transporte para Copacabana, Leme, Leblon, Ipanema, '\n",
      "         'Botafogo, Centro, São Conrado e Barra da Tijuca. O ponto de ônibus '\n",
      "         'fica a 3 minutos a pé e a estação de metrô do Leblon a '\n",
      "         'aproximadamente 15 minutos de caminhada. Em cerca de 10 minutos a pé '\n",
      "         'chega-se ao Baixo Gávea, à Praça Santos Dumont e aos shoppings. Para '\n",
      "         'a praia do Leblon, Lagoa Rodrigo de Freitas ou Jardim Botânico '\n",
      "         'leva-se no máximo 20 minutos caminhando. Isso tudo ainda mais perto '\n",
      "         'se preferir usar sua bike, que pode ser guardada no prédio com '\n",
      "         'segurança.'},\n",
      " {'_id': 'Nearest train station:  By subway - Stop SÃO BENTO - about 700m - 10 '\n",
      "         'min walk.  By train - Stop SÃO BENTO - about 700m - 10 min walk. If '\n",
      "         'you are carrying heavy and bulky luggage is recommended to take a '\n",
      "         'taxi from the airport. If you arrive by car please note that there '\n",
      "         'is free public car park spaces on the street, first come first serve '\n",
      "         'basis. Alternatively there are also paid car park spaces near by.'},\n",
      " {'_id': 'Really close to several bus stops and metro stations.'},\n",
      " {'_id': 'The apartment is two blocks from the 116 street crosstown bus and '\n",
      "         'local subway (C & B train).  If you are planning on going downtown, '\n",
      "         'you can take a 5 minute walk north to 125 and take the express '\n",
      "         'trains downtown (A & D trains).  If you are renting or own a car, '\n",
      "         'there is plenty of street parking along Manhattan avenue.  With four '\n",
      "         'train lines and multiple buses in walking distance, you can go '\n",
      "         'virtually anywhere.  A taxi from la guardia airport should cost '\n",
      "         'around 35-40 dollars.'},\n",
      " {'_id': 'the Parallel metro is 2 minutes from the apartment  taxi 2 minutes '\n",
      "         '...  in every way from the apartment you can have a nice walk to all '\n",
      "         'interesting locations'}]\n"
     ]
    }
   ],
   "source": [
    "# Check all possible values for 'transit' field\n",
    "transit_values = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$group\": {\"_id\": \"$transit\"}}\n",
    "]))\n",
    "pprint(transit_values[:5])  # Display the first few values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Analysis:** The `transit` field contains free-form text describing transportation options. It's unstructured and varies significantly in length and detail.\n",
    "    -  **Decision:** For the primary use case (displaying listing info quickly), structuring this field (e.g., splitting into an array) adds complexity without a clear, immediate benefit for the defined queries.\n",
    "       - **Action:** We will **leave the `transit` field as a string**. If future requirements necessitate searching specific transit types (e.g., \"metro\", \"bus\"), further refinement or indexing (like a text index) could be considered then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **⁉️ 1.3 | Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 76 unique non-array field paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking non-array fields: 100%|██████████| 76/76 [00:01<00:00, 74.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Missing Value Analysis (Including Array Subfields) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>4899</td>\n",
       "      <td>88.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>4841</td>\n",
       "      <td>87.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>3080</td>\n",
       "      <td>55.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>2478</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>2453</td>\n",
       "      <td>44.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>2285</td>\n",
       "      <td>41.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>2241</td>\n",
       "      <td>40.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>2232</td>\n",
       "      <td>40.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>2219</td>\n",
       "      <td>39.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>2084</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>1923</td>\n",
       "      <td>34.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>1626</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>1531</td>\n",
       "      <td>27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>1475</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>1475</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>1473</td>\n",
       "      <td>26.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>887</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>258</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>95</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>42</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>30</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>13</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>10</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>7</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>6</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       n       %\n",
       "field                                           \n",
       "images.medium_url                   5555  100.00\n",
       "images.thumbnail_url                5555  100.00\n",
       "images.xl_picture_url               5555  100.00\n",
       "monthly_price                       4899   88.19\n",
       "weekly_price                        4841   87.15\n",
       "notes                               3080   55.45\n",
       "interaction                         2478   44.61\n",
       "access                              2453   44.16\n",
       "house_rules                         2285   41.13\n",
       "neighborhood_overview               2241   40.34\n",
       "transit                             2232   40.18\n",
       "host_about                          2219   39.95\n",
       "security_deposit                    2084   37.52\n",
       "host_neighbourhood                  1923   34.62\n",
       "space                               1626   29.27\n",
       "cleaning_fee                        1531   27.56\n",
       "review_scores_checkin               1475   26.55\n",
       "review_scores_value                 1475   26.55\n",
       "review_scores_communication         1474   26.53\n",
       "review_scores_location              1474   26.53\n",
       "review_scores_rating                1474   26.53\n",
       "review_scores_cleanliness           1473   26.52\n",
       "last_review                         1388   24.99\n",
       "host_response_rate                  1388   24.99\n",
       "first_review                        1388   24.99\n",
       "host_response_time                  1388   24.99\n",
       "address.suburb                       887   15.97\n",
       "summary                              258    4.64\n",
       "description                           95    1.71\n",
       "reviews.comments                      42    0.03\n",
       "amenities                             30    0.54\n",
       "beds                                  13    0.23\n",
       "bathrooms                             10    0.18\n",
       "host_location                          8    0.14\n",
       "name                                   8    0.14\n",
       "host_verifications                     7    0.13\n",
       "address.market                         6    0.11\n",
       "bedrooms                               5    0.09\n",
       "availability.availability_60           0    0.00\n",
       "availability.availability_90           0    0.00\n",
       "availability                           0    0.00\n",
       "availability.availability_30           0    0.00\n",
       "address.location.type                  0    0.00\n",
       "availability.availability_365          0    0.00\n",
       "address.country_code                   0    0.00\n",
       "address.country                        0    0.00\n",
       "address.government_area                0    0.00\n",
       "address.location.is_location_exact     0    0.00\n",
       "accommodates                           0    0.00\n",
       "_id                                    0    0.00\n",
       "address                                0    0.00\n",
       "address.street                         0    0.00\n",
       "bed_type                               0    0.00\n",
       "images                                 0    0.00\n",
       "host_total_listings_count              0    0.00\n",
       "host_name                              0    0.00\n",
       "host_picture_url                       0    0.00\n",
       "host_thumbnail_url                     0    0.00\n",
       "host_url                               0    0.00\n",
       "calendar_last_scraped                  0    0.00\n",
       "extra_people                           0    0.00\n",
       "cancellation_policy                    0    0.00\n",
       "host_has_profile_pic                   0    0.00\n",
       "guests_included                        0    0.00\n",
       "host_id                                0    0.00\n",
       "host_identity_verified                 0    0.00\n",
       "host_is_superhost                      0    0.00\n",
       "host_listings_count                    0    0.00\n",
       "images.picture_url                     0    0.00\n",
       "price                                  0    0.00\n",
       "property_type                          0    0.00\n",
       "number_of_reviews                      0    0.00\n",
       "maximum_nights                         0    0.00\n",
       "listing_url                            0    0.00\n",
       "last_scraped                           0    0.00\n",
       "minimum_nights                         0    0.00\n",
       "room_type                              0    0.00\n",
       "reviews.reviewer_id                    0    0.00\n",
       "reviews.reviewer_name                  0    0.00\n",
       "reviews.date                           0    0.00\n",
       "reviews.listing_id                     0    0.00\n",
       "reviews._id                            0    0.00\n",
       "transactions.transactions.date         0    0.00\n",
       "transactions.transactions.price        0    0.00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check 'n' and '%' of missing values for all fields in the collection and subdocuments\n",
    "# Source: X. (2025). Grok 3 Beta — The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "#         Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "\n",
    "# --- Code for Non-Array Fields ---\n",
    "\n",
    "# Step 1 & 2: Get unique non-array field paths (simplified from your original)\n",
    "# We'll focus on fields NOT starting with 'reviews' or 'transactions.transactions'\n",
    "# A more robust way is needed if nested structures are complex, but this covers the main fields.\n",
    "all_field_paths_orig = set()\n",
    "pipeline_get_fields = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "    {\"$unwind\": \"$fields\"},\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}\n",
    "]\n",
    "cursor_fields = db.listingsAndReviews_HW2.aggregate(pipeline_get_fields)\n",
    "for doc in cursor_fields:\n",
    "     # Exclude the array fields themselves and fields starting with host_\n",
    "     if not doc['_id'].startswith('reviews') and \\\n",
    "        not doc['_id'].startswith('transactions'):                            # Keep only non-array fields\n",
    "        all_field_paths_orig.add(doc['_id'])\n",
    "\n",
    "# Manually add known nested non-array fields if needed (adjust based on schema)\n",
    "all_field_paths_orig.update([\n",
    "    'address.country', 'address.country_code', 'address.government_area', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb',\n",
    "    'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90',\n",
    "    'images.picture_url', 'images.medium_url', 'images.thumbnail_url', 'images.xl_picture_url'\n",
    "])\n",
    "unique_fields_orig = sorted(list(all_field_paths_orig))\n",
    "print(f\"Checking {len(unique_fields_orig)} unique non-array field paths...\")\n",
    "\n",
    "# Step 3: Count missing values for these non-array fields\n",
    "missing_counts_orig = {}\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "for field in tqdm(unique_fields_orig, desc=\"Checking non-array fields\"):\n",
    "    # Count documents where field is missing, null, or empty string\n",
    "    # Note: This check might be slow without indexes on every field\n",
    "    missing = db.listingsAndReviews_HW2.count_documents({\n",
    "        \"$or\": [\n",
    "            {field: {\"$exists\": False}},\n",
    "            {field: None},\n",
    "            {field: \"\"},\n",
    "            {field: []}, # Check for empty arrays if applicable\n",
    "            {field: {}}, # Check for empty objects if applicable\n",
    "        ]\n",
    "    })\n",
    "    missing_counts_orig[field] = missing\n",
    "\n",
    "# Step 4: Create DataFrame for non-array fields\n",
    "df_data_orig = {\n",
    "    \"n\": [missing_counts_orig.get(field, 0) for field in unique_fields_orig],\n",
    "    \"%\": [round((missing_counts_orig.get(field, 0) / total_docs) * 100, 2) if total_docs > 0 else 0 for field in unique_fields_orig]\n",
    "}\n",
    "df_orig = pd.DataFrame(df_data_orig, index=unique_fields_orig)\n",
    "df_orig.index.name = \"field\"\n",
    "\n",
    "# --- Code for Array Subfields ---\n",
    "\n",
    "# 1. Analyze 'reviews' subfields\n",
    "reviews_analysis_pipeline = [\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True, \"$ne\": []}}}, # Only docs with non-empty reviews\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,                    # Group across all unwound reviews\n",
    "        \"TotalReviews\": {\"$sum\": 1},    # Count total reviews\n",
    "        # Check each relevant subfield within the review object\n",
    "        \"MissingComments\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.comments\", None]}, {\"$eq\": [\"$reviews.comments\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewerId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.reviewer_id\", None]}, {\"$eq\": [\"$reviews.reviewer_id\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewerName\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.reviewer_name\", None]}, {\"$eq\": [\"$reviews.reviewer_name\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingDate\": {\"$sum\": {\"$cond\": [{\"$eq\": [\"$reviews.date\", None]}, 1, 0]}},                                             # Date usually only check for null\n",
    "        \"MissingListingId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.listing_id\", None]}, {\"$eq\": [\"$reviews.listing_id\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews._id\", None]}, {\"$eq\": [\"$reviews._id\", \"\"]}]}, 1, 0]}} # Check review _id\n",
    "    }},\n",
    "    # Project into a more readable format for combining later\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"TotalElements\": \"$TotalReviews\",\n",
    "        \"field_stats\": [\n",
    "            {\"field\": \"reviews.comments\", \"n\": \"$MissingComments\"},\n",
    "            {\"field\": \"reviews.reviewer_id\", \"n\": \"$MissingReviewerId\"},\n",
    "            {\"field\": \"reviews.reviewer_name\", \"n\": \"$MissingReviewerName\"},\n",
    "            {\"field\": \"reviews.date\", \"n\": \"$MissingDate\"},\n",
    "            {\"field\": \"reviews.listing_id\", \"n\": \"$MissingListingId\"},\n",
    "            {\"field\": \"reviews._id\", \"n\": \"$MissingReviewId\"}\n",
    "        ]\n",
    "    }}\n",
    "]\n",
    "reviews_missing_result = list(db.listingsAndReviews_HW2.aggregate(reviews_analysis_pipeline))\n",
    "\n",
    "# 2. Analyze 'transactions.transactions' subfields\n",
    "transactions_analysis_pipeline = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}}, # Only docs with non-empty transactions array\n",
    "    {\"$unwind\": \"$transactions.transactions\"},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None, # Group across all unwound transactions\n",
    "        \"TotalTransactions\": {\"$sum\": 1},\n",
    "        \"MissingDate\": {\"$sum\": {\"$cond\": [{\"$eq\": [\"$transactions.transactions.date\", None]}, 1, 0]}},\n",
    "        \"MissingPrice\": {\"$sum\": {\"$cond\": [{\"$or\": [\n",
    "            {\"$eq\": [\"$transactions.transactions.price\", None]},\n",
    "            # Add check for empty string ONLY if price was ever a string\n",
    "            {\"$eq\": [\"$transactions.transactions.price\", \"\"]}\n",
    "        ]}, 1, 0]}}\n",
    "    }},\n",
    "     # Project into a more readable format\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"TotalElements\": \"$TotalTransactions\",\n",
    "        \"field_stats\": [\n",
    "            {\"field\": \"transactions.transactions.date\", \"n\": \"$MissingDate\"},\n",
    "            {\"field\": \"transactions.transactions.price\", \"n\": \"$MissingPrice\"}\n",
    "        ]\n",
    "    }}\n",
    "]\n",
    "transactions_missing_result = list(db.listingsAndReviews_HW2.aggregate(transactions_analysis_pipeline))\n",
    "\n",
    "# 3. Combine results into DataFrame\n",
    "missing_data_combined = {}\n",
    "\n",
    "# Add non-array results\n",
    "for field, row in df_orig.iterrows():\n",
    "    missing_data_combined[field] = {\"n\": row['n'], \"TotalElements\": total_docs}\n",
    "\n",
    "# Add reviews results\n",
    "if reviews_missing_result:\n",
    "    total_reviews = reviews_missing_result[0].get(\"TotalElements\", 0)\n",
    "    for stat in reviews_missing_result[0].get(\"field_stats\", []):\n",
    "        missing_data_combined[stat[\"field\"]] = {\"n\": stat[\"n\"], \"TotalElements\": total_reviews}\n",
    "\n",
    "# Add transactions results\n",
    "if transactions_missing_result:\n",
    "    total_transactions = transactions_missing_result[0].get(\"TotalElements\", 0)\n",
    "    for stat in transactions_missing_result[0].get(\"field_stats\", []):\n",
    "        missing_data_combined[stat[\"field\"]] = {\"n\": stat[\"n\"], \"TotalElements\": total_transactions}\n",
    "\n",
    "# Create final DataFrame\n",
    "df_combined_data = []\n",
    "for field, data in missing_data_combined.items():\n",
    "    n_missing = data.get(\"n\", 0)\n",
    "    total_elements = data.get(\"TotalElements\", 0) # Use specific total for arrays\n",
    "    percent_missing = round((n_missing / total_elements) * 100, 2) if total_elements > 0 else 0\n",
    "    df_combined_data.append({\"field\": field, \"n\": n_missing, \"%\": percent_missing})\n",
    "\n",
    "missing_counts = pd.DataFrame(df_combined_data)\n",
    "missing_counts.set_index(\"field\", inplace=True)\n",
    "missing_counts[\"n\"] = missing_counts[\"n\"].astype(int)  # Ensure 'n' is integer type\n",
    "missing_counts.sort_values(by=\"n\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\n--- Combined Missing Value Analysis (Including Array Subfields) ---\")\n",
    "missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 'access' from 2453 documents.\n",
      "Cleaned 'address.market' from 6 documents.\n",
      "Cleaned 'address.suburb' from 887 documents.\n",
      "Cleaned 'amenities' from 30 documents.\n",
      "Cleaned 'bathrooms' from 10 documents.\n",
      "Cleaned 'bedrooms' from 5 documents.\n",
      "Cleaned 'beds' from 13 documents.\n",
      "Cleaned 'cleaning_fee' from 1531 documents.\n",
      "Cleaned 'description' from 95 documents.\n",
      "Cleaned 'first_review' from 1388 documents.\n",
      "Cleaned 'host_about' from 2219 documents.\n",
      "Cleaned 'host_location' from 8 documents.\n",
      "Cleaned 'host_neighbourhood' from 1923 documents.\n",
      "Cleaned 'host_response_rate' from 1388 documents.\n",
      "Cleaned 'host_response_time' from 1388 documents.\n",
      "Cleaned 'host_verifications' from 7 documents.\n",
      "Cleaned 'house_rules' from 2285 documents.\n",
      "Cleaned 'images.medium_url' from 5555 documents.\n",
      "Cleaned 'images.thumbnail_url' from 5555 documents.\n",
      "Cleaned 'images.xl_picture_url' from 5555 documents.\n",
      "Cleaned 'interaction' from 2478 documents.\n",
      "Cleaned 'last_review' from 1388 documents.\n",
      "Cleaned 'monthly_price' from 4899 documents.\n",
      "Cleaned 'name' from 8 documents.\n",
      "Cleaned 'neighborhood_overview' from 2241 documents.\n",
      "Cleaned 'notes' from 3080 documents.\n",
      "Cleaned 'review_scores_checkin' from 1475 documents.\n",
      "Cleaned 'review_scores_cleanliness' from 1473 documents.\n",
      "Cleaned 'review_scores_communication' from 1474 documents.\n",
      "Cleaned 'review_scores_location' from 1474 documents.\n",
      "Cleaned 'review_scores_rating' from 1474 documents.\n",
      "Cleaned 'review_scores_value' from 1475 documents.\n",
      "Cleaned 'security_deposit' from 2084 documents.\n",
      "Cleaned 'space' from 1626 documents.\n",
      "Cleaned 'summary' from 258 documents.\n",
      "Cleaned 'transit' from 2232 documents.\n",
      "Cleaned 'weekly_price' from 4841 documents.\n"
     ]
    }
   ],
   "source": [
    "# Clean up - Remove fields with \"\" or None from individual documents\n",
    "fields_to_clean = [field for field in unique_fields_orig if field in missing_counts.index and missing_counts.loc[field, 'n'] > 0]\n",
    "for field in fields_to_clean:\n",
    "    # Remove field where it's \"\" or None\n",
    "    db.listingsAndReviews_HW2.update_many(\n",
    "        {\"$or\": [{field: \"\"}, {field: None}, {field: []}, {field: {}}]},     # Check for empty strings, None, empty arrays, or empty objects\n",
    "        {\"$unset\": {field: \"\"}}                                              # Unset the field from the document if it matches the criteria\n",
    "    )\n",
    "    print(f\"Cleaned '{field}' from {missing_counts.loc[field, 'n']} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We do not treat the `reviews` and `transactions` fields as missing data because they are **arrays of subdocuments**, not simple scalar fields. Analyzing them as \"missing\" at the top level would be misleading — the field may exist and simply contain an empty array.\n",
    "  - Instead, we evaluate the **completeness of the data inside** these arrays by unwinding them and checking for missing values within each subdocument (e.g., `review.date`, `transaction.price`). This allows us to capture cases where fields are either null, missing entirely, or empty strings.\n",
    "\n",
    "- Our analysis showed that all `transactions` (n = $311 \\;093$) are fully populated, with **no missing values** in the inspected fields. Among the `reviews` (n = $149\\;793$), we found **42 missing values** in the `comments` field (i.e., either `null` or empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify cleanup\n",
    "post_cleanup_counts = {}\n",
    "for field in fields_to_clean:\n",
    "    \n",
    "    # Count remaining documents with field as None\n",
    "    remaining = db.listingsAndReviews_HW2.count_documents({\n",
    "        field: {\"$eq\": None, \"$exists\": True}\n",
    "    })\n",
    "    post_cleanup_counts[field] = remaining\n",
    "    if remaining > 0:\n",
    "        print(f\"Warning: {remaining} documents still have '{field}' as None and explicitly exist.\")\n",
    "    \n",
    "    # Check for empty strings \n",
    "    empty_str_count = db.listingsAndReviews_HW2.count_documents({\n",
    "        field: {\"$eq\": \"\", \"$exists\": True}\n",
    "    })\n",
    "    if empty_str_count > 0:\n",
    "        print(f\"Note: {empty_str_count} documents still have '{field}' as empty string and explicitly exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The initial check revealed numerous fields with missing (`null`) or empty string (`\"\"`) values, particularly for optional details like `notes`, `interaction`, `host_about`, `security_deposit`, and pricing fields (`weekly_price`, `monthly_price`).\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data cleanup by removing missing/empty fields** using `$unset` for fields identified with `null` or `\"\"` values, because these values often provide no information and can interfere with queries (e.g., type checking, `$exists`). We expect **cleaner data, slightly reduced document size, and more predictable query behavior** when filtering or checking for field existence.\n",
    "\n",
    "\n",
    "The verification confirms that `null` and `\"\"` values were successfully unset from the documents. Fields listed as having `0` remaining `null` or `\"\"` values (where `$exists: true`) are now clean in that regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **♨️ 1.4 | Data Cleanup - Invalid/Outliers Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'access', 'accommodates', 'address', 'address.country', 'address.country_code', 'address.government_area', 'address.location', 'address.location.coordinates', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb', 'amenities', 'availability', 'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90', 'bathrooms', 'bed_type', 'bedrooms', 'beds', 'calendar_last_scraped', 'cancellation_policy', 'cleaning_fee', 'description', 'extra_people', 'first_review', 'guests_included', 'host_about', 'host_has_profile_pic', 'host_id', 'host_identity_verified', 'host_is_superhost', 'host_listings_count', 'host_location', 'host_name', 'host_neighbourhood', 'host_picture_url', 'host_response_rate', 'host_response_time', 'host_thumbnail_url', 'host_total_listings_count', 'host_url', 'host_verifications', 'house_rules', 'images', 'images.medium_url', 'images.picture_url', 'images.thumbnail_url', 'images.xl_picture_url', 'interaction', 'last_review', 'last_scraped', 'listing_url', 'maximum_nights', 'minimum_nights', 'monthly_price', 'name', 'neighborhood_overview', 'notes', 'number_of_reviews', 'price', 'property_type', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value', 'reviews', 'reviews._id', 'reviews.comments', 'reviews.date', 'reviews.listing_id', 'reviews.reviewer_id', 'reviews.reviewer_name', 'reviews_per_month', 'room_type', 'security_deposit', 'space', 'summary', 'transactions', 'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count', 'transactions.transactions', 'transactions.transactions.date', 'transactions.transactions.price', 'transit', 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "print(unique_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Statistical Summary Generation ---\n",
      "Analyzing non-array fields...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing main fields: 100%|██████████| 75/75 [00:01<00:00, 44.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'reviews' subfields...\n",
      "Total review elements to analyze: 149792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing review fields: 100%|██████████| 6/6 [00:01<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'transactions.transactions' subfields...\n",
      "Total transaction elements to analyze: 311093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing transaction fields: 100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'amenities'...\n",
      "Total amenity elements to analyze: 121372\n",
      "Analyzing 'host_verifications'...\n",
      "Total verification elements to analyze: 27593\n",
      "\n",
      "--- Final Statistical Summary (Original Collection) ---\n",
      "Total fields: 85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Distinct Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>5555</td>\n",
       "      <td>5555</td>\n",
       "      <td>-</td>\n",
       "      <td>10006546</td>\n",
       "      <td>9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>3102</td>\n",
       "      <td>2988</td>\n",
       "      <td>-</td>\n",
       "      <td>Everything is located in a beautiful and spac...</td>\n",
       "      <td>ｼｪｱｷｯﾁﾝもあります! Share kitchen is located on 2nd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>5555</td>\n",
       "      <td>16</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>5555</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Australia</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>5555</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>AU</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>5555</td>\n",
       "      <td>418</td>\n",
       "      <td>-</td>\n",
       "      <td>AVer-o-Mar, Amorim e Terroso</td>\n",
       "      <td>Árvore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>5555</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>Point</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>5549</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>The Big Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>5555</td>\n",
       "      <td>677</td>\n",
       "      <td>-</td>\n",
       "      <td>ADALAR, Istanbul, Turkey</td>\n",
       "      <td>香港, 香港, Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>4668</td>\n",
       "      <td>409</td>\n",
       "      <td>-</td>\n",
       "      <td>Abbotsford/Wareemba</td>\n",
       "      <td>Şişli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>121372</td>\n",
       "      <td>185</td>\n",
       "      <td>-</td>\n",
       "      <td>24-hour check-in</td>\n",
       "      <td>translation missing: en.hosting_amenity_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>5555</td>\n",
       "      <td>31</td>\n",
       "      <td>11.82</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>5555</td>\n",
       "      <td>366</td>\n",
       "      <td>173.11</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>5555</td>\n",
       "      <td>61</td>\n",
       "      <td>26.45</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>5555</td>\n",
       "      <td>91</td>\n",
       "      <td>42.76</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>5545</td>\n",
       "      <td>17</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>Airbed</td>\n",
       "      <td>Real Bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5550</td>\n",
       "      <td>13</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>5542</td>\n",
       "      <td>19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>5555</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>2019-02-11 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>5555</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>flexible</td>\n",
       "      <td>super_strict_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>4024</td>\n",
       "      <td>291</td>\n",
       "      <td>94.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>5460</td>\n",
       "      <td>5441</td>\n",
       "      <td>-</td>\n",
       "      <td>Cozy room! It has a double bed, cable ...</td>\n",
       "      <td>룸에 창문이 있어괘적합니다. tv,무선인터넷  기본 필수품 준비되어 있습니다 숙소바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>5555</td>\n",
       "      <td>138</td>\n",
       "      <td>22.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>4167</td>\n",
       "      <td>1686</td>\n",
       "      <td>-</td>\n",
       "      <td>2009-10-27 04:00:00</td>\n",
       "      <td>2019-03-10 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>5555</td>\n",
       "      <td>14</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>3336</td>\n",
       "      <td>2949</td>\n",
       "      <td>-</td>\n",
       "      <td>\\n</td>\n",
       "      <td>｡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>5555</td>\n",
       "      <td>5104</td>\n",
       "      <td>-</td>\n",
       "      <td>10002884</td>\n",
       "      <td>99997584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>132</td>\n",
       "      <td>14.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>5547</td>\n",
       "      <td>675</td>\n",
       "      <td>-</td>\n",
       "      <td>New South Wales, Australia</td>\n",
       "      <td>부산, 대한민국</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>5555</td>\n",
       "      <td>3140</td>\n",
       "      <td>-</td>\n",
       "      <td>(Email hidden by Airbnb)</td>\n",
       "      <td>馨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>3632</td>\n",
       "      <td>446</td>\n",
       "      <td>-</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>Şişli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5086</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/defaults/user_pic-225x...</td>\n",
       "      <td>https://a0.muscache.com/im/users/9997988/profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>4167</td>\n",
       "      <td>62</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>4167</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>a few days or more</td>\n",
       "      <td>within an hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5086</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/defaults/user_pic-50x5...</td>\n",
       "      <td>https://a0.muscache.com/im/users/9997988/profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>132</td>\n",
       "      <td>14.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5104</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.airbnb.com/users/show/10002884</td>\n",
       "      <td>https://www.airbnb.com/users/show/99997584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>27593</td>\n",
       "      <td>19</td>\n",
       "      <td>-</td>\n",
       "      <td>email</td>\n",
       "      <td>zhima_selfie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>3270</td>\n",
       "      <td>3112</td>\n",
       "      <td>-</td>\n",
       "      <td>\"Mi casa es su casa\".  When you leave please t...</td>\n",
       "      <td>･No Smoking, ･No Pet, ･No Party, ･No Children ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5553</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/4ea/air/v2//pictures/0...</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/fff8056a-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>3077</td>\n",
       "      <td>2916</td>\n",
       "      <td>-</td>\n",
       "      <td>'Ohana Nui means Big Family, which is what we ...</td>\n",
       "      <td>개스트에 따라..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>4167</td>\n",
       "      <td>809</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-01-06 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>5555</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>2019-02-11 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5555</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.airbnb.com/rooms/10006546</td>\n",
       "      <td>https://www.airbnb.com/rooms/9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>5555</td>\n",
       "      <td>140</td>\n",
       "      <td>1382776.32</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>5555</td>\n",
       "      <td>45</td>\n",
       "      <td>5.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>656</td>\n",
       "      <td>309</td>\n",
       "      <td>5391.37</td>\n",
       "      <td>250.0</td>\n",
       "      <td>253384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>5547</td>\n",
       "      <td>5537</td>\n",
       "      <td>-</td>\n",
       "      <td>!5 mins from MTR! Ideal for biz travel / family</td>\n",
       "      <td>｡Townhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>3314</td>\n",
       "      <td>3227</td>\n",
       "      <td>-</td>\n",
       "      <td>\"Be happy in Porto\"  offers a quality accommod...</td>\n",
       "      <td>ｱｯﾄﾎｰﾑな雰囲気で､日本人のご家族が多く住んでいるｴﾘｱです｡最近はかわいいｶﾌｪも増え...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>2475</td>\n",
       "      <td>2381</td>\n",
       "      <td>-</td>\n",
       "      <td>!!!Sejam muito bem vindos!!!</td>\n",
       "      <td>￫  Feel free to smoke in our outdoor area, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>5555</td>\n",
       "      <td>259</td>\n",
       "      <td>27.61</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>5555</td>\n",
       "      <td>649</td>\n",
       "      <td>278.77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>36</td>\n",
       "      <td>-</td>\n",
       "      <td>Aparthotel</td>\n",
       "      <td>Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>4080</td>\n",
       "      <td>9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>4082</td>\n",
       "      <td>8</td>\n",
       "      <td>9.32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>4081</td>\n",
       "      <td>9</td>\n",
       "      <td>9.69</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>4081</td>\n",
       "      <td>8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>4081</td>\n",
       "      <td>41</td>\n",
       "      <td>93.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>4080</td>\n",
       "      <td>9</td>\n",
       "      <td>9.31</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>149792</td>\n",
       "      <td>149792</td>\n",
       "      <td>-</td>\n",
       "      <td>10000121</td>\n",
       "      <td>99999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>149784</td>\n",
       "      <td>146782</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>ﾜｲｷｷﾋﾞｰﾁ､DFS他ｼｮｯﾋﾟﾝｸﾞﾓｰﾙに近く非常に便利で有りながら静か｡ABCﾏｰ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>149792</td>\n",
       "      <td>2778</td>\n",
       "      <td>-</td>\n",
       "      <td>2009-10-27 04:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>149792</td>\n",
       "      <td>3923</td>\n",
       "      <td>-</td>\n",
       "      <td>10006546</td>\n",
       "      <td>9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>149792</td>\n",
       "      <td>146640</td>\n",
       "      <td>-</td>\n",
       "      <td>10000032</td>\n",
       "      <td>99998112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>149791</td>\n",
       "      <td>32901</td>\n",
       "      <td>-</td>\n",
       "      <td>'Dea</td>\n",
       "      <td>ﾕｳﾀﾛｳ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Shared room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>3471</td>\n",
       "      <td>213</td>\n",
       "      <td>509.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>3929</td>\n",
       "      <td>3887</td>\n",
       "      <td>-</td>\n",
       "      <td>Cozy room! It has a double bed, cable ...</td>\n",
       "      <td>￫ Second floor studio (you must climb 2 flight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>5297</td>\n",
       "      <td>5259</td>\n",
       "      <td>-</td>\n",
       "      <td>Simply Hostel is, a brand new Licensed ...</td>\n",
       "      <td>룸에 창문이 있어괘적합니다. tv,무선인터넷  기본 필수품 준비되어 있습니다 숙소바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_end_date</th>\n",
       "      <td>5555</td>\n",
       "      <td>208</td>\n",
       "      <td>-</td>\n",
       "      <td>2002-03-05 00:00:00</td>\n",
       "      <td>2017-01-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_start_date</th>\n",
       "      <td>5555</td>\n",
       "      <td>1362</td>\n",
       "      <td>-</td>\n",
       "      <td>1962-01-08 00:00:00</td>\n",
       "      <td>2015-11-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transaction_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>311093</td>\n",
       "      <td>8651</td>\n",
       "      <td>-</td>\n",
       "      <td>1962-03-08 00:00:00</td>\n",
       "      <td>2017-01-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>311093</td>\n",
       "      <td>73190</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>845.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>3323</td>\n",
       "      <td>3230</td>\n",
       "      <td>-</td>\n",
       "      <td>it is less than 5 minutes walk from Taksim an...</td>\n",
       "      <td>대중 교통이 와이켈렐 샤핑 쌘타 에서 도보로 5 -7 분 집까지, 관광 버스가 수시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>714</td>\n",
       "      <td>323</td>\n",
       "      <td>1530.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Count  Distinct Count        Mean  \\\n",
       "field                                                                    \n",
       "_id                                   5555            5555           -   \n",
       "access                                3102            2988           -   \n",
       "accommodates                          5555              16        3.51   \n",
       "address.country                       5555               9           -   \n",
       "address.country_code                  5555               9           -   \n",
       "address.government_area               5555             418           -   \n",
       "address.location.is_location_exact    5555               2        0.67   \n",
       "address.location.type                 5555               1           -   \n",
       "address.market                        5549              14           -   \n",
       "address.street                        5555             677           -   \n",
       "address.suburb                        4668             409           -   \n",
       "amenities                           121372             185           -   \n",
       "availability.availability_30          5555              31       11.82   \n",
       "availability.availability_365         5555             366      173.11   \n",
       "availability.availability_60          5555              61       26.45   \n",
       "availability.availability_90          5555              91       42.76   \n",
       "bathrooms                             5545              17        1.29   \n",
       "bed_type                              5555               5           -   \n",
       "bedrooms                              5550              13        1.41   \n",
       "beds                                  5542              19        2.07   \n",
       "calendar_last_scraped                 5555               7           -   \n",
       "cancellation_policy                   5555               5           -   \n",
       "cleaning_fee                          4024             291       94.07   \n",
       "description                           5460            5441           -   \n",
       "extra_people                          5555             138       22.79   \n",
       "first_review                          4167            1686           -   \n",
       "guests_included                       5555              14        1.75   \n",
       "host_about                            3336            2949           -   \n",
       "host_has_profile_pic                  5555               2         1.0   \n",
       "host_id                               5555            5104           -   \n",
       "host_identity_verified                5555               2        0.36   \n",
       "host_is_superhost                     5555               2         0.2   \n",
       "host_listings_count                   5555             132       14.41   \n",
       "host_location                         5547             675           -   \n",
       "host_name                             5555            3140           -   \n",
       "host_neighbourhood                    3632             446           -   \n",
       "host_picture_url                      5555            5086           -   \n",
       "host_response_rate                    4167              62       93.12   \n",
       "host_response_time                    4167               4           -   \n",
       "host_thumbnail_url                    5555            5086           -   \n",
       "host_total_listings_count             5555             132       14.41   \n",
       "host_url                              5555            5104           -   \n",
       "host_verifications                   27593              19           -   \n",
       "house_rules                           3270            3112           -   \n",
       "images.medium_url                        0               0           -   \n",
       "images.picture_url                    5555            5553           -   \n",
       "images.thumbnail_url                     0               0           -   \n",
       "images.xl_picture_url                    0               0           -   \n",
       "interaction                           3077            2916           -   \n",
       "last_review                           4167             809           -   \n",
       "last_scraped                          5555               7           -   \n",
       "listing_url                           5555            5555           -   \n",
       "maximum_nights                        5555             140  1382776.32   \n",
       "minimum_nights                        5555              45        5.56   \n",
       "monthly_price                          656             309     5391.37   \n",
       "name                                  5547            5537           -   \n",
       "neighborhood_overview                 3314            3227           -   \n",
       "notes                                 2475            2381           -   \n",
       "number_of_reviews                     5555             259       27.61   \n",
       "price                                 5555             649      278.77   \n",
       "property_type                         5555              36           -   \n",
       "review_scores_checkin                 4080               9         9.7   \n",
       "review_scores_cleanliness             4082               8        9.32   \n",
       "review_scores_communication           4081               9        9.69   \n",
       "review_scores_location                4081               8         9.6   \n",
       "review_scores_rating                  4081              41        93.1   \n",
       "review_scores_value                   4080               9        9.31   \n",
       "reviews._id                         149792          149792           -   \n",
       "reviews.comments                    149784          146782           -   \n",
       "reviews.date                        149792            2778           -   \n",
       "reviews.listing_id                  149792            3923           -   \n",
       "reviews.reviewer_id                 149792          146640           -   \n",
       "reviews.reviewer_name               149791           32901           -   \n",
       "reviews_per_month                       94               8        1.71   \n",
       "room_type                             5555               3           -   \n",
       "security_deposit                      3471             213      509.43   \n",
       "space                                 3929            3887           -   \n",
       "summary                               5297            5259           -   \n",
       "transactions.bucket_end_date          5555             208           -   \n",
       "transactions.bucket_start_date        5555            1362           -   \n",
       "transactions.transaction_count        5555             100        56.0   \n",
       "transactions.transactions.date      311093            8651           -   \n",
       "transactions.transactions.price     311093           73190        83.0   \n",
       "transit                               3323            3230           -   \n",
       "weekly_price                           714             323      1530.9   \n",
       "\n",
       "                                                                                  Min  \\\n",
       "field                                                                                   \n",
       "_id                                                                          10006546   \n",
       "access                               Everything is located in a beautiful and spac...   \n",
       "accommodates                                                                        1   \n",
       "address.country                                                             Australia   \n",
       "address.country_code                                                               AU   \n",
       "address.government_area                                  AVer-o-Mar, Amorim e Terroso   \n",
       "address.location.is_location_exact                                              False   \n",
       "address.location.type                                                           Point   \n",
       "address.market                                                              Barcelona   \n",
       "address.street                                               ADALAR, Istanbul, Turkey   \n",
       "address.suburb                                                    Abbotsford/Wareemba   \n",
       "amenities                                                            24-hour check-in   \n",
       "availability.availability_30                                                        0   \n",
       "availability.availability_365                                                       0   \n",
       "availability.availability_60                                                        0   \n",
       "availability.availability_90                                                        0   \n",
       "bathrooms                                                                         0.0   \n",
       "bed_type                                                                       Airbed   \n",
       "bedrooms                                                                            0   \n",
       "beds                                                                                0   \n",
       "calendar_last_scraped                                             2019-02-11 05:00:00   \n",
       "cancellation_policy                                                          flexible   \n",
       "cleaning_fee                                                                      0.0   \n",
       "description                                 Cozy room! It has a double bed, cable ...   \n",
       "extra_people                                                                      0.0   \n",
       "first_review                                                      2009-10-27 04:00:00   \n",
       "guests_included                                                                     1   \n",
       "host_about                                                                         \\n   \n",
       "host_has_profile_pic                                                            False   \n",
       "host_id                                                                      10002884   \n",
       "host_identity_verified                                                          False   \n",
       "host_is_superhost                                                               False   \n",
       "host_listings_count                                                                 0   \n",
       "host_location                                              New South Wales, Australia   \n",
       "host_name                                                    (Email hidden by Airbnb)   \n",
       "host_neighbourhood                                                         Abbotsford   \n",
       "host_picture_url                    https://a0.muscache.com/defaults/user_pic-225x...   \n",
       "host_response_rate                                                                  0   \n",
       "host_response_time                                                 a few days or more   \n",
       "host_thumbnail_url                  https://a0.muscache.com/defaults/user_pic-50x5...   \n",
       "host_total_listings_count                                                           0   \n",
       "host_url                                   https://www.airbnb.com/users/show/10002884   \n",
       "host_verifications                                                              email   \n",
       "house_rules                         \"Mi casa es su casa\".  When you leave please t...   \n",
       "images.medium_url                                                                   -   \n",
       "images.picture_url                  https://a0.muscache.com/4ea/air/v2//pictures/0...   \n",
       "images.thumbnail_url                                                                -   \n",
       "images.xl_picture_url                                                               -   \n",
       "interaction                         'Ohana Nui means Big Family, which is what we ...   \n",
       "last_review                                                       2012-01-06 05:00:00   \n",
       "last_scraped                                                      2019-02-11 05:00:00   \n",
       "listing_url                                     https://www.airbnb.com/rooms/10006546   \n",
       "maximum_nights                                                                      1   \n",
       "minimum_nights                                                                      1   \n",
       "monthly_price                                                                   250.0   \n",
       "name                                  !5 mins from MTR! Ideal for biz travel / family   \n",
       "neighborhood_overview               \"Be happy in Porto\"  offers a quality accommod...   \n",
       "notes                                                    !!!Sejam muito bem vindos!!!   \n",
       "number_of_reviews                                                                   0   \n",
       "price                                                                             9.0   \n",
       "property_type                                                              Aparthotel   \n",
       "review_scores_checkin                                                               2   \n",
       "review_scores_cleanliness                                                           2   \n",
       "review_scores_communication                                                         2   \n",
       "review_scores_location                                                              2   \n",
       "review_scores_rating                                                               20   \n",
       "review_scores_value                                                                 2   \n",
       "reviews._id                                                                  10000121   \n",
       "reviews.comments                                                                        \n",
       "reviews.date                                                      2009-10-27 04:00:00   \n",
       "reviews.listing_id                                                           10006546   \n",
       "reviews.reviewer_id                                                          10000032   \n",
       "reviews.reviewer_name                                                            'Dea   \n",
       "reviews_per_month                                                                   1   \n",
       "room_type                                                             Entire home/apt   \n",
       "security_deposit                                                                  0.0   \n",
       "space                                       Cozy room! It has a double bed, cable ...   \n",
       "summary                                    Simply Hostel is, a brand new Licensed ...   \n",
       "transactions.bucket_end_date                                      2002-03-05 00:00:00   \n",
       "transactions.bucket_start_date                                    1962-01-08 00:00:00   \n",
       "transactions.transaction_count                                                      1   \n",
       "transactions.transactions.date                                    1962-03-08 00:00:00   \n",
       "transactions.transactions.price                                                  0.02   \n",
       "transit                              it is less than 5 minutes walk from Taksim an...   \n",
       "weekly_price                                                                     60.0   \n",
       "\n",
       "                                                                                  Max  \n",
       "field                                                                                  \n",
       "_id                                                                           9993190  \n",
       "access                              ｼｪｱｷｯﾁﾝもあります! Share kitchen is located on 2nd ...  \n",
       "accommodates                                                                       16  \n",
       "address.country                                                         United States  \n",
       "address.country_code                                                               US  \n",
       "address.government_area                                                        Árvore  \n",
       "address.location.is_location_exact                                               True  \n",
       "address.location.type                                                           Point  \n",
       "address.market                                                         The Big Island  \n",
       "address.street                                                      香港, 香港, Hong Kong  \n",
       "address.suburb                                                                  Şişli  \n",
       "amenities                                  translation missing: en.hosting_amenity_50  \n",
       "availability.availability_30                                                       30  \n",
       "availability.availability_365                                                     365  \n",
       "availability.availability_60                                                       60  \n",
       "availability.availability_90                                                       90  \n",
       "bathrooms                                                                        16.0  \n",
       "bed_type                                                                     Real Bed  \n",
       "bedrooms                                                                           20  \n",
       "beds                                                                               25  \n",
       "calendar_last_scraped                                             2019-03-11 04:00:00  \n",
       "cancellation_policy                                                   super_strict_60  \n",
       "cleaning_fee                                                                   2000.0  \n",
       "description                         룸에 창문이 있어괘적합니다. tv,무선인터넷  기본 필수품 준비되어 있습니다 숙소바...  \n",
       "extra_people                                                                   2346.0  \n",
       "first_review                                                      2019-03-10 05:00:00  \n",
       "guests_included                                                                    16  \n",
       "host_about                                                                          ｡  \n",
       "host_has_profile_pic                                                             True  \n",
       "host_id                                                                      99997584  \n",
       "host_identity_verified                                                           True  \n",
       "host_is_superhost                                                                True  \n",
       "host_listings_count                                                              1198  \n",
       "host_location                                                                부산, 대한민국  \n",
       "host_name                                                                           馨  \n",
       "host_neighbourhood                                                              Şişli  \n",
       "host_picture_url                    https://a0.muscache.com/im/users/9997988/profi...  \n",
       "host_response_rate                                                                100  \n",
       "host_response_time                                                     within an hour  \n",
       "host_thumbnail_url                  https://a0.muscache.com/im/users/9997988/profi...  \n",
       "host_total_listings_count                                                        1198  \n",
       "host_url                                   https://www.airbnb.com/users/show/99997584  \n",
       "host_verifications                                                       zhima_selfie  \n",
       "house_rules                         ･No Smoking, ･No Pet, ･No Party, ･No Children ...  \n",
       "images.medium_url                                                                   -  \n",
       "images.picture_url                  https://a0.muscache.com/im/pictures/fff8056a-c...  \n",
       "images.thumbnail_url                                                                -  \n",
       "images.xl_picture_url                                                               -  \n",
       "interaction                                                                 개스트에 따라..  \n",
       "last_review                                                       2019-03-11 04:00:00  \n",
       "last_scraped                                                      2019-03-11 04:00:00  \n",
       "listing_url                                      https://www.airbnb.com/rooms/9993190  \n",
       "maximum_nights                                                             2147483647  \n",
       "minimum_nights                                                                   1250  \n",
       "monthly_price                                                                253384.0  \n",
       "name                                                                       ｡Townhouse  \n",
       "neighborhood_overview               ｱｯﾄﾎｰﾑな雰囲気で､日本人のご家族が多く住んでいるｴﾘｱです｡最近はかわいいｶﾌｪも増え...  \n",
       "notes                               ￫  Feel free to smoke in our outdoor area, but...  \n",
       "number_of_reviews                                                                 533  \n",
       "price                                                                         48842.0  \n",
       "property_type                                                                   Villa  \n",
       "review_scores_checkin                                                              10  \n",
       "review_scores_cleanliness                                                          10  \n",
       "review_scores_communication                                                        10  \n",
       "review_scores_location                                                             10  \n",
       "review_scores_rating                                                              100  \n",
       "review_scores_value                                                                10  \n",
       "reviews._id                                                                  99999615  \n",
       "reviews.comments                    ﾜｲｷｷﾋﾞｰﾁ､DFS他ｼｮｯﾋﾟﾝｸﾞﾓｰﾙに近く非常に便利で有りながら静か｡ABCﾏｰ...  \n",
       "reviews.date                                                      2019-03-11 04:00:00  \n",
       "reviews.listing_id                                                            9993190  \n",
       "reviews.reviewer_id                                                          99998112  \n",
       "reviews.reviewer_name                                                           ﾕｳﾀﾛｳ  \n",
       "reviews_per_month                                                                  10  \n",
       "room_type                                                                 Shared room  \n",
       "security_deposit                                                              39228.0  \n",
       "space                               ￫ Second floor studio (you must climb 2 flight...  \n",
       "summary                             룸에 창문이 있어괘적합니다. tv,무선인터넷  기본 필수품 준비되어 있습니다 숙소바...  \n",
       "transactions.bucket_end_date                                      2017-01-09 00:00:00  \n",
       "transactions.bucket_start_date                                    2015-11-28 00:00:00  \n",
       "transactions.transaction_count                                                    100  \n",
       "transactions.transactions.date                                    2017-01-09 00:00:00  \n",
       "transactions.transactions.price                                                 845.8  \n",
       "transit                             대중 교통이 와이켈렐 샤핑 쌘타 에서 도보로 5 -7 분 집까지, 관광 버스가 수시...  \n",
       "weekly_price                                                                  59123.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a statistical summary for all fields in the collection\n",
    "# Source: Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "#         X. (2025). Grok 3 Beta — The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "\n",
    "# --- Configuration ---\n",
    "# Fields within arrays to analyze individually\n",
    "review_subfields = [\"comments\", \"date\", \"listing_id\", \"reviewer_id\", \"reviewer_name\", \"_id\"]\n",
    "transaction_subfields = [\"date\", \"price\"]\n",
    "amenity_subfield = \"amenities\"                      # The array itself contains the strings\n",
    "verification_subfield = \"host_verifications\"        # The array itself contains the strings\n",
    "\n",
    "# Fields to exclude from the main document analysis (handled separately or irrelevant)\n",
    "exclude_from_main = [\"reviews\", \"transactions\", \"amenities\", \"host_verifications\"]\n",
    "\n",
    "print(\"--- Starting Statistical Summary Generation ---\")\n",
    "\n",
    "# --- 1. Analyze Non-Array Fields ---\n",
    "print(\"Analyzing non-array fields...\")\n",
    "\n",
    "# Get unique top-level and simple nested fields first\n",
    "all_main_fields = set()\n",
    "pipeline_get_main_fields = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "    {\"$unwind\": \"$fields\"},\n",
    "    {\"$match\": {\"fields.k\": {\"$nin\": exclude_from_main}}}, # Exclude array roots\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}\n",
    "]\n",
    "cursor_main_fields = db.listingsAndReviews_HW2.aggregate(pipeline_get_main_fields)\n",
    "for doc in cursor_main_fields:\n",
    "    all_main_fields.add(doc['_id'])\n",
    "\n",
    "# Add known nested fields (adjust as needed based on actual schema)\n",
    "all_main_fields.update([\n",
    "    'address.country', 'address.country_code', 'address.government_area',\n",
    "    'address.location.is_location_exact', 'address.location.type',\n",
    "    'address.market', 'address.street', 'address.suburb',\n",
    "    'availability.availability_30', 'availability.availability_365',\n",
    "    'availability.availability_60', 'availability.availability_90',\n",
    "    'images.picture_url', 'images.thumbnail_url', 'images.medium_url', 'images.xl_picture_url',\n",
    "    'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count' # Keep transaction summaries\n",
    "])\n",
    "# Remove parent keys if sub-keys exist to avoid double counting structure vs values\n",
    "fields_to_remove = {'address', 'availability', 'images', 'address.location', 'transactions'}\n",
    "unique_main_fields = sorted(list(all_main_fields - fields_to_remove))\n",
    "\n",
    "summary_main = {}\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "for field in tqdm(unique_main_fields, desc=\"Processing main fields\"):\n",
    "    # Determine field type from a sample document\n",
    "    sample_doc = db.listingsAndReviews_HW2.find_one({field: {\"$exists\": True}}, {field: 1})\n",
    "    field_type = None\n",
    "    field_value_sample = None\n",
    "    if sample_doc and field:\n",
    "        keys = field.split('.')\n",
    "        val = sample_doc\n",
    "        try:\n",
    "            for key in keys:\n",
    "                val = val[key]\n",
    "            field_value_sample = val\n",
    "            if isinstance(field_value_sample, (int, float, Decimal128)):\n",
    "                field_type = 'numeric'\n",
    "            elif isinstance(field_value_sample, datetime):\n",
    "                field_type = 'date'\n",
    "            elif isinstance(field_value_sample, bool):\n",
    "                field_type = 'boolean'\n",
    "            else:\n",
    "                field_type = 'categorical'\n",
    "        except (KeyError, TypeError):\n",
    "            field_type = 'mixed_or_missing'\n",
    "\n",
    "    group_stage = {\n",
    "        \"_id\": None,\n",
    "        \"Count\": {\"$sum\": 1},\n",
    "        \"DistinctCount\": {\"$addToSet\": f\"${field}\"}\n",
    "    }\n",
    "    if field_type == 'numeric':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "        group_stage[\"AvgValue\"] = {\"$avg\": {\"$convert\": {\"input\": f\"${field}\", \"to\": \"double\", \"onError\": None, \"onNull\": None}}}\n",
    "    elif field_type == 'date':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "    elif field_type == 'boolean':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "    elif field_type == 'categorical':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "\n",
    "    pipeline = [\n",
    "        {\"$match\": {field: {\"$exists\": True, \"$ne\": None}}}, # Ensure field exists and is not null\n",
    "        {\"$group\": group_stage},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"Count\": 1,\n",
    "            \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Mean\": \"$AvgValue\",\n",
    "            \"Min\": \"$MinValue\",\n",
    "            \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        for key in [\"Min\", \"Max\", \"Mean\"]:\n",
    "             if key in stats:\n",
    "                 if isinstance(stats[key], Decimal128):\n",
    "                     stats[key] = float(stats[key].to_decimal())\n",
    "                 if isinstance(stats[key], float):\n",
    "                     stats[key] = round(stats[key], 2)\n",
    "        summary_main[field] = stats\n",
    "    else:\n",
    "        summary_main[field] = {\"Count\": 0, \"DistinctCount\": 0}\n",
    "\n",
    "# --- 2. Analyze 'reviews' Subfields ---\n",
    "print(\"Analyzing 'reviews' subfields...\")\n",
    "summary_reviews = {}\n",
    "pipeline_reviews_base = [\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True}}},  # Filter for docs with reviews array\n",
    "    {\"$unwind\": \"$reviews\"}                      # Unwind the reviews array\n",
    "]\n",
    "\n",
    "# Count total review elements first\n",
    "pipeline_reviews_count = pipeline_reviews_base + [{\"$count\": \"TotalReviews\"}]\n",
    "total_reviews_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_reviews_count))\n",
    "total_reviews = total_reviews_result[0]['TotalReviews'] if total_reviews_result else 0\n",
    "print(f\"Total review elements to analyze: {total_reviews}\")\n",
    "\n",
    "if total_reviews > 0:\n",
    "    for subfield in tqdm(review_subfields, desc=\"Processing review fields\"):\n",
    "        field_path = f\"reviews.{subfield}\" # Path within the unwound document\n",
    "\n",
    "        # Determine type from sample (using the original collection)\n",
    "        sample_review_doc = db.listingsAndReviews_HW2.find_one({\"reviews\": {\"$exists\": True, \"$ne\": []}}, {\"reviews\": {\"$slice\": 1}})\n",
    "        field_type = None\n",
    "        if sample_review_doc and sample_review_doc.get('reviews'):\n",
    "             review_item = sample_review_doc['reviews'][0]\n",
    "             if subfield in review_item:\n",
    "                 field_value_sample = review_item[subfield]\n",
    "                 if isinstance(field_value_sample, (int, float, Decimal128)): field_type = 'numeric'\n",
    "                 elif isinstance(field_value_sample, datetime): field_type = 'date'\n",
    "                 elif isinstance(field_value_sample, bool): field_type = 'boolean'\n",
    "                 else: field_type = 'categorical'\n",
    "\n",
    "        group_stage = {\n",
    "             \"_id\": None,\n",
    "             \"Count\": {\"$sum\": 1}, # Count matching unwound documents\n",
    "             \"DistinctCount\": {\"$addToSet\": f\"${field_path}\"}\n",
    "        }\n",
    "        if field_type == 'date':\n",
    "             group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "             group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "        elif field_type == 'categorical': # Get Min/Max strings\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "\n",
    "        pipeline = pipeline_reviews_base + [\n",
    "             {\"$match\": {field_path: {\"$exists\": True, \"$ne\": None}}}, # Only where subfield exists and is not null\n",
    "             {\"$group\": group_stage},\n",
    "             {\"$project\": {\n",
    "                 \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "                 \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "             }}\n",
    "        ]\n",
    "\n",
    "        result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "        if result:\n",
    "            stats = result[0]\n",
    "            stats[\"TotalElements\"] = total_reviews\n",
    "            # Clean up Min/Max if they weren't added\n",
    "            if \"Min\" not in stats: stats[\"Min\"] = None\n",
    "            if \"Max\" not in stats: stats[\"Max\"] = None\n",
    "            summary_reviews[field_path] = stats\n",
    "        else:\n",
    "            summary_reviews[field_path] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_reviews}\n",
    "\n",
    "# --- 3. Analyze 'transactions.transactions' Subfields ---\n",
    "print(\"Analyzing 'transactions.transactions' subfields...\")\n",
    "summary_tx = {}\n",
    "pipeline_tx_base = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$transactions.transactions\"}\n",
    "]\n",
    "\n",
    "# Count total transaction elements\n",
    "pipeline_tx_count = pipeline_tx_base + [{\"$count\": \"TotalTransactions\"}]\n",
    "total_tx_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_tx_count))\n",
    "total_transactions = total_tx_result[0]['TotalTransactions'] if total_tx_result else 0\n",
    "print(f\"Total transaction elements to analyze: {total_transactions}\")\n",
    "\n",
    "if total_transactions > 0:\n",
    "    for subfield in tqdm(transaction_subfields, desc=\"Processing transaction fields\"):\n",
    "        field_path = f\"transactions.transactions.{subfield}\"\n",
    "\n",
    "        # Determine type from sample\n",
    "        sample_tx_doc = db.listingsAndReviews_HW2.find_one({\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}, {\"transactions.transactions\": {\"$slice\": 1}})\n",
    "        field_type = None\n",
    "        if sample_tx_doc and sample_tx_doc.get('transactions', {}).get('transactions'):\n",
    "             tx_item = sample_tx_doc['transactions']['transactions'][0]\n",
    "             if subfield in tx_item:\n",
    "                 field_value_sample = tx_item[subfield]\n",
    "                 if isinstance(field_value_sample, (int, float, Decimal128)): field_type = 'numeric'\n",
    "                 elif isinstance(field_value_sample, datetime): field_type = 'date'\n",
    "                 else: field_type = 'categorical'\n",
    "\n",
    "        group_stage = {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": f\"${field_path}\"}\n",
    "        }\n",
    "        if field_type == 'numeric':\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "            group_stage[\"AvgValue\"] = {\"$avg\": {\"$convert\": {\"input\": f\"${field_path}\", \"to\": \"double\", \"onError\": None, \"onNull\": None}}}\n",
    "        elif field_type == 'date':\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "\n",
    "        pipeline = pipeline_tx_base + [\n",
    "             {\"$match\": {field_path: {\"$exists\": True, \"$ne\": None}}},\n",
    "             {\"$group\": group_stage},\n",
    "             {\"$project\": {\n",
    "                 \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "                 \"Mean\": \"$AvgValue\", \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "             }}\n",
    "        ]\n",
    "\n",
    "        result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "        if result:\n",
    "            stats = result[0]\n",
    "            stats[\"TotalElements\"] = total_transactions\n",
    "            for key in [\"Min\", \"Max\", \"Mean\"]:\n",
    "                 if key in stats:\n",
    "                     if isinstance(stats[key], Decimal128):\n",
    "                         stats[key] = float(stats[key].to_decimal())\n",
    "                     if isinstance(stats[key], float):\n",
    "                         stats[key] = round(stats[key], 2)\n",
    "            # Clean up missing keys\n",
    "            if \"Min\" not in stats: stats[\"Min\"] = None\n",
    "            if \"Max\" not in stats: stats[\"Max\"] = None\n",
    "            if \"Mean\" not in stats: stats[\"Mean\"] = None\n",
    "            summary_tx[field_path] = stats\n",
    "        else:\n",
    "            summary_tx[field_path] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_transactions}\n",
    "\n",
    "# --- 4. Analyze 'amenities' ---\n",
    "print(\"Analyzing 'amenities'...\")\n",
    "summary_amen = {}\n",
    "pipeline_amen_base = [\n",
    "    {\"$match\": {\"amenities\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$amenities\"}\n",
    "]\n",
    "pipeline_amen_count = pipeline_amen_base + [{\"$count\": \"TotalAmenities\"}]\n",
    "total_amen_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_amen_count))\n",
    "total_amenities = total_amen_result[0]['TotalAmenities'] if total_amen_result else 0\n",
    "print(f\"Total amenity elements to analyze: {total_amenities}\")\n",
    "\n",
    "if total_amenities > 0:\n",
    "    pipeline = pipeline_amen_base + [\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": \"$amenities\"},\n",
    "            \"MinValue\": {\"$min\": \"$amenities\"},\n",
    "            \"MaxValue\": {\"$max\": \"$amenities\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        stats[\"TotalElements\"] = total_amenities\n",
    "        summary_amen[\"amenities\"] = stats\n",
    "    else:\n",
    "        summary_amen[\"amenities\"] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_amenities}\n",
    "\n",
    "# --- 5. Analyze 'host_verifications' ---\n",
    "print(\"Analyzing 'host_verifications'...\")\n",
    "summary_verif = {}\n",
    "pipeline_verif_base = [\n",
    "    {\"$match\": {\"host_verifications\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$host_verifications\"}\n",
    "]\n",
    "pipeline_verif_count = pipeline_verif_base + [{\"$count\": \"TotalVerifications\"}]\n",
    "total_verif_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_verif_count))\n",
    "total_verifications = total_verif_result[0]['TotalVerifications'] if total_verif_result else 0\n",
    "print(f\"Total verification elements to analyze: {total_verifications}\")\n",
    "\n",
    "if total_verifications > 0:\n",
    "    pipeline = pipeline_verif_base + [\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": \"$host_verifications\"},\n",
    "            \"MinValue\": {\"$min\": \"$host_verifications\"},\n",
    "            \"MaxValue\": {\"$max\": \"$host_verifications\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        stats[\"TotalElements\"] = total_verifications\n",
    "        summary_verif[\"host_verifications\"] = stats\n",
    "    else:\n",
    "        summary_verif[\"host_verifications\"] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_verifications}\n",
    "\n",
    "# --- 6. Combine and Create Final DataFrame ---\n",
    "summary_combined = {**summary_main, **summary_reviews, **summary_tx, **summary_amen, **summary_verif}\n",
    "\n",
    "df_data_combined = []\n",
    "for field, stats in summary_combined.items():\n",
    "    df_data_combined.append({\n",
    "        \"field\": field,\n",
    "        \"Count\": stats.get(\"Count\", 0),\n",
    "        \"Distinct Count\": stats.get(\"DistinctCount\", 0),\n",
    "        \"Mean\": stats.get(\"Mean\", '-'),\n",
    "        \"Min\": stats.get(\"Min\", '-'),\n",
    "        \"Max\": stats.get(\"Max\", '-')\n",
    "    })\n",
    "\n",
    "df_stats_final = pd.DataFrame(df_data_combined)\n",
    "df_stats_final.set_index(\"field\", inplace=True)\n",
    "df_stats_final.sort_index(inplace=True)\n",
    "df_stats_final.fillna('-', inplace=True)\n",
    "\n",
    "print(\"\\n--- Final Statistical Summary (Original Collection) ---\")\n",
    "print(\"Total fields:\", len(df_stats_final))\n",
    "df_stats_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Analysing the results**\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "The table above provides a statistical summary of the fields in the collection `listingsAndReviews_HW2` including the count of documents, distinct values, mean, minimum, and maximum values for each field.\n",
    "- From the analysis, we can verify that most fields are consistent with our expectations, with the exception of a few fields: `maximum_nights`, `bathrooms`, `bedrooms`, and `price.`\n",
    "\n",
    "<br>\n",
    "\n",
    "**`maximum_nights`**\n",
    "\n",
    "- As shown in the results above, the maximum value for the field **`maximum_nights` is extremely high** — specifically, $2\\;147\\;483\\;647$. While we know with certainty that no guest will ever book a stay for this many nights, this value appears in the dataset.\n",
    "  - After reviewing Airbnb’s official guidelines (**Source:** https://www.airbnb.pt/help/article/880?), it is confirmed that hosts have full freedom to define any number for the `maximum_nights` field. Therefore, such high values are permitted by Airbnb.\n",
    "  - It is likely that some hosts intentionally set extremely high values to signal that there is effectively no maximum stay limit. These values, although unusually large, are still valid in the context of Airbnb’s platform.\n",
    "  - While these values are valid, in a different context — such as modeling guest behavior or predicting average stay length — they could be treated as statistical outliers. However, since that is not the goal of our current work, we will not perform any data cleaning or transformation for these records.\n",
    "\n",
    "**`bathrooms`**\n",
    "\n",
    "- As shown in the results above, the minimum value for the field **`bathrooms`** is $0$. In some cases this value makes total sense (**Source:** https://community.withairbnb.com/t5/Advice-on-your-space/bathroom-classification/m-p/1652130) while in others it doesn't. \n",
    "   - Properties with types like ***Camper/RV***, ***Tent*** and ***Shared Room*** may not have private bathrooms indicating that the value $0$ makes sense. On the other hand property types like ***Apartment*** and House are unlikely to have $0$ bathrooms.\n",
    "\n",
    "**`bedrooms`**\n",
    "\n",
    "- As shown in the results above, the minimum value for the field **`bedrooms`** is $0$. \n",
    "  - For properties with types like ***Apartment*** that are **Studios** or **Lofts** this value makes sense potentially reflecting that they share a single open space. \n",
    "  - On the other hand property types like ***House*** are unlikely to have **$0$ bedrooms**.\n",
    "\n",
    "**`price`**\n",
    "\n",
    "- As shown in the results above, the maximum value for the field **`price`** is $48\\;842.0$. The field price indicates the price per night for a listing.\n",
    "  - This value is extremely high and seems unrealistic for a single night stay. \n",
    "  - It is possible that this value is a result of data entry errors or outliers in the dataset.\n",
    "  - To further investigate, we can check the distribution of prices and identify any potential outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`maximum_nights`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with _id: 10911771 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/52473150\n",
      "Document with _id: 19550563 has maximum_nights: 1234567890           | Host URL: https://www.airbnb.com/users/show/137344895\n",
      "Document with _id: 6357527 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/18762837\n",
      "Document with _id: 744242 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/4334558\n"
     ]
    }
   ],
   "source": [
    "# Check cases with 'maximum_nights' more that 1 000 000\n",
    "large_maximum_nights = db.listingsAndReviews_HW2.find({\"maximum_nights\": {\"$gt\": 1_000_000}})\n",
    "for doc in large_maximum_nights:\n",
    "    print(f\"Document with _id: {doc['_id']} has maximum_nights: {doc['maximum_nights']:<20} | Host URL: {doc['host_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`bathrooms`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of listings where number of bathrooms is 0\n",
    "db.listingsAndReviews_HW2.count_documents({\"bathrooms\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a total of $14$ listings with $0$ `bathrooms`. We will investigate the property types of these listings to see if they are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/6250742'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/27201583'}\n",
      "{'property_type': 'Hostel', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/30098437'}\n",
      "{'property_type': 'Camper/RV', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/36714324'}\n",
      "{'property_type': 'Serviced apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/14861546'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/51198195'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/219415974'}\n",
      "{'property_type': 'Bed and breakfast', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/98135964'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/221016656'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/226980154'}\n",
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/283136'}\n",
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/34682013'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/494228'}\n",
      "{'property_type': 'Serviced apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/38468501'}\n"
     ]
    }
   ],
   "source": [
    "# Check cases with 'bathrooms' = 0\n",
    "cursor = db.listingsAndReviews_HW2.find({\"bathrooms\": 0}, projection={\"_id\": 0, \"bathrooms\": 1, \"property_type\": 1, \"host_url\":1})\n",
    "for doc in cursor:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can from the results above, there are some listings with $0$ `bathrooms` with property types that do not make sense (e.g ***House***, ***Apartment***, etc.).\n",
    "  - To further investigate, we would need more information about each listings, access to the databases's metadata and to the host_url (links to the listings don't seem to work).\n",
    "  - Hence no changes will be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`bedrooms`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count listings with 0 bedrooms\n",
    "db.listingsAndReviews_HW2.count_documents({\"bedrooms\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see there a total of $496$ listings with $0$ `bedrooms`.\n",
    "    - As they represent almost $10\\%$ of total listings we will analyse the distribution of property types with $0$ `bedrooms` to understand which are correctly described with $0$ `bedrooms` and which aren't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment: 305\n",
      "Condominium: 52\n",
      "Loft: 33\n",
      "Serviced apartment: 25\n",
      "House: 19\n",
      "Guest suite: 14\n",
      "Guesthouse: 9\n",
      "Bed and breakfast: 6\n",
      "Boutique hotel: 5\n",
      "Other: 4\n",
      "Cabin: 3\n",
      "Townhouse: 3\n",
      "Hostel: 3\n",
      "Cottage: 3\n",
      "Tiny house: 2\n",
      "Camper/RV: 2\n",
      "Bungalow: 2\n",
      "Resort: 1\n",
      "Aparthotel: 1\n",
      "Pension (South Korea): 1\n",
      "Hotel: 1\n",
      "Farm stay: 1\n",
      "Casa particular (Cuba): 1\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of property types with 0 bedrooms\n",
    "pipeline = [\n",
    "    {\"$match\": {\"bedrooms\": 0}},\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$property_type\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$sort\": {\"count\": -1}}  \n",
    "]\n",
    "\n",
    "results = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "for doc in results:\n",
    "    print(f\"{doc['_id']}: {doc['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can from the results above, there are some listings with $0$ `bedrooms` with property types that do not make sense (e.g ***House*** etc.).\n",
    "  - As explained in the case of bathrooms, to further investigate these cases, we would need more information about each listings, access to the databases's metadata and to the **`host_url`** (links to the listings don't seem to work).\n",
    "  - Hence no changes will be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`price`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'property_type': 'Apartment', 'price': Decimal128('48842.00'), 'host_url': 'https://www.airbnb.com/users/show/118695718'}\n"
     ]
    }
   ],
   "source": [
    "# Find prperties that have a price equal to 48842.0 and project _id, property_type, price and host_url\n",
    "cursor = db.listingsAndReviews_HW2.find({\"price\": 48842.0}, projection={\"_id\": 0, \"property_type\": 1, \"price\": 1, \"host_url\":1})\n",
    "for doc in cursor:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range: 0-100, Count: 2181, Average Price: 59.24\n",
      "Price Range: 101-500, Count: 2627, Average Price: 213.11\n",
      "Price Range: 501-1000, Count: 528, Average Price: 686.03\n",
      "Price Range: 1001-5000, Count: 207, Average Price: 1724.65\n",
      "Price Range: 5001-10000, Count: 6, Average Price: 6149.83\n",
      "Price Range: 10001-20000, Count: 5, Average Price: 10910.80\n",
      "Price Range: 20001-50000, Count: 1, Average Price: 48842.00\n"
     ]
    }
   ],
   "source": [
    "# Distribution of prices across multiple price ranges (bins)\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/bucket/\n",
    "\n",
    "bins = [0, 100, 500, 1000, 5000, 10000, 20000, 50000]\n",
    "labels = [\"0-100\", \"101-500\", \"501-1000\", \"1001-5000\", \"5001-10000\", \"10001-20000\", \"20001-50000\"]\n",
    "pipeline = [\n",
    "    {\"$bucket\": {\n",
    "        \"groupBy\": \"$price\",\n",
    "        \"boundaries\": bins,\n",
    "        \"default\": \"50001+\",  # Default bucket for values above the last boundary\n",
    "        \"output\": {\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"average_price\": {\"$avg\": \"$price\"}\n",
    "        }\n",
    "    }}\n",
    "]\n",
    "results = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "for doc in results:\n",
    "    if doc['_id'] == \"50001+\":  # Handle the default bucket\n",
    "        price_range = \"50001+\"\n",
    "    else:\n",
    "        # Map the bucket index to the corresponding label\n",
    "        index = bins.index(doc['_id'])\n",
    "        price_range = labels[index]\n",
    "    \n",
    "    avg_price = float(str(doc['average_price']))  # Convert Decimal128 to string, then to float\n",
    "    print(f\"Price Range: {price_range}, Count: {doc['count']}, Average Price: {avg_price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the results above, we can see that we only have $6$ listings with `price` over $10\\;000$ *per night*\n",
    "  - These most likely correspond to outliers or luxury listings.\n",
    "  - Since we lack the metadata, working `host_url` links to these properties to determine if they are valid, **we will not remove them**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`review_scores_rating`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '10006546', 'review_scores_rating': 89},\n",
       " {'_id': '1001265', 'review_scores_rating': 84},\n",
       " {'_id': '10021707', 'review_scores_rating': 100},\n",
       " {'_id': '1003530', 'review_scores_rating': 94},\n",
       " {'_id': '10038496', 'review_scores_rating': 98},\n",
       " {'_id': '10047964', 'review_scores_rating': 100},\n",
       " {'_id': '10051164', 'review_scores_rating': 80},\n",
       " {'_id': '10057826', 'review_scores_rating': 88},\n",
       " {'_id': '10059872', 'review_scores_rating': 100},\n",
       " {'_id': '10083468', 'review_scores_rating': 97}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all cases with 'review_scores_rating' more that 10\n",
    "list(db.listingsAndReviews_HW2.find({'review_scores_rating': {\"$gt\": 10}},      # Query to find documents with 'review_scores_rating' > 10\n",
    "                                    {'_id': 1, 'review_scores_rating': 1})      # Projection to include only '_id' and 'review_scores_rating'\n",
    "     )[:10]  # Display first 10 documents with 'review_scores_rating' > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of documents with 'review_scores_rating' greater than 10:\u001b[0m 4081\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1mNumber of documents with 'review_scores_rating' greater than 10:\\033[0m {len(list(db.listingsAndReviews_HW2.find({'review_scores_rating': {'$gt': 10}})))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize 'review_scores_rating' to be between 0 and 10\n",
    "# We consider that the range of all values is between 0 and 100, so we divide by 10 to normalize the values\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/divide/\n",
    "    [{\"$set\": {\"review_scores_rating\": {\"$divide\": [\"$review_scores_rating\", 10]}}}]\n",
    ")\n",
    "\n",
    "# Check all cases with 'review_scores_rating' more that 10\n",
    "list(db.listingsAndReviews_HW2.find({'review_scores_rating': {\"$gt\": 10}}, {'_id': 1, 'review_scores_rating': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'review_scores_rating': [{'BSONType': 'double'}, {'BSONType': 'null'}]\n"
     ]
    }
   ],
   "source": [
    "# Check if 'review_scores_rating' is decimal after teh change\n",
    "review_scores_rating_type = db.listingsAndReviews_HW2.aggregate([\n",
    "    # Only consider documents where the field exists\n",
    "    {\"$match\": {\"review_scores_rating\": {\"$exists\": True}}},\n",
    "    \n",
    "    # Group by the BSON type of the field\n",
    "    {\"$group\": {\"_id\": {\"$type\": \"$review_scores_rating\"}}},\n",
    "    \n",
    "    # Project the type name \n",
    "    {\"$project\": {\"_id\": 0, \"BSONType\": \"$_id\"}}\n",
    "])\n",
    "print(f\"Data type of 'review_scores_rating': {list(review_scores_rating_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `review_scores_rating` field shows values up to 100, while other `review_scores_*` fields (checkin, cleanliness, etc.) are consistently between 0-10. This suggests `review_scores_rating` uses a different scale (0-100).\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data normalization** to the `review_scores_rating` field by dividing its value by $10$, because its range ($0-100$) was inconsistent with other review scores ($0-10$). Unlike the other scores, this one will be kept in decimal format after normalization, in order to preserve more detailed information. We expect **consistent scaling across all review score metrics**, enabling meaningful calculation of averages (as required in **Q9**).\n",
    "\n",
    "The verification query confirms that no `review_scores_rating` values are now greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents found with last_scraped < last_review.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'last_scraped' < 'last_review' (Invalid data)\n",
    "invalid_dates = db.listingsAndReviews_HW2.find({\n",
    "    \"$expr\": {\n",
    "        \"$lt\": [\"$last_scraped\", \"$last_review\"]\n",
    "    }\n",
    "})\n",
    "if len(list(invalid_dates)) >  0:\n",
    "    for doc in invalid_dates:\n",
    "        print(f\"Document with _id: {doc['_id']} has last_scraped: {doc['last_scraped']} < last_review: {doc['last_review']}\")\n",
    "else:\n",
    "    print(\"No documents found with last_scraped < last_review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents found with first_review > last_review.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'first_review' > 'last_review' (Invalid data)\n",
    "invalid_dates = db.listingsAndReviews_HW2.find({\n",
    "    \"$expr\": {\n",
    "        \"$gt\": [\"$first_review\", \"$last_review\"]\n",
    "    }\n",
    "})\n",
    "if len(list(invalid_dates)) > 0:\n",
    "    for doc in invalid_dates:\n",
    "        print(f\"Document with _id: {doc['_id']} has first_review: {doc['first_review']} > last_review: {doc['last_review']}\")\n",
    "else:\n",
    "    print(\"No documents found with first_review > last_review.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **📚 1.5 | Data Model Adjustments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three stage approach for data model and final schema design**\n",
    "\n",
    "1. Workload stage\n",
    "2. Relationship assessment\n",
    "3. Patterns\n",
    "\n",
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- Data Model Design Process  -->\n",
    "    <img src=\"./img/DataModels&Schema.png\" height=\"400\" alt=\"Data Model Design Process\" />\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "Based on the **Workload**, **Relationships**, and **Patterns** analysis, we will now implement the new schema design by creating separate collections for `Hosts`, `Reviews`, and `Transactions`, and restructuring the `Listings` collection.\n",
    "\n",
    "**Overall Strategy:** Move large, unbounded, or independently accessed data (**reviews**, **host details**, **transactions**) out of the main listing document into their own collections, using references (`Host_ID`, `Listing_ID`, `Reviewer_ID`) to link them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Workload Stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal documents in the collection 'listingsAndReviews_HW2':\u001b[0m 5555\n",
      "\u001b[1mTotal size of the collection 'listingsAndReviews_HW2':\u001b[0m      108212716 bytes (0.101 GB)\n"
     ]
    }
   ],
   "source": [
    "# Determine total number of documents and total size\n",
    "total_documents = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "stats = db.listingsAndReviews_HW2.database.command(\"collstats\", db.listingsAndReviews_HW2.name)\n",
    "total_size = stats[\"size\"]  # Total document data size in bytes\n",
    "total_size_gb = total_size / (1024 ** 3)\n",
    "\n",
    "print(f\"\\033[1mTotal documents in the collection 'listingsAndReviews_HW2':\\033[0m {total_documents}\")\n",
    "print(f\"\\033[1mTotal size of the collection 'listingsAndReviews_HW2':\\033[0m      {total_size} bytes ({total_size_gb:.3f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **🧠 Workload Stage Summary**\n",
    "\n",
    "<center>\n",
    "\n",
    "| # | Step / Question | What it Entails | Entities Involved | Possible Next Steps |\n",
    "|---|------------------|------------------|--------------------|----------------------|\n",
    "| **1** | **Assess Data Size** | Determine current collection volume and size | `listingsAndReviews_HW2` | - 5,555 documents<br>- Use `collstats` for total size (in GB)<br>- Check average document size |\n",
    "| **2a** | **Most Common Use Case** | Show property info to customers (title, price, photos, short description, sample reviews) | `Listings`, `Reviews` | - Optimize listing document for fast reads<br>- Move heavy data (e.g., full reviews, transactions) to separate collections<br>- Use **Subset pattern** for a few recent reviews |\n",
    "| **2b (Q7)** | Unique amenities list for host registration | Show all **unique amenities** from listings; rarely changes | `Listings`, `Amenities` | - Extract distinct amenities<br>- Store in a static `Amenities` collection <br>- Index `amenities` if queried live |\n",
    "| **2c (Q8)** | Top 20 reviewers and fast review count lookup | Rank reviewers and return count of reviews per reviewer | `Reviews`, `Reviewers` | - Create `Reviewers` collection with review count<br>- Index `reviewer_id` and `name`<br>- Keep updated with new reviews |\n",
    "| **2d (Q9)** | Average of review scores (supporting dynamic metric fields) | Compute average across all review metrics | `Listings`, `review_scores` | - Use key-value structure<br>- Query using `$objectToArray`<br>- Allow flexibility for new fields |\n",
    "| **2e (Q10)** | Avg transaction value per property for time period | Time-based aggregation on transactions | `Transactions`, `Listings` | - Create a `Transactions` collection<br>- Index `listing_id` and `date`<br>- Query using `$match` + `$group` |\n",
    "| **2f (Q11)** | Summary page of top 10 cities + top listings per city | Show city-level stats and example listings | `Listings`, `Reviews`, `CitySummary` | - Use aggregation to generate stats<br>- Optionally store results in a `CitySummary` collection<br>- Keep up to date with listing changes |\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** All the operations that we will do are mostly *reads*, but in real-world cenarios, ***AirBnB*** would have to do a lot of *writes* as well. So, we will try to optimize the database for both reads and writes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Relationships Assessment Stage**\n",
    "\n",
    "1. Identify which entities are related\n",
    "2. Measure quantity of related data (**1:1**, **1:N**, **N:N**)\n",
    "3. Decide whether to embed data or reference  it\n",
    "    - Embed for fast reads & tightly coupled data\n",
    "    - Reference for flexibility & loosely coupled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **🔗 Relationships Phase Table (with Correct Embed/Reference Direction)**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Entities** | **Relationship Type** | **Cardinality** | **Embed or Reference?** | **Reasoning** | **Context in Project** |\n",
    "|--------------|------------------------|------------------|--------------------------|----------------|--------------------------|\n",
    "| `Listing` ↔ `Host` | Listing has one Host | 1:1 or 1:N | **Reference `Host` in `Listing`** | Avoid duplication across listings; host info may be reused and updated | All queries involving listing display (**Q1**, **Q11**) |\n",
    "| `Listing` ↔ `Review` | Listing has many Reviews | 1:N | **Reference `Reviews` in `Listing`** | Reviews grow over time; referencing avoids bloating the listing document | **Q1** (optimize listing), **Q8** (track reviewers), **Q9** (review scores) |\n",
    "| `Review` ↔ `Reviewer` | Review written by one Reviewer | N:1 | **Reference `Reviewer` in `Review`** | Reviewers write multiple reviews; useful for tracking top reviewers | **Q8** (top reviewers) |\n",
    "| `Listing` ↔ `Transaction` | Listing has many Transactions | 1:N | **Reference `Transactions` in `Listing`** | Transactions are time-series data, accessed separately | **Q10** (avg transaction value over time) |\n",
    "| `Listing` ↔ `Amenities` | Listing has many amenities | 1:N | **Embed `Amenities` in `Listing`** | Small, static data; fast access during listing reads | **Q7** (suggested amenities for hosts), **Q1** |\n",
    "| `City` ↔ `Listing` | City has many listings | 1:N | **Reference `Listing` in `City`** | Used for aggregations; typically based on `address.market` | **Q11** (summary of top cities and listings) |\n",
    "| `Listing` ↔ `Review Scores` | Listing has one set of review scores | 1:1 | **Embed `Review Scores` in `Listing`** | Small, always needed in listing view; quick access | **Q9** (average score across dynamic metrics), **Q1** |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Patterns Phase**\n",
    "\n",
    "1. Recognize common access or structure patterns in data\n",
    "2. Apply modeling patterns (e.g., bucket, subset, outlier) to optimize for performance, scalability, and simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **✅ Patterns Phase Table**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Use Case / Entity** | **Recognized Access Pattern** | **Applied Pattern (Allowed)** | **Why This Pattern?** | **Context in Project** |\n",
    "|------------------------|-------------------------------|-------------------------------|------------------------|-------------------------|\n",
    "| **Customer views a listing (main use case)** | Needs fast access to main listing info with recent reviews | **Subset Pattern** (keep top 5 reviews) | Embed a few recent reviews; keeps listing lean and fast | **Q1** (Main use case for browsing listings) |\n",
    "| **Full review history** | Large volume, rarely read fully | **Outlier Pattern** | Separate heavy review arrays into another collection to improve performance | **Q1**, **Q8**, **Q9** |\n",
    "| **Host registration: show common amenities** | Read-heavy, rarely changing | **Computed Pattern** | Precompute distinct amenities once and store them; avoids repetitive scans | **Q7** |\n",
    "| **Track top 20 reviewers + review count** | Aggregate reviews per reviewer | **Computed Pattern** | Maintain review counts in a separate `Reviewers` collection for fast access | **Q8** |\n",
    "| **Dynamic review metrics per listing** | New fields may be added without fixed schema | **Attribute Pattern** | Store review scores as key-value fields to support flexible querying | **Q9** |\n",
    "| **Transactions per listing over time** | Time-based reads (e.g., avg per month) | **Bucket Pattern** | Store and query transactions in monthly buckets for efficient time-series analysis | **Q10** |\n",
    "| **Summary of top 10 cities and listings** | Repeated aggregated reads across listings and cities | **Computed Pattern** | Store precomputed city-level summaries and examples for performance | **Q11** |\n",
    "\n",
    "</center>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "# **CONFIRMAR TABELAS TODAS**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Final Schema Design**\n",
    "\n",
    "##### **1. List of All Collections Required**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Collection Name**        | **Purpose** |\n",
    "|----------------------------|-------------|\n",
    "| `Listings`                 | Core listing info (`title`, `price`, `amenities`, `review scores`, etc.) |\n",
    "| `Reviews`                  | Full detailed reviews (stored separately from listings) |\n",
    "| `Reviewers`                | Reviewer profiles with review count (precomputed) |\n",
    "| `Transactions`             | Time-series financial transactions related to listings |\n",
    "| `Hosts`                    | Host information referenced by listings |\n",
    "| `CitySummary` (Optional)   | Precomputed metrics for top 10 cities (for summary dashboard) |\n",
    "| `Amenities` (Optional)     | List of unique amenities (for host registration) |\n",
    "\n",
    "</center>\n",
    "\n",
    "##### **2. How Collections Are Connected**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **From Entity** | **To Entity** | **Relationship** | **Why** | \n",
    "|------------------|---------------|------------------|----------------------|\n",
    "| `Listings` → `Hosts` | N:1 | **Reference** | Avoid host duplication; allows host reuse and updates \n",
    "| `Listings` → `Reviews` | 1:N | **Reference** | Reviews can be large and grow over time; keeps listing document light \n",
    "| `Reviews` → `Reviewers` | N:1 | **Reference** | One reviewer can write many reviews; enables reviewer-level tracking \n",
    "| `Listings` → `Transactions` | 1:N | **Reference** | Time-series data; best stored and queried separately \n",
    "| `Listings` → `Review Scores` | 1:1 | **Embed** | Review scores are small and always needed when displaying listings\n",
    "| `Listings` → `Amenities` | 1:N | **Embed** | Amenities are small, static, and always needed when displaying listings \n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "##### **3. Overview**\n",
    "\n",
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- Final Schema Design  -->\n",
    "    <img src=\"./img/FinalSchemaDesign.png\" with=\"400\" alt=\"Final Schema Design\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Justification for Schema Changes & Pattern Application**\n",
    "\n",
    "The original schema suffered from embedding large, potentially unbounded arrays (`reviews`, `transactions`) and duplicating data (`host` information, `reviews_copy*`), leading to performance issues. Our redesigned schema addresses this by:\n",
    "\n",
    "1.  **Creating Separate Collections:**\n",
    "    *   **`Hosts`:** Normalizes host data, avoiding repetition. Each listing references its host via `Host_ID`. *Pattern:* **Normalization**.\n",
    "    *   **`Reviews`:** Stores all reviews separately. Each review references its `Listing_ID` and `Reviewer_ID`. *Pattern:* **Outlier Pattern** (moving large embedded array), **Reference Pattern**.\n",
    "    *   **`Reviewers`:** Stores unique reviewer information. Each reviewer references the reviews they wrote. *Pattern:* **Normalization**, **Reference Pattern**. *Potential:* Could use **Computed Pattern** to store `ReviewCount` here for Q8, but current implementation calculates it on the fly.\n",
    "    *   **`Transactions`:** Stores individual transactions. Each transaction references its `Listing_ID`. *Pattern:* **Outlier Pattern**, **Reference Pattern**. This moves *away* from the original implicit **Bucket Pattern** to allow finer-grained queries (Q10).\n",
    "\n",
    "2.  **Refining the `Listings` Collection:**\n",
    "    *   Keeps core, frequently accessed listing details embedded (name, price, address, availability, etc.). *Pattern:* **Embedding**.\n",
    "    *   Embeds `Amenities` as it's a relatively small, bounded array often needed with the listing. *Pattern:* **Embedding**.\n",
    "    *   Restructures `review_scores_*` into a `Review_Scores` subdocument. *Pattern:* **Attribute Pattern** (allows adding new score types without changing average calculation query - Q9).\n",
    "    *   Retains summary transaction info (`bucket_start_date`, `bucket_end_date`, `transaction_count`) but removes the detailed `transactions` array. *Pattern:* **Subset Pattern** (keeping summary, referencing details).\n",
    "    *   References `Host_ID`.\n",
    "\n",
    "3.  **Optimizing for Specific Use Cases:**\n",
    "    *   **`Amenities` Collection (for Q7):** Stores unique amenities. *Pattern:* **Computed Pattern** (pre-calculating distinct values for fast lookup).\n",
    "    *   **`CitySummary` Collection (Optional, for Q11):** Stores pre-aggregated city data. *Pattern:* **Computed Pattern** (for dashboard performance).\n",
    "\n",
    "<br>\n",
    "\n",
    "*   **Expected Results:**\n",
    "    *   **Improved Read Performance (Q1):** Smaller `Listings` documents load faster.\n",
    "    *   **Scalability:** `Reviews` and `Transactions` can grow independently without impacting `Listings` performance.\n",
    "    *   **Data Integrity:** Host updates only need to occur in the `Hosts` collection.\n",
    "    *   **Efficient Queries:** Specific queries (like Q7, Q8, Q10, Q11) benefit from dedicated collections, appropriate indexing, and computed/subset patterns. Lookups introduce some overhead for cross-collection queries (like Q4), but indexing mitigates this, and the benefits of normalization often outweigh this cost for overall maintainability and read performance on the primary `Listings` collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop new collections if they exist to start fresh\n",
    "db.drop_collection(\"Listings\")\n",
    "db.drop_collection(\"Reviews\")\n",
    "db.drop_collection(\"Reviewers\")\n",
    "db.drop_collection(\"Transactions\")\n",
    "db.drop_collection(\"Hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Reviews` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '1022200',\n",
      " 'reviews': [{'_id': '277195899',\n",
      "              'date': datetime.datetime(2018, 6, 15, 4, 0),\n",
      "              'listing_id': '1022200',\n",
      "              'reviewer_id': '710109',\n",
      "              'reviewer_name': 'Sylvia',\n",
      "              'comments': 'Great location and lovely facility overall.  A '\n",
      "                          'great deal!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Print one example document of 'reviews' array\n",
    "pprint(db.listingsAndReviews_HW2.find_one({\"_id\": \"1022200\"}, {\"reviews\": 1}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x233474d6600>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create Reviews collection\n",
    "reviews_fields = [\"_id\", \"reviews\"]\n",
    "\n",
    "# Aggregate to extract reviews and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$unwind\": \"$reviews\"},                                                        # Unwind the 'reviews' array to create a document for each review\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                   # Will create a ObjectId for each review\n",
    "        \"Listing_ID\": \"$_id\",                                                       # Include the listing ID\n",
    "        \"Review_ID\": \"$reviews._id\",                                                # Include the review ID\n",
    "        \"Review_Comments\": \"$reviews.comments\",                                     # Include the review comments\n",
    "        \"Review_Date\": \"$reviews.date\",                                             # Include the review date\n",
    "        \"Reviewer_ID\": \"$reviews.reviewer_id\",                                      # Include the reviewer ID\n",
    "    }},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Reviews\"}                                                             # Output directly to 'Reviews' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Reviews' collection:\u001b[0m 149792\n",
      "\u001b[1mSample document from 'Reviews' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fcea5c4f6288c2cac4e62d'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Review_ID': '58663741',\n",
      " 'Review_Comments': 'A casa da Ana e do Gonçalo foram o local escolhido para a '\n",
      "                    'passagem de ano com um grupo de amigos. Fomos super bem '\n",
      "                    'recebidos com uma grande simpatia e predisposição a '\n",
      "                    'ajudar com qualquer coisa que fosse necessário.\\r\\n'\n",
      "                    'A casa era ainda melhor do que parecia nas fotos, '\n",
      "                    'totalmente equipada, com mantas, aquecedor e tudo o que '\n",
      "                    'pudessemos precisar.\\r\\n'\n",
      "                    'A localização não podia ser melhor! Não há melhor do que '\n",
      "                    'acordar de manhã e ao virar da esquina estar a ribeira do '\n",
      "                    'Porto.',\n",
      " 'Review_Date': datetime.datetime(2016, 1, 3, 5, 0),\n",
      " 'Reviewer_ID': '51483096'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Reviews collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Reviews' collection:\\033[0m {db.Reviews.count_documents({})  }\")   # Count the number of documents in the Reviews collection\n",
    "print(f\"\\033[1mSample document from 'Reviews' collection:\\033[0m\")\n",
    "pprint(db.Reviews.find_one(), sort_dicts=False)                                                             # Print one example document from the Reviews collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied the **Outlier Pattern** and **Referencing** by creating a separate `Reviews` collection. This addresses the issue of the potentially large and unbounded `reviews` array embedded within the original listing documents, which negatively impacted performance. We expect **smaller, faster-loading listing documents**, **improved scalability** as reviews can grow independently, and **efficient querying of reviews** using the indexed `Listing_ID` and `Review_ID` fields. Each document in this collection represents a single review and links back to its corresponding listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Review.Listing_ID and Review.Review_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Reviews.create_index([(\"Listing_ID\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Review_ID_1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Reviews.create_index([(\"Review_ID\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Reviewers` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop_collection(\"Reviewers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2334ce61970>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create Reviewers collection\n",
    "reviewers_fields = [\"_id\", \"reviews.reviewer_id\", \"reviews.reviewer_name\"]\n",
    "\n",
    "# Aggregate to extract unique reviewers and their corresponding review IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$unwind\": \"$reviews\"},                                        # Unwind the 'reviews' array to create a document for each review\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$reviews.reviewer_id\",                              # Group by reviewer ID\n",
    "        \"Reviewer_Name\": {\"$first\": \"$reviews.reviewer_name\"},      # Take the first name (assumes consistency)\n",
    "    }},\n",
    "    {\"$project\": {\n",
    "        \"_id\": \"$_id\",                                              # Use Reviewer_ID as the document _id (not an ObjectId)\n",
    "        \"Reviewer_ID\": \"$_id\",                                      # Include reviewer ID\n",
    "        \"Reviewer_Name\": 1,                                         # Include reviewer name\n",
    "        # \"Reviews_Count\"                                           # Computed Pattern that will be create in Q8\n",
    "    }},\n",
    "    # Output directly to 'Reviewers' collection\n",
    "    {\"$out\": \"Reviewers\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Reviewers' collection:\u001b[0m 146640\n",
      "\u001b[1mSample document from 'Reviewers' collection:\u001b[0m\n",
      "{'_id': '170827308', 'Reviewer_Name': 'Mitchell', 'Reviewer_ID': '170827308'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Reviewers collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Reviewers' collection:\\033[0m {db.Reviewers.count_documents({})}\")        # Count the number of documents in the Reviewers collection\n",
    "print(f\"\\033[1mSample document from 'Reviewers' collection:\\033[0m\")\n",
    "pprint(db.Reviewers.find_one(), sort_dicts=False)                                                                  # Print one example document from the Reviewers collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Normalization/Referencing** by creating a separate `Reviewers` collection. This addresses the need to efficiently track reviewers and their activity (**Q8**) without duplicating reviewer names across potentially numerous reviews in the main `Reviews` collection. Each document in `Reviewers` represents a unique reviewer, identified by `Reviewer_ID`. We expect **improved data consistency** (reviewer names stored once) and **efficient lookups for reviewer-specific information**, especially when combined with the `Reviewer_ID` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reviewer_ID_1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Reviewers.Reviewer_ID and Reviews.Reviewer_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Reviewers.create_index([(\"Reviewer_ID\")])                                        # Create index on Reviewer_ID field in Reviewers collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reviewer_ID_1'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Reviews.create_index([(\"Reviewer_ID\")])                                          # Create index on Reviewer_ID field in Reviews collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Hosts` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found \u001b[1m17 host_* fields\u001b[0m: \n",
      "\n",
      "['_id',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create Hosts collection\n",
    "# Extract all fields with \"host_\" prefix\n",
    "host_fields = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},             # Convert document to key-value pairs\n",
    "    {\"$unwind\": \"$fields\"},                                             # Flatten the fields array\n",
    "    {\"$match\": {\"fields.k\": {\"$regex\": \"^host_\"}}},                     # Match fields starting with 'host_'\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}},                                   # Group by field names to get distinct fields\n",
    "])\n",
    "\n",
    "# Convert the aggregation result to a list with only field names\n",
    "host_fields = sorted([doc[\"_id\"] for doc in host_fields])\n",
    "\n",
    "# Add \"_id\" field to host_fields in first position\n",
    "host_fields.insert(0, \"_id\")  # Add \"_id\" field to the beginning of the list\n",
    "\n",
    "# Print the list of host fields\n",
    "print(f\"Found \\033[1m{len(host_fields)} host_* fields\\033[0m: \\n\")\n",
    "pprint(host_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2334c8f88f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Aggregate to extract hosts and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    \n",
    "    # Group documents by host ID to create a document for each host\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$host_id\",                                                         # Group by host ID\n",
    "        \"host_fields\": {\"$first\": \"$$ROOT\"},                                       # Keep the entire document\n",
    "    }},\n",
    "    \n",
    "    # Project the desired fields into the new Hosts collection    \n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                              # Will create a ObjectId for each host\n",
    "        \"Host_ID\": \"$host_fields.host_id\",                                                     # Include the host ID\n",
    "        \"Host_Name\": \"$host_fields.host_name\",                                                 # Include the host name\n",
    "        \"Host_About\": \"$host_fields.host_about\",                                               # Include the host about\n",
    "        \"Host_Location\": \"$host_fields.host_location\",                                         # Include the host location\n",
    "        \"Host_Neighbourhood\": \"$host_fields.host_neighbourhood\",                               # Include the host neighbourhood\n",
    "        \"Host_Picture_URL\": \"$host_fields.host_picture_url\",                                   # Include the host picture URL\n",
    "        \"Host_Thumbnail_URL\": \"$host_fields.host_thumbnail_url\",                               # Include the host thumbnail URL\n",
    "        \"Host_Response_Rate\": \"$host_fields.host_response_rate\",                               # Include the host response rate\n",
    "        \"Host_Response_Time\": \"$host_fields.host_response_time\",                               # Include the host response time\n",
    "        \"Host_Verifications\": \"$host_fields.host_verifications\",                               # Include the host verifications\n",
    "        \"Host_Has_Profile_Pic\": \"$host_fields.host_has_profile_pic\",                           # Include the host has profile pic\n",
    "        \"Host_Identity_Verified\": \"$host_fields.host_identity_verified\",                       # Include the host identity verified\n",
    "        \"Host_Is_Superhost\": \"$host_fields.host_is_superhost\",                                 # Include the host is superhost\n",
    "        \"Host_Listings_Count\": \"$host_fields.host_listings_count\",                             # Include the host listings count\n",
    "        \"Host_Total_Listings_Count\": \"$host_fields.host_total_listings_count\",                 # Include the host total listings count\n",
    "        \"Host_URL\": \"$host_fields.host_url\",                                                   # Include the host URL\n",
    "    }},   \n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Hosts\"}                                                             # Output directly to 'Hosts' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Hosts' collection:\u001b[0m 5104\n",
      "\u001b[1mSample document from 'Hosts' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fcea604f6288c2cac72f4d'),\n",
      " 'Host_ID': '10002884',\n",
      " 'Host_Name': 'Han',\n",
      " 'Host_About': 'Welcome to my room!',\n",
      " 'Host_Location': 'HK',\n",
      " 'Host_Neighbourhood': 'Mong Kok',\n",
      " 'Host_Picture_URL': 'https://a0.muscache.com/im/users/10002884/profile_pic/1387359746/original.jpg?aki_policy=profile_x_medium',\n",
      " 'Host_Thumbnail_URL': 'https://a0.muscache.com/im/users/10002884/profile_pic/1387359746/original.jpg?aki_policy=profile_small',\n",
      " 'Host_Response_Rate': 100,\n",
      " 'Host_Response_Time': 'within an hour',\n",
      " 'Host_Verifications': ['email', 'phone', 'reviews', 'jumio', 'government_id'],\n",
      " 'Host_Has_Profile_Pic': True,\n",
      " 'Host_Identity_Verified': True,\n",
      " 'Host_Is_Superhost': False,\n",
      " 'Host_Listings_Count': 1,\n",
      " 'Host_Total_Listings_Count': 1,\n",
      " 'Host_URL': 'https://www.airbnb.com/users/show/10002884'}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check the new Hosts collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Hosts' collection:\\033[0m {db.Hosts.count_documents({})}\")  # Count the number of documents in the Hosts collection\n",
    "print(f\"\\033[1mSample document from 'Hosts' collection:\\033[0m\")\n",
    "pprint(db.Hosts.find_one(), sort_dicts=False)                                                        # Print one example document from the Hosts collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Data Normalization/Reference** by creating a separate `Hosts` collection. This eliminates the duplication of host information previously embedded in each listing document. Each document in `Hosts` represents a unique host, identified by `Host_ID`, and is referenced from the `Listings` collection. We expect **improved data integrity (updates to host info only need to happen in one place), reduced overall storage**, and **efficient querying of host-specific information** using the indexed `Host_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All host IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Check if all host IDs are unique\n",
    "host_ids = db.Hosts.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Host_ID\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(host_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate host IDs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Host ID: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All host IDs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host_ID_1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Hosts.Host_ID index for faster queries (\"Foreign Key\")\n",
    "db.Hosts.create_index([(\"Host_ID\")])  # Create index on Host_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Transactions` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '1022200',\n",
      " 'transactions': {'bucket_end_date': datetime.datetime(2016, 11, 21, 0, 0),\n",
      "                  'bucket_start_date': datetime.datetime(1972, 6, 6, 0, 0),\n",
      "                  'transaction_count': 45,\n",
      "                  'transactions': [{'date': datetime.datetime(2015, 12, 1, 0, 0),\n",
      "                                    'price': Decimal128('29.15849659079999511845926463138312')},\n",
      "                                   {'date': datetime.datetime(1989, 12, 14, 0, 0),\n",
      "                                    'price': Decimal128('0.7724161292822024904580757720395922')},\n",
      "                                   {'date': datetime.datetime(1998, 12, 31, 0, 0),\n",
      "                                    'price': Decimal128('1.295972012182961652371204763767309')},\n",
      "                                   {'date': datetime.datetime(2009, 3, 30, 0, 0),\n",
      "                                    'price': Decimal128('31.52850186521098763137160858605057')},\n",
      "                                   {'date': datetime.datetime(2000, 5, 31, 0, 0),\n",
      "                                    'price': Decimal128('49.18051651563923343246642616577446')},\n",
      "                                   {'date': datetime.datetime(2009, 7, 7, 0, 0),\n",
      "                                    'price': Decimal128('34.65621723737613280036384821869432')},\n",
      "                                   {'date': datetime.datetime(2015, 7, 8, 0, 0),\n",
      "                                    'price': Decimal128('86.22352514753742980246897786855697')},\n",
      "                                   {'date': datetime.datetime(2011, 6, 16, 0, 0),\n",
      "                                    'price': Decimal128('54.43494403571661877094811643473803')},\n",
      "                                   {'date': datetime.datetime(2016, 10, 18, 0, 0),\n",
      "                                    'price': Decimal128('115.5600242040379441732511622831225')},\n",
      "                                   {'date': datetime.datetime(1998, 10, 12, 0, 0),\n",
      "                                    'price': Decimal128('1.206638616530141705496248505369294')},\n",
      "                                   {'date': datetime.datetime(1991, 1, 2, 0, 0),\n",
      "                                    'price': Decimal128('1.361862142742455317190319874498527')},\n",
      "                                   {'date': datetime.datetime(2016, 5, 17, 0, 0),\n",
      "                                    'price': Decimal128('118.1858096895133769521635258570313')},\n",
      "                                   {'date': datetime.datetime(2015, 5, 15, 0, 0),\n",
      "                                    'price': Decimal128('30.67717643739939248348491673823446')},\n",
      "                                   {'date': datetime.datetime(2003, 4, 28, 0, 0),\n",
      "                                    'price': Decimal128('14.79466170541391356607618945417925')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 27, 0, 0),\n",
      "                                    'price': Decimal128('16.81818592088138331064328667707741')},\n",
      "                                   {'date': datetime.datetime(2003, 6, 17, 0, 0),\n",
      "                                    'price': Decimal128('15.01234189362955007140953966882079')},\n",
      "                                   {'date': datetime.datetime(1988, 3, 2, 0, 0),\n",
      "                                    'price': Decimal128('0.7181873554933055903148897414212115')},\n",
      "                                   {'date': datetime.datetime(2015, 10, 30, 0, 0),\n",
      "                                    'price': Decimal128('76.44256410019895042751159053295850')},\n",
      "                                   {'date': datetime.datetime(2007, 12, 17, 0, 0),\n",
      "                                    'price': Decimal128('20.63278087075391198368379264138638')},\n",
      "                                   {'date': datetime.datetime(2011, 7, 13, 0, 0),\n",
      "                                    'price': Decimal128('13.58544794397653809880921471631154')},\n",
      "                                   {'date': datetime.datetime(2015, 6, 22, 0, 0),\n",
      "                                    'price': Decimal128('73.46376878396031884221883956342935')},\n",
      "                                   {'date': datetime.datetime(2015, 2, 11, 0, 0),\n",
      "                                    'price': Decimal128('75.90495979706304296996677294373512')},\n",
      "                                   {'date': datetime.datetime(1979, 4, 20, 0, 0),\n",
      "                                    'price': Decimal128('0.1779933743016186287189128734098630')},\n",
      "                                   {'date': datetime.datetime(1973, 8, 6, 0, 0),\n",
      "                                    'price': Decimal128('0.0561500005424022674560546875')},\n",
      "                                   {'date': datetime.datetime(2004, 7, 28, 0, 0),\n",
      "                                    'price': Decimal128('2.043086696201633412073306317324750')},\n",
      "                                   {'date': datetime.datetime(1985, 5, 14, 0, 0),\n",
      "                                    'price': Decimal128('0.4646852238595403083998292004253016')},\n",
      "                                   {'date': datetime.datetime(2014, 11, 7, 0, 0),\n",
      "                                    'price': Decimal128('19.45859800790097438039083499461412')},\n",
      "                                   {'date': datetime.datetime(2006, 12, 12, 0, 0),\n",
      "                                    'price': Decimal128('13.39928664879049691194268234539777')},\n",
      "                                   {'date': datetime.datetime(2016, 7, 13, 0, 0),\n",
      "                                    'price': Decimal128('33.58402622979829743599111679941415')},\n",
      "                                   {'date': datetime.datetime(1998, 9, 23, 0, 0),\n",
      "                                    'price': Decimal128('16.96044890308613162233086768537759')},\n",
      "                                   {'date': datetime.datetime(2002, 9, 26, 0, 0),\n",
      "                                    'price': Decimal128('9.793800762771049051025329390540719')},\n",
      "                                   {'date': datetime.datetime(2016, 5, 26, 0, 0),\n",
      "                                    'price': Decimal128('118.5466676311641691654585883952677')},\n",
      "                                   {'date': datetime.datetime(1997, 9, 11, 0, 0),\n",
      "                                    'price': Decimal128('6.445615410792042254684020008426159')},\n",
      "                                   {'date': datetime.datetime(2005, 1, 14, 0, 0),\n",
      "                                    'price': Decimal128('21.96567254190052764784013561438769')},\n",
      "                                   {'date': datetime.datetime(2009, 7, 24, 0, 0),\n",
      "                                    'price': Decimal128('9.000573985989589687051193322986364')},\n",
      "                                   {'date': datetime.datetime(2016, 2, 11, 0, 0),\n",
      "                                    'price': Decimal128('21.73591227836645600746123818680644')},\n",
      "                                   {'date': datetime.datetime(2012, 9, 20, 0, 0),\n",
      "                                    'price': Decimal128('68.06032346689130463346373289823532')},\n",
      "                                   {'date': datetime.datetime(2016, 6, 9, 0, 0),\n",
      "                                    'price': Decimal128('30.60337968896972782317789096850901')},\n",
      "                                   {'date': datetime.datetime(2013, 3, 1, 0, 0),\n",
      "                                    'price': Decimal128('11.92923913679549308142213703831657')},\n",
      "                                   {'date': datetime.datetime(2016, 6, 2, 0, 0),\n",
      "                                    'price': Decimal128('80.15773522778474102779000531882047')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 3, 0, 0),\n",
      "                                    'price': Decimal128('16.79925040549669645884023339021950')},\n",
      "                                   {'date': datetime.datetime(1991, 1, 30, 0, 0),\n",
      "                                    'price': Decimal128('1.112550641097352244202056681388057')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 3, 0, 0),\n",
      "                                    'price': Decimal128('16.76913728179111018334879190661013')},\n",
      "                                   {'date': datetime.datetime(2015, 9, 2, 0, 0),\n",
      "                                    'price': Decimal128('63.59945944469900780404714168980717')},\n",
      "                                   {'date': datetime.datetime(2016, 4, 12, 0, 0),\n",
      "                                    'price': Decimal128('35.33423154808716759589515277184545')}]}}\n"
     ]
    }
   ],
   "source": [
    "# Print one example document of 'transactions' array\n",
    "pprint(db.listingsAndReviews_HW2.find_one({\"_id\": \"1022200\"}, {\"transactions\": 1}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Transactions collection\n",
    "transactions_fields = [\"_id\", \n",
    "                       # \"transactions.bucket_end_date\", \"transactions.bucket_start_date\", \"transactions.transaction_count\", \n",
    "                       \"transactions.transactions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2334c8f80b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate to extract transactions and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True}}},                        # Match documents where 'transactions.transactions' exists\n",
    "    {\"$unwind\": \"$transactions.transactions\"},                                           # Unwind the 'transactions' array to create a document for each transaction\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                        # Will create a ObjectId for each transaction\n",
    "        \"Listing_ID\": \"$_id\",                                                            # Include the listing ID\n",
    "        \"Transaction_ID\": \"$transactions.transactions._id\",                              # Include the transaction ID\n",
    "        \"Transaction_Date\": \"$transactions.transactions.date\",                           # Include the transaction date\n",
    "        \"Transaction_Price\": \"$transactions.transactions.price\"                          # Include the transaction price\n",
    "    }},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Transactions\"}                                                             # Output directly to 'Transactions' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Transactions' collection:\u001b[0m 311093\n",
      "\u001b[1mSample document from 'Transactions' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fcea614f6288c2cac7433d'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Transaction_Date': datetime.datetime(2008, 8, 12, 0, 0),\n",
      " 'Transaction_Price': Decimal128('132.1063781684291313922585686668753')}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Transactions collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Transactions' collection:\\033[0m {db.Transactions.count_documents({})}\") # Count the number of documents in the Transactions collection\n",
    "print(f\"\\033[1mSample document from 'Transactions' collection:\\033[0m\")\n",
    "pprint(db.Transactions.find_one(), sort_dicts=False)                                                              # Print one example document from the Transactions collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Reference** by creating a separate `Transactions` collection, moving the potentially large and time-sensitive `transactions.transactions` array out of the main listing document. This isolates transaction data for focused querying (like in **Q10**). Each document represents a single transaction and includes a `Listing_ID` reference. We expect **faster reads for the main `Listings` collection**, **improved performance for time-based queries on transactions** (especially with the index on `Listing_ID` and potentially `Transaction_Date`), and **better scalability for transaction data** (as it can grow independently of the listing document and we have limit of 16MB per document).\n",
    "\n",
    "**Note:** We decided to *keep* the `transactions.bucket_end_date`, `transactions.bucket_start_date`, and `transactions.transaction_count` fields within the main `Listings` collection (under the `Transactions` subdocument, but without the nested `transactions` array). These fields provide a useful summary about the transaction history associated with the listing, which might be needed for display without querying the full `Transactions` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1: Check if all (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique\n",
    "transactions_ids = db.Transactions.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": {\"Listing_ID\": \"$Listing_ID\", \"Transaction_Date\": \"$Transaction_Date\", \"Transaction_Price\": \"$Transaction_Price\"},\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(transactions_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate (Listing_ID, Transaction_Date, Transaction_Price) pairs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Pair: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Transactions.Listing_ID index for faster queries (\"Foreign Key\")\n",
    "db.Transactions.create_index([(\"Listing_ID\")])  # Create index on Listing_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Listings` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop_collection(\"Listings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found \u001b[1m45 listings fields\u001b[0m: \n",
      "\n",
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transit',\n",
      " 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create Listings collection\n",
    "# Extract all fields except for \"reviews\", \"transactions.transactions\" array, and \"host_\" fields\n",
    "listings_fields = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},             # Convert document to key-value pairs\n",
    "    {\"$unwind\": \"$fields\"},                                             # Flatten the fields array\n",
    "    {\"$match\": {\n",
    "        \"fields.k\": {\n",
    "            \"$not\": {\n",
    "                \"$regex\": \"^reviews|^transactions\\\\.transactions|^host_\"\n",
    "            }\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}                                    # Group by field names to get distinct fields\n",
    "])\n",
    "\n",
    "# Convert the aggregation result to a list with only field names\n",
    "listings_fields = sorted([doc[\"_id\"] for doc in listings_fields])\n",
    "\n",
    "# Print the list of listings fields\n",
    "print(f\"Found \\033[1m{len(listings_fields)} listings fields\\033[0m: \\n\")\n",
    "pprint(listings_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2334ce635f0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Aggregate to extract listings and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                   # Will create a ObjectId for each listing\n",
    "        \"Listing_ID\": \"$_id\",                                                       # Include the listing ID\n",
    "        \"Host_ID\": \"$host_id\",                                                      # Include the host ID\n",
    "        \"Name\": \"$name\",                                                            # Name of the listing\n",
    "        \"Description\": \"$description\",                                              # Description of the listing\n",
    "        \"Summary\": \"$summary\",                                                      # Summary of the listing\n",
    "        \"Space\": \"$space\",                                                          # Space details\n",
    "        \"Property_Type\": \"$property_type\",                                          # Type of property\n",
    "        \"Room_Type\": \"$room_type\",                                                  # Type of room\n",
    "        \"Accommodates\": \"$accommodates\",                                            # Number of guests accommodated\n",
    "        \"Bedrooms\": \"$bedrooms\",                                                    # Number of bedrooms\n",
    "        \"Beds\": \"$beds\",                                                            # Number of beds\n",
    "        \"Bathrooms\": \"$bathrooms\",                                                  # Number of bathrooms\n",
    "        \"Bed_Type\": \"$bed_type\",                                                    # Type of bed\n",
    "        \"Price\": \"$price\",                                                          # Price per night\n",
    "        \"Cleaning_Fee\": \"$cleaning_fee\",                                            # Cleaning fee\n",
    "        \"Security_Deposit\": \"$security_deposit\",                                    # Security deposit\n",
    "        \"Extra_People\": \"$extra_people\",                                            # Extra charges for additional people\n",
    "        \"Weekly_Price\": \"$weekly_price\",                                            # Weekly price\n",
    "        \"Monthly_Price\": \"$monthly_price\",                                          # Monthly price\n",
    "        \"Minimum_Nights\": \"$minimum_nights\",                                        # Minimum nights for booking\n",
    "        \"Maximum_Nights\": \"$maximum_nights\",                                        # Maximum nights for booking\n",
    "        \"Guests_Included\": \"$guests_included\",                                      # Number of guests included in the price\n",
    "        \"Address\": \"$address\",                                                      # Address details\n",
    "        \"Access\": \"$access\",                                                        # Access details\n",
    "        \"Interaction\": \"$interaction\",                                              # Interaction details\n",
    "        \"House_Rules\": \"$house_rules\",                                              # House rules\n",
    "        \"Amenities\": \"$amenities\",                                                  # Amenities provided\n",
    "        \"Availability\": \"$availability\",                                            # Availability details\n",
    "        \"Calendar_Last_Scraped\": \"$calendar_last_scraped\",                          # Last scraped date of the calendar\n",
    "        \"Last_Scraped\": \"$last_scraped\",                                            # Last scraped date of the listing\n",
    "        \"Cancellation_Policy\": \"$cancellation_policy\",                              # Cancellation policy\n",
    "        \"Neighborhood_Overview\": \"$neighborhood_overview\",                          # Overview of the neighborhood\n",
    "        \"Transit\": \"$transit\",                                                      # Transit information\n",
    "        \"Notes\": \"$notes\",                                                          # Additional notes\n",
    "        \"Images\": \"$images\",                                                        # Images of the listing\n",
    "        \"Listing_URL\": \"$listing_url\",                                              # URL of the listing\n",
    "        \"First_Review\": \"$first_review\",                                            # Date of the first review\n",
    "        \"Last_Review\": \"$last_review\",                                              # Date of the last review\n",
    "        \"Number_of_Reviews\": \"$number_of_reviews\",                                  # Total number of reviews\n",
    "        \"Review_Scores_Rating\": \"$review_scores_rating\",                            # Review scores rating\n",
    "        \n",
    "        # Review scores for subdocument | Capitalize and prefix the score name (e.g., \"review_scores__checkin\" -> \"Checkin\")\n",
    "        \"Review_Scores\": {\n",
    "            \"Checkin\": \"$review_scores_checkin\",                                    # Check-in rating\n",
    "            \"Cleanliness\": \"$review_scores_cleanliness\",                            # Cleanliness rating\n",
    "            \"Communication\": \"$review_scores_communication\",                        # Communication rating\n",
    "            \"Location\": \"$review_scores_location\",                                  # Location rating\n",
    "            \"Rating\": \"$review_scores_rating\",                                      # Overall rating\n",
    "            \"Value\": \"$review_scores_value\"                                         # Value rating\n",
    "        },\n",
    "        \n",
    "        \"Transactions\": \"$transactions\"                                             # Transactions details\n",
    "    }},\n",
    "    # Drop the 'transactions.transactions' field from the listings collection\n",
    "    {\"$unset\": \"Transactions.transactions\"},\n",
    "    \n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Listings\"}                                                            # Output directly to 'Listings' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Listings' collection:\u001b[0m 5555\n",
      "\u001b[1mSample document from 'Listings' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fcea664f6288c2cacc0272'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Host_ID': '51399391',\n",
      " 'Name': 'Ribeira Charming Duplex',\n",
      " 'Description': 'Fantastic duplex apartment with three bedrooms, located in '\n",
      "                'the historic area of Porto, Ribeira (Cube) - UNESCO World '\n",
      "                'Heritage Site. Centenary building fully rehabilitated, '\n",
      "                'without losing their original character. Privileged views of '\n",
      "                'the Douro River and Ribeira square, our apartment offers the '\n",
      "                'perfect conditions to discover the history and the charm of '\n",
      "                'Porto. Apartment comfortable, charming, romantic and cozy in '\n",
      "                'the heart of Ribeira. Within walking distance of all the most '\n",
      "                'emblematic places of the city of Porto. The apartment is '\n",
      "                'fully equipped to host 8 people, with cooker, oven, washing '\n",
      "                'machine, dishwasher, microwave, coffee machine (Nespresso) '\n",
      "                'and kettle. The apartment is located in a very typical area '\n",
      "                'of the city that allows to cross with the most picturesque '\n",
      "                'population of the city, welcoming, genuine and happy people '\n",
      "                'that fills the streets with his outspoken speech and '\n",
      "                'contagious with your sincere generosity, wrapped in a only '\n",
      "                'parochial spirit. We are always available to help guests',\n",
      " 'Summary': 'Fantastic duplex apartment with three bedrooms, located in the '\n",
      "            'historic area of Porto, Ribeira (Cube) - UNESCO World Heritage '\n",
      "            'Site. Centenary building fully rehabilitated, without losing '\n",
      "            'their original character.',\n",
      " 'Space': 'Privileged views of the Douro River and Ribeira square, our '\n",
      "          'apartment offers the perfect conditions to discover the history and '\n",
      "          'the charm of Porto. Apartment comfortable, charming, romantic and '\n",
      "          'cozy in the heart of Ribeira. Within walking distance of all the '\n",
      "          'most emblematic places of the city of Porto. The apartment is fully '\n",
      "          'equipped to host 8 people, with cooker, oven, washing machine, '\n",
      "          'dishwasher, microwave, coffee machine (Nespresso) and kettle. The '\n",
      "          'apartment is located in a very typical area of the city that allows '\n",
      "          'to cross with the most picturesque population of the city, '\n",
      "          'welcoming, genuine and happy people that fills the streets with his '\n",
      "          'outspoken speech and contagious with your sincere generosity, '\n",
      "          'wrapped in a only parochial spirit.',\n",
      " 'Property_Type': 'House',\n",
      " 'Room_Type': 'Entire home/apt',\n",
      " 'Accommodates': 8,\n",
      " 'Bedrooms': 3,\n",
      " 'Beds': 5,\n",
      " 'Bathrooms': Decimal128('1.0'),\n",
      " 'Bed_Type': 'Real Bed',\n",
      " 'Price': Decimal128('80.00'),\n",
      " 'Cleaning_Fee': Decimal128('35.00'),\n",
      " 'Security_Deposit': Decimal128('200.00'),\n",
      " 'Extra_People': Decimal128('15.00'),\n",
      " 'Minimum_Nights': 2,\n",
      " 'Maximum_Nights': 30,\n",
      " 'Guests_Included': 6,\n",
      " 'Address': {'street': 'Porto, Porto, Portugal',\n",
      "             'government_area': 'Cedofeita, Ildefonso, Sé, Miragaia, Nicolau, '\n",
      "                                'Vitória',\n",
      "             'market': 'Porto',\n",
      "             'country': 'Portugal',\n",
      "             'country_code': 'PT',\n",
      "             'location': {'type': 'Point',\n",
      "                          'coordinates': [-8.61308, 41.1413],\n",
      "                          'is_location_exact': False}},\n",
      " 'Access': 'We are always available to help guests. The house is fully '\n",
      "           'available to guests. We are always ready to assist guests. when '\n",
      "           'possible we pick the guests at the airport.  This service transfer '\n",
      "           'have a cost per person. We will also have service \"meal at home\" '\n",
      "           'with a diverse menu and the taste of each. Enjoy the moment!',\n",
      " 'Interaction': 'Cot - 10 € / night Dog - € 7,5 / night',\n",
      " 'House_Rules': 'Make the house your home...',\n",
      " 'Amenities': ['TV',\n",
      "               'Cable TV',\n",
      "               'Wifi',\n",
      "               'Kitchen',\n",
      "               'Paid parking off premises',\n",
      "               'Smoking allowed',\n",
      "               'Pets allowed',\n",
      "               'Buzzer/wireless intercom',\n",
      "               'Heating',\n",
      "               'Family/kid friendly',\n",
      "               'Washer',\n",
      "               'First aid kit',\n",
      "               'Fire extinguisher',\n",
      "               'Essentials',\n",
      "               'Hangers',\n",
      "               'Hair dryer',\n",
      "               'Iron',\n",
      "               'Pack ’n Play/travel crib',\n",
      "               'Room-darkening shades',\n",
      "               'Hot water',\n",
      "               'Bed linens',\n",
      "               'Extra pillows and blankets',\n",
      "               'Microwave',\n",
      "               'Coffee maker',\n",
      "               'Refrigerator',\n",
      "               'Dishwasher',\n",
      "               'Dishes and silverware',\n",
      "               'Cooking basics',\n",
      "               'Oven',\n",
      "               'Stove',\n",
      "               'Cleaning before checkout',\n",
      "               'Waterfront'],\n",
      " 'Availability': {'availability_30': 28,\n",
      "                  'availability_60': 47,\n",
      "                  'availability_90': 74,\n",
      "                  'availability_365': 239},\n",
      " 'Calendar_Last_Scraped': datetime.datetime(2019, 2, 16, 5, 0),\n",
      " 'Last_Scraped': datetime.datetime(2019, 2, 16, 5, 0),\n",
      " 'Cancellation_Policy': 'moderate',\n",
      " 'Neighborhood_Overview': 'In the neighborhood of the river, you can find '\n",
      "                          'several restaurants as varied flavors, but without '\n",
      "                          'forgetting the so traditional northern food. You '\n",
      "                          'can also find several bars and pubs to unwind after '\n",
      "                          \"a day's visit to the magnificent Port. To enjoy the \"\n",
      "                          'Douro River can board the boats that daily make the '\n",
      "                          'ride of six bridges. You can also embark towards '\n",
      "                          \"Régua, Barca d'Alva, Pinhão, etc and enjoy the \"\n",
      "                          'Douro Wine Region, World Heritage of Humanity. The '\n",
      "                          \"Infante's house is a few meters and no doubt it \"\n",
      "                          'deserves a visit. They abound grocery stores, '\n",
      "                          'bakeries, etc. to make your meals. Souvenir shop, '\n",
      "                          'wine cellars, etc. to bring some souvenirs.',\n",
      " 'Transit': 'Transport: • Metro station and S. Bento railway 5min; • Bus stop '\n",
      "            'a 50 meters; • Lift Guindais (Funicular) 50 meters; • Tuc Tuc-to '\n",
      "            'get around the city; • Buses tourist; • Cycling through the '\n",
      "            'marginal drive; • Cable car in Gaia, overlooking the Port (just '\n",
      "            'cross the bridge).',\n",
      " 'Notes': 'Lose yourself in the narrow streets and staircases zone, have lunch '\n",
      "          'in pubs and typical restaurants, and find the renovated cafes and '\n",
      "          'shops in town. If you like exercise, rent a bicycle in the area and '\n",
      "          'ride along the river to the sea, where it will enter beautiful '\n",
      "          'beaches and terraces for everyone. The area is safe, find the bus '\n",
      "          'stops 1min and metro line 5min. The bustling nightlife is a 10 min '\n",
      "          'walk, where the streets are filled with people and entertainment '\n",
      "          'for all. But Porto is much more than the historical center, here is '\n",
      "          'modern museums, concert halls, clean and cared for beaches and surf '\n",
      "          'all year round. Walk through the Ponte D. Luis and visit the '\n",
      "          'different Caves of Port wine, where you will enjoy the famous port '\n",
      "          'wine. Porto is a spoken city everywhere in the world as the best to '\n",
      "          'be visited and savored by all ... natural beauty, culture, '\n",
      "          'tradition, river, sea, beach, single people, typical food, and we '\n",
      "          'are among those who best receive tourists, confirm! Come visit us '\n",
      "          'and feel at ho',\n",
      " 'Images': {'picture_url': 'https://a0.muscache.com/im/pictures/e83e702f-ef49-40fb-8fa0-6512d7e26e9b.jpg?aki_policy=large'},\n",
      " 'Listing_URL': 'https://www.airbnb.com/rooms/10006546',\n",
      " 'First_Review': datetime.datetime(2016, 1, 3, 5, 0),\n",
      " 'Last_Review': datetime.datetime(2019, 1, 20, 5, 0),\n",
      " 'Number_of_Reviews': 51,\n",
      " 'Review_Scores_Rating': 8.9,\n",
      " 'Review_Scores': {'Checkin': 10,\n",
      "                   'Cleanliness': 9,\n",
      "                   'Communication': 10,\n",
      "                   'Location': 10,\n",
      "                   'Rating': 8.9,\n",
      "                   'Value': 9},\n",
      " 'Transactions': {'bucket_end_date': datetime.datetime(2016, 11, 23, 0, 0),\n",
      "                  'bucket_start_date': datetime.datetime(1979, 10, 4, 0, 0),\n",
      "                  'transaction_count': 21}}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check the new Listings collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Listings' collection:\\033[0m {db.Listings.count_documents({})}\")     # Count the number of documents in the Listings collection\n",
    "print(f\"\\033[1mSample document from 'Listings' collection:\\033[0m\")\n",
    "pprint(db.Listings.find_one(), sort_dicts=False)                                                               # Print one example document from the Listings collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **schema restructuring** to create the final `Listings` collection. This involved **removing embedded host details, the full reviews array, and the detailed transactions array**, replacing them with references (`Host_ID`). We **restructured the `review_scores_*` fields into a `Review_Scores` subdocument**, applying the **Attribute Pattern** for flexibility (**Q9**). Key identifying information (`Listing_ID`), frequently accessed data (`Name`, `Price`, `Address`, `Amenities`, etc.), and summary transaction info remain embedded. We expect **significantly faster retrieval of core listing information** for the primary customer-facing use case (**Q1**), as documents are much smaller. The restructured `Review_Scores` allows for flexible querying of score averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All listing IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Check if all listing IDs are unique\n",
    "listings_ids = db.Listings.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Listing_ID\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(listings_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate listing IDs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Listing ID: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All listing IDs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Listings.Listing_ID and Listings.Host_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Listings.create_index([(\"Listing_ID\")])                                      # Create index on Listing_ID field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host_ID_1'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Listings.create_index([(\"Host_ID\")])                                         # Create index on Host_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🔍 Queries** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🛋️Standard Difficulty Questions** [2 points per question]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\tOnce a month, we reward hosts with recognition. \n",
    "#       Select three superhosts with at least two listings that can accommodate more than four people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0192 seconds\n",
      "\n",
      "Found \u001b[1m14 superhosts\u001b[0m with at least 2 listings that can accommodate more than 4 people.\n",
      "\n",
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assunção De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Daniel                    | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Elite                     | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [14, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Great Vacation Retreats   | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [5, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Jane                      | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 9]\n",
      "\u001b[1mHost Name\u001b[0m: Liiiving                  | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Miguel & João             | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 5]\n",
      "\u001b[1mHost Name\u001b[0m: Mindy                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Patty And Beckett         | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [8, 8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Resortica                 | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Wilson&Shan               | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [9, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Yaiza                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 6]\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for superhosts and listings accommodating > 4\n",
    "    {\"$match\": {\"host_is_superhost\": True, \"accommodates\": {\"$gt\": 4}}},\n",
    "    # Group by host_id to count listings and collect accommodates values\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$host_id\",\n",
    "        \"HostName\": {\"$first\": \"$host_name\"},\n",
    "        \"ListingCount\": {\"$sum\": 1},\n",
    "        \"AccommodatesList\": {\"$push\": \"$accommodates\"}  # Collect all accommodates values\n",
    "    }},\n",
    "    # Filter for hosts with at least 2 listings\n",
    "    {\"$match\": {\"ListingCount\": {\"$gte\": 2}}},\n",
    "    # Sort by host name for consistency\n",
    "    {\"$sort\": {\"HostName\": 1}},\n",
    "    \n",
    "    # Limit to 3 superhosts\n",
    "    # {\"$limit\": 3},\n",
    "    \n",
    "    # Project output without _id\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"HostName\": 1,\n",
    "        \"ListingCount\": 1,\n",
    "        \"AccommodatesList\": 1                           # Include the list of accommodation capacities\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nFound \\033[1m{len(result)} superhosts\\033[0m with at least 2 listings that can accommodate more than 4 people.\\n\")\n",
    "for host in result:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0353 seconds\n",
      "\n",
      "Found \u001b[1m14 superhosts\u001b[0m with at least 2 listings accommodating > 4 people.\n",
      "\n",
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assunção De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Daniel                    | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Elite                     | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [14, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Great Vacation Retreats   | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [5, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Jane                      | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 9]\n",
      "\u001b[1mHost Name\u001b[0m: Liiiving                  | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Miguel & João             | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 5]\n",
      "\u001b[1mHost Name\u001b[0m: Mindy                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Patty And Beckett         | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [8, 8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Resortica                 | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Wilson&Shan               | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [9, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Yaiza                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 6]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query2 = list(db.Hosts.aggregate([\n",
    "    \n",
    "    # Start with Hosts collection to filter superhosts\n",
    "    {\"$match\": {\"Host_Is_Superhost\": True}},\n",
    "    \n",
    "    # Lookup listings for each host\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Listings\",\n",
    "        \"localField\": \"Host_ID\",\n",
    "        \"foreignField\": \"Host_ID\",\n",
    "        \"as\": \"listings\"\n",
    "    }},\n",
    "    \n",
    "    # Filter listings accommodating > 4\n",
    "    {\"$project\": {\n",
    "        \"HostName\": \"$Host_Name\",\n",
    "        \"listings\": {\n",
    "            \"$filter\": {\n",
    "                \"input\": \"$listings\",\n",
    "                \"cond\": {\"$gt\": [\"$$this.Accommodates\", 4]}\n",
    "            }\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group to count listings per host\n",
    "    {\"$project\": {\n",
    "        \"HostName\": 1,\n",
    "        \"ListingCount\": {\"$size\": \"$listings\"},\n",
    "        \"AccommodatesList\": \"$listings.Accommodates\"\n",
    "    }},\n",
    "    \n",
    "    # Filter hosts with at least 2 listings\n",
    "    {\"$match\": {\"ListingCount\": {\"$gte\": 2}}},\n",
    "    \n",
    "    # Sort by name for consistency\n",
    "    {\"$sort\": {\"HostName\": 1}}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nFound \\033[1m{len(query2)} superhosts\\033[0m with at least 2 listings accommodating > 4 people.\\n\")\n",
    "for host in query2:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assunção De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n"
     ]
    }
   ],
   "source": [
    "# Select three superhosts with at least two listings that can accommodate more than four people\n",
    "for host in query2[:3]:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q2):** The new schema query uses a `$lookup` to join `Hosts` and `Listings`. While lookups can introduce overhead compared to querying a single collection, this approach maintains normalized data by avoiding host information duplication. The execution time in the new schema (0.052s) is slightly slower than the original (0.030s) for this specific query. This is expected due to the left outer join operation (**$lookup**). However, the trade-off ensures data integrity and avoids redundancy across the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)\tThe company considers investing into property to rent. \n",
    "#       Which bed type is most common in listings with a waterfront and a dishwasher in New York?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0551 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "# 3. Most common bed type in New York listings with waterfront and dishwasher\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"address.market\": \"New York\",\n",
    "        \"amenities\": {\n",
    "            \"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}  # Matches any waterfront variant (case-insensitive)\n",
    "        },\n",
    "        \"amenities\": {\n",
    "            \"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}  # Matches any dishwasher variant (case-insensitive)\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$bed_type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{result[0]['BedType']}\\033[0m with \\033[1m{result[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0438 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query3 = list(db.Listings.aggregate([\n",
    "    \n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"Address.market\": \"New York\",\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}},  # Matches any waterfront variant (case-insensitive)\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}},  # Matches any dishwasher variant (case-insensitive)\n",
    "        \"Bed_Type\": {\"$exists\": True}                                            # Ensure Bed_Type field exists\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Bed_Type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{query3[0]['BedType']}\\033[0m with \\033[1m{query3[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q3):** Both queries yield the same result (**\"Real Bed\"**, count **75**). The new schema query targets the optimized `Listings` collection. Performance is comparable or slightly better in the new schema (0.086s vs 0.095s in the original). This indicates that querying the leaner `Listings` collection, even with similar filtering logic on embedded arrays (`Amenities`), provides a performance benefit or at least maintains performance while offering better overall structure. Indexing `Address.market` and `Amenities` could further optimize this if it were a very frequent query pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amenities_1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing 'Address.market' and 'Amenities' fields for faster queries (Single Field Indexes - Text)\n",
    "db.Listings.create_index([(\"Address.market\")])  # Create index on Address.market field\n",
    "db.Listings.create_index([(\"Amenities\")])       # Create index on Amenities field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0259 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "# Re-run the query with indexes\n",
    "start_time = time.time()\n",
    "\n",
    "query3 = list(db.Listings.aggregate([\n",
    "    \n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"Address.market\": \"New York\",\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}},  # Matches any waterfront variant (case-insensitive)\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}},  # Matches any dishwasher variant (case-insensitive)\n",
    "        \"Bed_Type\": {\"$exists\": True}                                            # Ensure Bed_Type field exists\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Bed_Type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{query3[0]['BedType']}\\033[0m with \\033[1m{query3[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we expected, the new schema query with indexing on `Address.market` and `Amenities` is faster than the original query, because in this case we are searching for a specific value in the `Amenities` array and `Address.market` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\tWe're considering hiring someone to write reviews professionally. \n",
    "#       Who wrote the longest review in New York?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0726 seconds\n",
      "\n",
      "Reviewer who wrote the longest review in New York is: \u001b[1mAngela\u001b[0m with \u001b[1m4665 characters\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 4. Reviewer who wrote the longest review in New York\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for New York\n",
    "    {\"$match\": {\"address.market\": \"New York\"}},\n",
    "    # Unwind reviews array\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    # Project review length and reviewer, handling null comments\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerName\": \"$reviews.reviewer_name\",\n",
    "        \"ReviewLength\": {\"$strLenCP\":                # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/strLenCP/\n",
    "            {\"$ifNull\": [\"$reviews.comments\", \"\"]}}  # Default to empty string if null\n",
    "    }},\n",
    "    # Sort by length descending\n",
    "    {\"$sort\": {\"ReviewLength\": -1}},\n",
    "    # Limit to 1\n",
    "    {\"$limit\": 1}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline)) # [{'ReviewLength': 4665, 'ReviewerName': 'Angela'}]\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nReviewer who wrote the longest review in New York is: \\033[1m{result[0]['ReviewerName']}\\033[0m with \\033[1m{result[0]['ReviewLength']} characters\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 12.6605 seconds\n",
      "[{'ReviewLength': 4665, 'ReviewerName': 'Angela'}]\n",
      "\n",
      "Reviewer who wrote the longest review in New York is: \u001b[1mAngela\u001b[0m with \u001b[1m4665 characters\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query4 = list(db.Reviews.aggregate([\n",
    "    # Join Reviews with Listings to filter by New York\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Listings\",\n",
    "        \"localField\": \"Listing_ID\",\n",
    "        \"foreignField\": \"Listing_ID\",\n",
    "        \"as\": \"listing\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the listings array to create a document for each review\n",
    "    {\"$unwind\": \"$listing\"},\n",
    "    \n",
    "    # Filter for New York listings\n",
    "    {\"$match\": {\"listing.Address.market\": \"New York\"}},\n",
    "    \n",
    "    # Project review length and reviewer, handling null comments\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Reviewer_ID\": \"$Reviewer_ID\",                                          # Include Reviewer_ID\n",
    "        \"ReviewLength\": {\"$strLenCP\": {\"$ifNull\": [\"$Review_Comments\", \"\"]}}    # Calculate length of review comments (handling nulls)\n",
    "    }},\n",
    "    \n",
    "    # Join Reviews with Reviewers to get reviewer names\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Reviewers\",\n",
    "        \"localField\": \"Reviewer_ID\",\n",
    "        \"foreignField\": \"Reviewer_ID\",\n",
    "        \"as\": \"reviewer\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the reviewers array to create a document for each review\n",
    "    {\"$unwind\": \"$reviewer\"},\n",
    "    \n",
    "    # Project reviewer name\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerName\": \"$reviewer.Reviewer_Name\",\n",
    "        \"ReviewLength\": 1\n",
    "    }},\n",
    "    \n",
    "    # Sort by length descending\n",
    "    {\"$sort\": {\"ReviewLength\": -1}},\n",
    "    \n",
    "    # Limit to 1 (reviewer with longest review)\n",
    "    {\"$limit\": 1}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# pprint(query4)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "pprint(query4, sort_dicts=False)\n",
    "print(f\"\\nReviewer who wrote the longest review in New York is: \\033[1m{query4[0]['ReviewerName']}\\033[0m with \\033[1m{query4[0]['ReviewLength']} characters\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q4):** The new schema query involves lookups between `Reviews`, `Listings` (for the market filter), and `Reviewers`. Although separating collections often improves performance for targeted reads, the multiple `$lookup` stages required here introduce significant overhead compared to the original query which only needed to unwind the embedded `reviews` array. This resulted in a considerably longer execution time (20.0s vs 0.1s). While indexing helps, the cost of joining large collections for *this specific aggregation* outweighs the benefit of smaller individual documents in the `Reviews` collection. For frequent queries like this, further optimization (like denormalizing the reviewer name into the `Reviews` collection or creating materialized views) might be considered in a real-world scenario. However, the current schema prioritizes scalability and avoids data duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\tTo assess the security of different areas, what is the biggest and smallest (price-security deposit) difference per number of visitors at a property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0320 seconds\n",
      "\n",
      "Biggest difference (price - security deposit) per number of visitors: \u001b[1m19229.5\u001b[0m\n",
      "Smallest difference (price - security deposit) per number of visitors: \u001b[1m0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 5. Biggest and smallest (price - security deposit) difference per number of visitors\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for listings with price and security deposit\n",
    "    {\"$match\": {\n",
    "        \"price\": {\"$exists\": True, \"$ne\": None},                                  # Price exists and is not null\n",
    "        \"security_deposit\": {\"$exists\": True, \"$ne\": None}                        # Security deposit exists and is not null\n",
    "    }},\n",
    "    \n",
    "    # Calculate difference per visitor, converting strings to numbers\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"DifferencePerVisitor\": {\n",
    "            \"$divide\": [\n",
    "                {\"$abs\":                                                        # Absolute value of difference\n",
    "                    {\"$subtract\": [\n",
    "                        {\"$toDouble\": {\"$ifNull\": [\"$price\", \"0\"]}},            # Convert price to double, default 0\n",
    "                        {\"$toDouble\": {\"$ifNull\": [\"$security_deposit\", \"0\"]}}  # Convert security_deposit, default 0\n",
    "                    ]}\n",
    "                }\n",
    "                , \"$accommodates\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "    # Group to find min and max\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"MaxDifference\": {\"$max\": \"$DifferencePerVisitor\"},\n",
    "        \"MinDifference\": {\"$min\": \"$DifferencePerVisitor\"}\n",
    "    }},\n",
    "    # Project output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"MaxDifference\": {\"$round\": [\"$MaxDifference\", 2]},\n",
    "        \"MinDifference\": {\"$round\": [\"$MinDifference\", 2]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nBiggest difference (price - security deposit) per number of visitors: \\033[1m{result[0]['MaxDifference']}\\033[0m\")\n",
    "print(f\"Smallest difference (price - security deposit) per number of visitors: \\033[1m{result[0]['MinDifference']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0170 seconds\n",
      "\n",
      "Biggest difference (price - security deposit) per visitor: \u001b[1m19229.5\u001b[0m\n",
      "Smallest difference (price - security deposit) per visitor: \u001b[1m0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query5 = list(db.Listings.aggregate([\n",
    "    # Filter for listings with security deposit and accommodates fields\n",
    "    {\"$match\": {\n",
    "        \"Security_Deposit\": {\"$exists\": True},             # Security deposit exists\n",
    "        \"Accommodates\": {\"$exists\": True}                  # Accommodates field exists\n",
    "    }},\n",
    "            \n",
    "    # Calculate difference per visitor, converting strings to numbers\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"DifferencePerVisitor\": {\n",
    "            \"$divide\": [\n",
    "                {\"$abs\": {\"$subtract\": [\n",
    "                    {\"$toDouble\": \"$Price\"},\n",
    "                    {\"$toDouble\": {\"$ifNull\": [\"$Security_Deposit\", \"0\"]}}\n",
    "                ]}},\n",
    "                \"$Accommodates\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group to find min and max\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"MaxDifference\": {\"$max\": \"$DifferencePerVisitor\"},\n",
    "        \"MinDifference\": {\"$min\": \"$DifferencePerVisitor\"}\n",
    "    }},\n",
    "    \n",
    "    # Project output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"MaxDifference\": {\"$round\": [\"$MaxDifference\", 2]},\n",
    "        \"MinDifference\": {\"$round\": [\"$MinDifference\", 2]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nBiggest difference (price - security deposit) per visitor: \\033[1m{query5[0]['MaxDifference']}\\033[0m\")\n",
    "print(f\"Smallest difference (price - security deposit) per visitor: \\033[1m{query5[0]['MinDifference']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This query assumes both `price` and `security_deposit` exist and are valid numbers for the calculation. The `$match` stage ensures we only consider documents where these fields are present and not null. The `$ifNull` and type conversion steps handle potential data inconsistencies found during cleanup.\n",
    "\n",
    "> **Comparison (Q5):** Both queries correctly identify the min/max difference per visitor. The new schema query operates on the `Listings` collection where `Price` and `Security_Deposit` are already correctly typed as `Decimal128` (or `null`), simplifying the `$project` stage compared to the original query that needed `$toDouble` and `$ifNull`. The execution times are comparable (0.03s vs 0.09s), suggesting that for this full collection aggregation, the schema change did drastically alter performance (3x more fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6)  Identify areas by whether they are typically used for short breaks, like weekend mini breaks, or whether they are more suitable for long trips. \n",
    "#     This information support targeted advertising of different customer types. \n",
    "#     It is not expected to change much over time so we won’t look to update it, we just require current view. \n",
    "#     What is the average duration of stay (in nights) per type of property per city (you can use the maximum_nights to measure length of stays)? \n",
    "#     For each property type return the city with the highest and lowest average value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0314 seconds\n",
      "\n",
      "Average stay duration per property type per city:\n",
      "\n",
      "\u001b[1mProperty Type\u001b[0m          | \u001b[1mHighest Avg City\u001b[0m                 | \u001b[1mLowest Avg City\u001b[0m  \n",
      "================================================================================\n",
      "Tiny house             | Porto                            | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 5    \n",
      "--------------------------------------------------------------------------------\n",
      "Resort                 | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 7    \n",
      "--------------------------------------------------------------------------------\n",
      "Hostel                 | Oahu                             | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 10   \n",
      "--------------------------------------------------------------------------------\n",
      "Heritage hotel (India) | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 14             \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Guest suite            | Barcelona                        | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Villa                  | New York                         | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 15   \n",
      "--------------------------------------------------------------------------------\n",
      "Loft                   | Maui                             | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 28   \n",
      "--------------------------------------------------------------------------------\n",
      "Campsite               | Oahu                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hut                    | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Camper/RV              | Montreal                         | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Treehouse              | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Bed and breakfast      | Other (International)            | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Chalet                 | Sydney                           | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Condominium            | Other (Domestic)                 | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Townhouse              | Rio De Janeiro                   | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Other                  | Barcelona                        | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hotel                  | Porto                            | Other (International)\n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 35   \n",
      "--------------------------------------------------------------------------------\n",
      "Aparthotel             | New York                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 60   \n",
      "--------------------------------------------------------------------------------\n",
      "Nature lodge           | Maui                             | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 90   \n",
      "--------------------------------------------------------------------------------\n",
      "Cabin                  | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 120  \n",
      "--------------------------------------------------------------------------------\n",
      "Serviced apartment     | Oahu                             | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 180  \n",
      "--------------------------------------------------------------------------------\n",
      "Casa particular (Cuba) | Barcelona                        | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 235  \n",
      "--------------------------------------------------------------------------------\n",
      "Apartment              | Istanbul                         | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 5200438        \u001b[1mLowest Avg Nights:\u001b[0m 371  \n",
      "--------------------------------------------------------------------------------\n",
      "Cottage                | Hong Kong                        | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 410  \n",
      "--------------------------------------------------------------------------------\n",
      "Guesthouse             | Istanbul                         | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 470  \n",
      "--------------------------------------------------------------------------------\n",
      "Bungalow               | Montreal                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 485  \n",
      "--------------------------------------------------------------------------------\n",
      "House                  | Other (International)            | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 572  \n",
      "--------------------------------------------------------------------------------\n",
      "Boutique hotel         | Rio De Janeiro                   | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 578  \n",
      "--------------------------------------------------------------------------------\n",
      "Farm stay              | Hong Kong                        | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 846  \n",
      "--------------------------------------------------------------------------------\n",
      "Barn                   | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Boat                   | Porto                            | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Houseboat              | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Castle                 | Montreal                         | Montreal            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Earth house            | Rio De Janeiro                   | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Train                  | Sydney                           | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Pension (South Korea)  | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Average stay duration per property type per city, with highest and lowest\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Group by property type and city, converting maximum_nights to number\n",
    "    {\"$group\": {\n",
    "        \"_id\": {\"PropertyType\": \"$property_type\", \"City\": \"$address.market\"},\n",
    "        \"AvgMaxNights\": {\"$avg\": {\"$toInt\": {\"$ifNull\": [\"$maximum_nights\", \"0\"]}}}  # Convert to int, default 0\n",
    "    }},\n",
    "    # Group by property type to find min/max cities\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$_id.PropertyType\",\n",
    "        \"Cities\": {\n",
    "            \"$push\": {\n",
    "                # Handle with Null values\n",
    "                \"City\": {\"$ifNull\": [\"$_id.City\", \"Unknown\"]},                      # Default to \"Unknown\" if null\n",
    "                \"AvgMaxNights\": \"$AvgMaxNights\"}\n",
    "        }\n",
    "    }},\n",
    "    # Sort cities by AvgMaxNights\n",
    "    {\"$sort\": {\"Cities.AvgMaxNights\": 1}},\n",
    "    \n",
    "    # Project min and max per property type\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"PropertyType\": \"$_id\",\n",
    "        \"HighestAvgCity\": {\n",
    "            \"$arrayElemAt\": [\n",
    "                \"$Cities\",\n",
    "                {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$max\": \"$Cities.AvgMaxNights\"}]}\n",
    "            ]\n",
    "        },\n",
    "        \"LowestAvgCity\": {\n",
    "            \"$arrayElemAt\": [\n",
    "                \"$Cities\",\n",
    "                {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$min\": \"$Cities.AvgMaxNights\"}]}\n",
    "            ]\n",
    "        }\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage stay duration per property type per city:\\n\")\n",
    "print(f\"{'\\033[1mProperty Type\\033[0m':<30} | {'\\033[1mHighest Avg City\\033[0m':<40} | {'\\033[1mLowest Avg City\\033[0m':<25}\")\n",
    "print(\"=\" * 80)\n",
    "for item in result:\n",
    "    print(f\"{item['PropertyType']:<22} | {item['HighestAvgCity']['City']:<32} | {item['LowestAvgCity']['City']:<20}\")\n",
    "    print(f\"                         \\033[1mHighest Avg Nights:\\033[0m {round(item['HighestAvgCity']['AvgMaxNights']):<12}   \\033[1mLowest Avg Nights:\\033[0m {round(item['LowestAvgCity']['AvgMaxNights']):<5}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0190 seconds\n",
      "\n",
      "Average stay duration per property type per city:\n",
      "\n",
      "\u001b[1mProperty Type\u001b[0m          | \u001b[1mHighest Avg City\u001b[0m                 | \u001b[1mLowest Avg City\u001b[0m  \n",
      "================================================================================\n",
      "Tiny house             | Porto                            | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 5    \n",
      "--------------------------------------------------------------------------------\n",
      "Resort                 | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 7    \n",
      "--------------------------------------------------------------------------------\n",
      "Hostel                 | Oahu                             | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 10   \n",
      "--------------------------------------------------------------------------------\n",
      "Guest suite            | Barcelona                        | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Heritage hotel (India) | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 14             \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Villa                  | New York                         | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 15   \n",
      "--------------------------------------------------------------------------------\n",
      "Loft                   | Maui                             | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 28   \n",
      "--------------------------------------------------------------------------------\n",
      "Townhouse              | Rio De Janeiro                   | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Treehouse              | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Chalet                 | Sydney                           | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Camper/RV              | Montreal                         | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hut                    | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Bed and breakfast      | Other (International)            | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Condominium            | Other (Domestic)                 | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Campsite               | Oahu                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Other                  | Barcelona                        | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hotel                  | Porto                            | Other (International)\n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 35   \n",
      "--------------------------------------------------------------------------------\n",
      "Aparthotel             | New York                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 60   \n",
      "--------------------------------------------------------------------------------\n",
      "Nature lodge           | Maui                             | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 90   \n",
      "--------------------------------------------------------------------------------\n",
      "Cabin                  | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 120  \n",
      "--------------------------------------------------------------------------------\n",
      "Serviced apartment     | Oahu                             | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 180  \n",
      "--------------------------------------------------------------------------------\n",
      "Casa particular (Cuba) | Barcelona                        | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 235  \n",
      "--------------------------------------------------------------------------------\n",
      "Apartment              | Istanbul                         | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 5200438        \u001b[1mLowest Avg Nights:\u001b[0m 371  \n",
      "--------------------------------------------------------------------------------\n",
      "Cottage                | Hong Kong                        | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 410  \n",
      "--------------------------------------------------------------------------------\n",
      "Guesthouse             | Istanbul                         | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 470  \n",
      "--------------------------------------------------------------------------------\n",
      "Bungalow               | Montreal                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 485  \n",
      "--------------------------------------------------------------------------------\n",
      "House                  | Other (International)            | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 572  \n",
      "--------------------------------------------------------------------------------\n",
      "Boutique hotel         | Rio De Janeiro                   | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 578  \n",
      "--------------------------------------------------------------------------------\n",
      "Farm stay              | Hong Kong                        | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 846  \n",
      "--------------------------------------------------------------------------------\n",
      "Castle                 | Montreal                         | Montreal            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Barn                   | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Pension (South Korea)  | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Boat                   | Porto                            | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Earth house            | Rio De Janeiro                   | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Train                  | Sydney                           | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Houseboat              | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query6 = list(db.Listings.aggregate([\n",
    "    # Group by property type and city, converting maximum_nights to number\n",
    "     {\"$group\": {\n",
    "        \"_id\": {\"PropertyType\": \"$Property_Type\", \"City\": \"$Address.market\"},\n",
    "        \"AvgMaxNights\": {\"$avg\": {\"$toInt\": {\"$ifNull\": [\"$Maximum_Nights\", \"0\"]}}}\n",
    "    }},\n",
    "    # Group by property type to find min/max cities\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$_id.PropertyType\",\n",
    "        \"Cities\": {\"$push\": {\n",
    "            \"City\": {\"$ifNull\": [\"$_id.City\", \"Unknown\"]},\n",
    "            \"AvgMaxNights\": \"$AvgMaxNights\"\n",
    "        }}\n",
    "    }},\n",
    "    \n",
    "    # Sort cities by AvgMaxNights\n",
    "    {\"$sort\": {\"Cities.AvgMaxNights\": 1}},\n",
    "        \n",
    "    # Project min and max per property type\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"PropertyType\": \"$_id\",\n",
    "        \"HighestAvgCity\": {\"$arrayElemAt\": [\n",
    "            \"$Cities\",\n",
    "            {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$max\": \"$Cities.AvgMaxNights\"}]}\n",
    "        ]},\n",
    "        \"LowestAvgCity\": {\"$arrayElemAt\": [\n",
    "            \"$Cities\",\n",
    "            {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$min\": \"$Cities.AvgMaxNights\"}]}\n",
    "        ]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage stay duration per property type per city:\\n\")\n",
    "print(f\"{'\\033[1mProperty Type\\033[0m':<30} | {'\\033[1mHighest Avg City\\033[0m':<40} | {'\\033[1mLowest Avg City\\033[0m':<25}\")\n",
    "print(\"=\" * 80)\n",
    "for item in query6:\n",
    "    print(f\"{item['PropertyType']:<22} | {item['HighestAvgCity']['City']:<32} | {item['LowestAvgCity']['City']:<20}\")\n",
    "    print(f\"                         \\033[1mHighest Avg Nights:\\033[0m {round(item['HighestAvgCity']['AvgMaxNights']):<12}   \\033[1mLowest Avg Nights:\\033[0m {round(item['LowestAvgCity']['AvgMaxNights']):<5}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on Outliers:** The results show a very high maximum average ($5\\;200\\;438$ nights for **Apartments** in **Istanbul**). This is likely due to outlier values in the `maximum_nights` field (like $2\\;147\\;483\\;647$) skewing the average significantly. \n",
    "\n",
    "In a real-world scenario, these outliers should be investigated and potentially cleaned or filtered out before calculating the average, or a more robust metric like the *median* might be preferred to better represent typical stay lengths. However, following the prompt's instruction to use `maximum_nights` and calculate the average, we present the result as calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q6):** The logic is identical, just adapted to the new field names (`Property_Type`, `Address.market`, `Maximum_Nights`) in the `Listings` collection. Performance is slightly better in the new schema (0.039s vs 0.049s). This improvement is likely due to operating on the leaner `Listings` collection, even though the aggregation logic remains complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **⏳Advanced Difficulty Questions** [3 points per question]\n",
    "\n",
    "(Consider database optimization for these queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7)\tWe are creating a new webpage for hosts when setting up their account. \n",
    "#       It will list suggested typical amenities. \n",
    "#       This data will need to be available every time a host registers a property but is not expected to change very much. \n",
    "#       The starting point for the list will be all unique amenities currently listed in properties (across all documents). \n",
    "#       Optimize the database for this use case and show how the data should be queried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0386 seconds\n",
      "\n",
      "[{'Amenity': '24-hour check-in'},\n",
      " {'Amenity': 'Accessible-height bed'},\n",
      " {'Amenity': 'Accessible-height toilet'},\n",
      " {'Amenity': 'Air conditioning'},\n",
      " {'Amenity': 'Air purifier'}]\n",
      "\n",
      "\u001b[1mTotal unique amenities:\u001b[0m 185\n"
     ]
    }
   ],
   "source": [
    "# 7. All unique amenities across listings\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Unwind amenities array\n",
    "    {\"$unwind\": \"$amenities\"},\n",
    "    # Group to get unique amenities\n",
    "    {\"$group\": {\"_id\": \"$amenities\"}},\n",
    "    # Project output\n",
    "    {\"$project\": {\"_id\": 0, \"Amenity\": \"$_id\"}},\n",
    "    # Sort alphabetically\n",
    "    {\"$sort\": {\"Amenity\": 1}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result[:5])                                              # Display first few unique amenities\n",
    "print(f\"\\n\\33[1mTotal unique amenities:\\33[0m {len(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q7: `Computed Pattern`**\n",
    "\n",
    "We applied the **Computed Pattern** because the query requires retrieving all *unique* amenities across thousands of listings, which involves an expensive aggregation (`$unwind` + `$group`) every time the data is requested. This operation is inefficient and unnecessary, especially since the list of possible amenities changes infrequently.\n",
    "\n",
    "We expect a **significant reduction in query cost and response time** based on the replacement of a costly aggregation pipeline with a simple and fast `find()` operation on a small, precomputed `Amenities` collection. This improves performance for high-traffic endpoints, such as the host registration form, and avoids unnecessary compute overhead during peak usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0543 seconds\n",
      "\n",
      "[{'Amenity': '24-hour check-in',\n",
      "  'TotalFrequency': 748,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1825')},\n",
      " {'Amenity': 'Accessible-height bed',\n",
      "  'TotalFrequency': 248,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1826')},\n",
      " {'Amenity': 'Accessible-height toilet',\n",
      "  'TotalFrequency': 193,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1827')},\n",
      " {'Amenity': 'Air conditioning',\n",
      "  'TotalFrequency': 3431,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1828')},\n",
      " {'Amenity': 'Air purifier',\n",
      "  'TotalFrequency': 3,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1829')}]\n",
      "\n",
      "\u001b[1mTotal unique amenities:\u001b[0m 185\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create Amenities collection\n",
    "db.Amenities.drop()\n",
    "db.Listings.aggregate([\n",
    "    {\"$unwind\": \"$Amenities\"},\n",
    "    {\"$group\": {\"_id\": \"$Amenities\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$project\": {\"_id\": 0, \"Amenity\": \"$_id\", \"TotalFrequency\": \"$count\"}},\n",
    "    {\"$sort\": {\"Amenity\": 1}},\n",
    "    {\"$out\": \"Amenities\"}\n",
    "])\n",
    "\n",
    "# Query\n",
    "result = list(db.Amenities.find().limit(5))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)\n",
    "print(f\"\\n\\33[1mTotal unique amenities:\\33[0m {db.Amenities.count_documents({})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example of Suggested Amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mIndex information for Amenities collection:\u001b[0m\n",
      "{'Amenity_1': {'key': [('Amenity', 1)], 'v': 2},\n",
      " 'Amenity_text_TotalFrequency_-1': {'default_language': 'english',\n",
      "                                    'key': [('_fts', 'text'),\n",
      "                                            ('_ftsx', 1),\n",
      "                                            ('TotalFrequency', -1)],\n",
      "                                    'language_override': 'language',\n",
      "                                    'textIndexVersion': 3,\n",
      "                                    'v': 2,\n",
      "                                    'weights': SON([('Amenity', 1)])},\n",
      " 'TotalFrequency_-1': {'key': [('TotalFrequency', -1)], 'v': 2},\n",
      " '_id_': {'key': [('_id', 1)], 'v': 2}}\n"
     ]
    }
   ],
   "source": [
    "# Create index on Amenities collection for faster queries - In this case, we can use a text index for searching amenities\n",
    "# Since it is a index for a text field with non-text values, we can create a compound index with TotalFrequency for sorting \n",
    "db.Amenities.create_index([(\"Amenity\")])             # Create a single index on Amenity field for text search\n",
    "db.Amenities.create_index([(\"TotalFrequency\", -1)])  # Create a single index on TotalFrequency field for sorting\n",
    "db.Amenities.create_index([(\"Amenity\", \"text\"), \n",
    "                           (\"TotalFrequency\", -1)])  # Create index on Amenity field for text search and sort by frequency\n",
    "\n",
    "# Print the index information for the Amenities collection\n",
    "print(\"\\n\\033[1mIndex information for Amenities collection:\\033[0m\")\n",
    "pprint(db.Amenities.index_information())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider top amenities based on the most common ones in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0036 seconds\n",
      "\n",
      "[{'Amenity': 'Wifi',\n",
      "  'TotalFrequency': 5303,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18d9')},\n",
      " {'Amenity': 'Essentials',\n",
      "  'TotalFrequency': 5048,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1860')},\n",
      " {'Amenity': 'Kitchen',\n",
      "  'TotalFrequency': 4951,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1887')},\n",
      " {'Amenity': 'TV',\n",
      "  'TotalFrequency': 4295,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18c7')},\n",
      " {'Amenity': 'Hangers',\n",
      "  'TotalFrequency': 4226,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc1877')}]\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {},\n",
      "             'find': 'Amenities',\n",
      "             'limit': 5,\n",
      "             'singleBatch': True,\n",
      "             'sort': {'TotalFrequency': -1}},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 5,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 5,\n",
      "                                                       'alreadyHasObj': 0,\n",
      "                                                       'docsExamined': 5,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'inputStage': {'advanced': 5,\n",
      "                                                                      'direction': 'forward',\n",
      "                                                                      'dupsDropped': 0,\n",
      "                                                                      'dupsTested': 0,\n",
      "                                                                      'executionTimeMillisEstimate': 0,\n",
      "                                                                      'indexBounds': {'TotalFrequency': ['[MaxKey, '\n",
      "                                                                                                         'MinKey]']},\n",
      "                                                                      'indexName': 'TotalFrequency_-1',\n",
      "                                                                      'indexVersion': 2,\n",
      "                                                                      'isEOF': 0,\n",
      "                                                                      'isMultiKey': False,\n",
      "                                                                      'isPartial': False,\n",
      "                                                                      'isSparse': False,\n",
      "                                                                      'isUnique': False,\n",
      "                                                                      'keyPattern': {'TotalFrequency': -1},\n",
      "                                                                      'keysExamined': 5,\n",
      "                                                                      'multiKeyPaths': {'TotalFrequency': []},\n",
      "                                                                      'nReturned': 5,\n",
      "                                                                      'needTime': 0,\n",
      "                                                                      'needYield': 0,\n",
      "                                                                      'restoreState': 0,\n",
      "                                                                      'saveState': 0,\n",
      "                                                                      'seeks': 1,\n",
      "                                                                      'stage': 'IXSCAN',\n",
      "                                                                      'works': 5},\n",
      "                                                       'isEOF': 0,\n",
      "                                                       'nReturned': 5,\n",
      "                                                       'needTime': 0,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'stage': 'FETCH',\n",
      "                                                       'works': 5},\n",
      "                                        'isCached': False,\n",
      "                                        'isEOF': 1,\n",
      "                                        'limitAmount': 5,\n",
      "                                        'nReturned': 5,\n",
      "                                        'needTime': 0,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'LIMIT',\n",
      "                                        'works': 6},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 1,\n",
      "                    'nReturned': 5,\n",
      "                    'totalDocsExamined': 5,\n",
      "                    'totalKeysExamined': 5},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Amenities',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {},\n",
      "                  'planCacheKey': '5ABB3E72',\n",
      "                  'planCacheShapeHash': '24645C5A',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': '24645C5A',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'inputStage': {'direction': 'forward',\n",
      "                                                                'indexBounds': {'TotalFrequency': ['[MaxKey, '\n",
      "                                                                                                   'MinKey]']},\n",
      "                                                                'indexName': 'TotalFrequency_-1',\n",
      "                                                                'indexVersion': 2,\n",
      "                                                                'isMultiKey': False,\n",
      "                                                                'isPartial': False,\n",
      "                                                                'isSparse': False,\n",
      "                                                                'isUnique': False,\n",
      "                                                                'keyPattern': {'TotalFrequency': -1},\n",
      "                                                                'multiKeyPaths': {'TotalFrequency': []},\n",
      "                                                                'stage': 'IXSCAN'},\n",
      "                                                 'stage': 'FETCH'},\n",
      "                                  'isCached': False,\n",
      "                                  'limitAmount': 5,\n",
      "                                  'stage': 'LIMIT'}},\n",
      " 'queryShapeHash': '0C250117B11D83F876C46ABB2AFE4B7B95F2A4472488EDF3ED2091E6BD9F4F45',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run a query to find top 5 amenities with the highest frequency\n",
    "start_time = time.time()\n",
    "result = list(db.Amenities.find().sort(\"TotalFrequency\", -1).limit(5))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)  # Display top 5 amenities with highest frequency\n",
    "\n",
    "\n",
    "# Output the information about query performance (Q7)\n",
    "pprint(db.Amenities.find().sort(\"TotalFrequency\", -1).limit(5).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider that in the webpage for host registration, it will suggest the amenities after input some words. For example, if the host types \"pool\", it will suggest the following amenities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuerying Amenities collection for amenities containing 'pool':\u001b[0m\n",
      "Execution time: 0.0032 seconds\n",
      "\n",
      "[{'Amenity': 'Pool',\n",
      "  'TotalFrequency': 819,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18a5')},\n",
      " {'Amenity': 'Pool with pool hoist',\n",
      "  'TotalFrequency': 4,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18a6')},\n",
      " {'Amenity': 'Private pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18ab')},\n",
      " {'Amenity': 'Shared pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18b5')},\n",
      " {'Amenity': 'Swimming pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fcea734f6288c2cacc18c6')}]\n",
      "\n",
      "\u001b[1mTotal amenities containing 'pool':\u001b[0m 5\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {'Amenity': {'$options': 'i', '$regex': 'pool'}},\n",
      "             'find': 'Amenities'},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 5,\n",
      "                                        'alreadyHasObj': 0,\n",
      "                                        'docsExamined': 5,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 5,\n",
      "                                                       'direction': 'forward',\n",
      "                                                       'dupsDropped': 0,\n",
      "                                                       'dupsTested': 0,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'filter': {'Amenity': {'$options': 'i',\n",
      "                                                                              '$regex': 'pool'}},\n",
      "                                                       'indexBounds': {'Amenity': ['[\"\", '\n",
      "                                                                                   '{})',\n",
      "                                                                                   '[/pool/i, '\n",
      "                                                                                   '/pool/i]']},\n",
      "                                                       'indexName': 'Amenity_1',\n",
      "                                                       'indexVersion': 2,\n",
      "                                                       'isEOF': 1,\n",
      "                                                       'isMultiKey': False,\n",
      "                                                       'isPartial': False,\n",
      "                                                       'isSparse': False,\n",
      "                                                       'isUnique': False,\n",
      "                                                       'keyPattern': {'Amenity': 1},\n",
      "                                                       'keysExamined': 185,\n",
      "                                                       'multiKeyPaths': {'Amenity': []},\n",
      "                                                       'nReturned': 5,\n",
      "                                                       'needTime': 180,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'seeks': 1,\n",
      "                                                       'stage': 'IXSCAN',\n",
      "                                                       'works': 186},\n",
      "                                        'isCached': False,\n",
      "                                        'isEOF': 1,\n",
      "                                        'nReturned': 5,\n",
      "                                        'needTime': 180,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'FETCH',\n",
      "                                        'works': 186},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 0,\n",
      "                    'nReturned': 5,\n",
      "                    'totalDocsExamined': 5,\n",
      "                    'totalKeysExamined': 185},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Amenities',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {'Amenity': {'$options': 'i',\n",
      "                                              '$regex': 'pool'}},\n",
      "                  'planCacheKey': 'AA26591A',\n",
      "                  'planCacheShapeHash': 'EE46BBE5',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': 'EE46BBE5',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                 'filter': {'Amenity': {'$options': 'i',\n",
      "                                                                        '$regex': 'pool'}},\n",
      "                                                 'indexBounds': {'Amenity': ['[\"\", '\n",
      "                                                                             '{})',\n",
      "                                                                             '[/pool/i, '\n",
      "                                                                             '/pool/i]']},\n",
      "                                                 'indexName': 'Amenity_1',\n",
      "                                                 'indexVersion': 2,\n",
      "                                                 'isMultiKey': False,\n",
      "                                                 'isPartial': False,\n",
      "                                                 'isSparse': False,\n",
      "                                                 'isUnique': False,\n",
      "                                                 'keyPattern': {'Amenity': 1},\n",
      "                                                 'multiKeyPaths': {'Amenity': []},\n",
      "                                                 'stage': 'IXSCAN'},\n",
      "                                  'isCached': False,\n",
      "                                  'stage': 'FETCH'}},\n",
      " 'queryShapeHash': '0526FEDBB2032B0822DC5D2997B97C46B3EEBA22B2D743585F4AFCB7968E4199',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run a query to find all amenities containing \"pool\" (Example)\n",
    "# This is a case-insensitive search for \"pool\" in the amenities\n",
    "# Note: The regex search is case-insensitive due to the \"$options\": \"i\" flag\n",
    "\n",
    "print(\"\\n\\033[1mQuerying Amenities collection for amenities containing 'pool':\\033[0m\")\n",
    "start_time = time.time()\n",
    "result = list(db.Amenities.find({\"Amenity\": {\"$regex\": \"pool\", \"$options\": \"i\"}}))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)  # Display first few results\n",
    "print(f\"\\n\\033[1mTotal amenities containing 'pool':\\033[0m {len(result)}\")\n",
    "\n",
    "# Output the information about query performance (Q7)\n",
    "pprint(db.Amenities.find({\"Amenity\": {\"$regex\": \"pool\", \"$options\": \"i\"}}).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q7):** By creating the `Amenities` collection (where we compute the field `CountFrequency` for each unique amenity - **Computed Pattern**), fetching the list of unique amenities is reduced from an aggregation across all listings (original query, ~0.06s) to a simple `find()` on the dedicated collection (new query, negligible time, dominated by the one-time creation ~0.08s). \n",
    "- For the 1st use case described (top 5 most common amenities), this is a significant performance improvement. The index `TotalFrequency_-1` improves matches on the `CountFrequency` field, making searchesvery efficient (explain plan shows `IXSCAN`).\n",
    "- For the 2nd use case described (frequent reads for host registration), this is a significant performance improvement. The index `Amenity_1` further optimizes matches *within* this collection, making searches like the \"pool\" example very efficient (explain plan shows `IXSCAN`).\n",
    "  - For both cases, the compound index `Amenity_text_TotalFrequency_-1` is not the best choice, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop compound index on Amenities collection \n",
    "db.Amenities.drop_index('Amenity_text_TotalFrequency_-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8)\tWe plan to track our reviewers better. \n",
    "#       We want to create a webpage that shows the top 20 reviewers and the count of the number of reviews of each of these reviewers. \n",
    "#       This webpage should be kept up to date. It should also have a link to return the number of reviews for a given reviewer ID or Name \n",
    "#           (show how to query for number of reviews by ID or query quickly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.4869 seconds\n",
      "\n",
      "[{'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'},\n",
      " {'ReviewCount': 13, 'ReviewerId': '67084875', 'ReviewerName': 'Nick'},\n",
      " {'ReviewCount': 10, 'ReviewerId': '2961855', 'ReviewerName': 'Uge'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '162027327', 'ReviewerName': 'Thien'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '20991911', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '55241576', 'ReviewerName': 'Courtney'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '1705870', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '60816198', 'ReviewerName': 'Todd'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '12679057', 'ReviewerName': 'Jodi'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '69140895', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '78093968', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '47303133', 'ReviewerName': 'Lance'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '25715809', 'ReviewerName': 'Megan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '24667379', 'ReviewerName': 'Karen'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '57325457', 'ReviewerName': 'Mary'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '93859831', 'ReviewerName': 'Pierre'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '73708321', 'ReviewerName': 'Gonzalo'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '86665925', 'ReviewerName': 'Chris'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '128210181', 'ReviewerName': 'Branden'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '61469899', 'ReviewerName': 'Erik'}]\n"
     ]
    }
   ],
   "source": [
    "# 8. Top 20 reviewers and count by ID or Name\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Unwind reviews\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    # Group by reviewer\n",
    "    {\"$group\": {\"_id\": \"$reviews.reviewer_id\", \"ReviewerName\": {\"$first\": \"$reviews.reviewer_name\"}, \"ReviewCount\": {\"$sum\": 1}}},\n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"ReviewCount\": -1}},\n",
    "    # Limit to 20\n",
    "    {\"$limit\": 20},\n",
    "    # Project output\n",
    "    {\"$project\": {\"_id\": 0, \"ReviewerId\": \"$_id\", \"ReviewerName\": 1, \"ReviewCount\": 1}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mReviews for ID 51483096:\u001b[0m 1 |  \u001b[1mTime:\u001b[0m 0.1357 seconds\n",
      "\u001b[1mReviews for Name Angela:\u001b[0m 247 |  \u001b[1mTime:\u001b[0m 0.1313 seconds\n"
     ]
    }
   ],
   "source": [
    "# Function to get review count by ID or Name\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name.\n",
    "\n",
    "    Args:\n",
    "        reviewer_id (int, optional): The ID of the reviewer. Defaults to None.\n",
    "        reviewer_name (str, optional): The name of the reviewer. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the count of reviews and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    match = {}\n",
    "    if reviewer_id:\n",
    "        match[\"reviews.reviewer_id\"] = reviewer_id\n",
    "    elif reviewer_name:\n",
    "        match[\"reviews.reviewer_name\"] = reviewer_name\n",
    "    pipeline = [\n",
    "        {\"$unwind\": \"$reviews\"},\n",
    "        {\"$match\": match},\n",
    "        {\"$group\": {\"_id\": None, \"Count\": {\"$sum\": 1}}},\n",
    "        {\"$project\": {\"_id\": 0, \"Count\": 1}}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[0][\"Count\"] if result else 0, exec_time\n",
    "\n",
    "reviewer_id=\"51483096\"\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\033[1mReviews for ID {reviewer_id}:\\033[0m {count} |  \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name=\"Angela\"\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mReviews for Name {reviewer_name}:\\033[0m {count} |  \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q8: `Computed Pattern` & `Indexing`**\n",
    "\n",
    "We applied the **Computed Pattern** and **Indexing** because **Q8** requires both listing the top 20 reviewers by number of reviews and efficiently retrieving the review count for any specific reviewer. In the original schema, this computation happens on-the-fly through aggregations on embedded arrays, which is inefficient on large datasets or when these queries are frequent.\n",
    "\n",
    "We expect improved performance with the addition of an index on `Reviewer_ID` in the `Reviews` collection allows rapid lookups using `count_documents()` for individual reviewers.\n",
    "\n",
    "*   **Further Optimization (Computed Pattern):** To make fetching the top 20 *and* individual counts consistently fast, we could add a `ReviewCount` field to the `Reviewers` collection and update it whenever a review is added/deleted (using `$inc`). This implements the **Computed Pattern** fully for review counts. The current implementation prioritizes normalization and relies on indexing for the fast lookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 10.1045 seconds\n",
      "\n",
      "[{'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'},\n",
      " {'ReviewCount': 13, 'ReviewerId': '67084875', 'ReviewerName': 'Nick'},\n",
      " {'ReviewCount': 10, 'ReviewerId': '2961855', 'ReviewerName': 'Uge'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '20991911', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '162027327', 'ReviewerName': 'Thien'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '60816198', 'ReviewerName': 'Todd'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '1705870', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '69140895', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '12679057', 'ReviewerName': 'Jodi'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '55241576', 'ReviewerName': 'Courtney'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '78093968', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '47303133', 'ReviewerName': 'Lance'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '128210181', 'ReviewerName': 'Branden'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '61469899', 'ReviewerName': 'Erik'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '25715809', 'ReviewerName': 'Megan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '34005800', 'ReviewerName': 'Dan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '57325457', 'ReviewerName': 'Mary'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '93859831', 'ReviewerName': 'Pierre'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '86665925', 'ReviewerName': 'Chris'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '24667379', 'ReviewerName': 'Karen'}]\n",
      "\n",
      "\u001b[1mReviews for ID 20775242:\u001b[0m 24 | \u001b[1mTime:\u001b[0m 0.0037 seconds\n",
      "\u001b[1mReviews for Name Filipe:\u001b[0m [{'Count': 44}] | \u001b[1mTime:\u001b[0m 10.1860 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query8 = list(db.Reviews.aggregate([\n",
    "    # Group by Reviewer_ID to count reviews\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Reviewer_ID\",\n",
    "        \"ReviewCount\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Join with Reviewers collection to get names\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Reviewers\",\n",
    "        \"localField\": \"_id\",\n",
    "        \"foreignField\": \"Reviewer_ID\",\n",
    "        \"as\": \"reviewer_info\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the reviewer_info array\n",
    "    {\"$unwind\": \"$reviewer_info\"},\n",
    "    \n",
    "    # Project the required fields\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerId\": \"$_id\",\n",
    "        \"ReviewerName\": \"$reviewer_info.Reviewer_Name\",\n",
    "        \"ReviewCount\": 1\n",
    "    }},\n",
    "    \n",
    "    # Sort by review count in descending order\n",
    "    {\"$sort\": {\"ReviewCount\": -1}},\n",
    "    \n",
    "    # Limit to the top 20 reviewers\n",
    "    {\"$limit\": 20}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(query8)\n",
    "\n",
    "# Lookup function\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name.\n",
    "    Args:\n",
    "        reviewer_id (int): The ID of the reviewer.\n",
    "        reviewer_name (str): The name of the reviewer.\n",
    "        \n",
    "    Returns:\n",
    "        result (int): The count of reviews for the specified reviewer ID.\n",
    "        exec_time (float): The time taken to execute the query.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if reviewer_id:\n",
    "        result = db.Reviews.count_documents({\"Reviewer_ID\": reviewer_id})\n",
    "    elif reviewer_name:\n",
    "        pipeline = [\n",
    "            # Join Reviews with Reviewers to get names\n",
    "            {\"$lookup\": {\n",
    "                \"from\": \"Reviewers\",\n",
    "                \"localField\": \"Reviewer_ID\",\n",
    "                \"foreignField\": \"Reviewer_ID\",\n",
    "                \"as\": \"reviewer_info\"\n",
    "            }},\n",
    "            \n",
    "            # Unwind the reviewer_info array\n",
    "            {\"$unwind\": \"$reviewer_info\"},\n",
    "            \n",
    "            # Match the reviewer name\n",
    "            {\"$match\": {\"reviewer_info.Reviewer_Name\": reviewer_name}},\n",
    "            \n",
    "            # Group to count reviews\n",
    "            {\"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"Count\": {\"$sum\": 1}\n",
    "            }},\n",
    "            \n",
    "            # Project the count\n",
    "            {\"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"Count\": 1\n",
    "            }}\n",
    "        ]\n",
    "        result = db.Reviews.aggregate(pipeline)\n",
    "        result = list(result)\n",
    "    exec_time = time.time() - start_time\n",
    "    return result, exec_time\n",
    "\n",
    "reviewer_id = query8[0][\"ReviewerId\"]\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\n\\033[1mReviews for ID {reviewer_id}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name = query8[0][\"ReviewerName\"]\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mReviews for Name {reviewer_name}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance:\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {'Reviewer_ID': '20775242'},\n",
      "             'find': 'Reviewers'},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 1,\n",
      "                                        'alreadyHasObj': 0,\n",
      "                                        'docsExamined': 1,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 1,\n",
      "                                                       'direction': 'forward',\n",
      "                                                       'dupsDropped': 0,\n",
      "                                                       'dupsTested': 0,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'indexBounds': {'Reviewer_ID': ['[\"20775242\", '\n",
      "                                                                                       '\"20775242\"]']},\n",
      "                                                       'indexName': 'Reviewer_ID_1',\n",
      "                                                       'indexVersion': 2,\n",
      "                                                       'isEOF': 1,\n",
      "                                                       'isMultiKey': False,\n",
      "                                                       'isPartial': False,\n",
      "                                                       'isSparse': False,\n",
      "                                                       'isUnique': False,\n",
      "                                                       'keyPattern': {'Reviewer_ID': 1},\n",
      "                                                       'keysExamined': 1,\n",
      "                                                       'multiKeyPaths': {'Reviewer_ID': []},\n",
      "                                                       'nReturned': 1,\n",
      "                                                       'needTime': 0,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'seeks': 1,\n",
      "                                                       'stage': 'IXSCAN',\n",
      "                                                       'works': 2},\n",
      "                                        'isCached': True,\n",
      "                                        'isEOF': 1,\n",
      "                                        'nReturned': 1,\n",
      "                                        'needTime': 0,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'FETCH',\n",
      "                                        'works': 2},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 0,\n",
      "                    'nReturned': 1,\n",
      "                    'totalDocsExamined': 1,\n",
      "                    'totalKeysExamined': 1},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Reviewers',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {'Reviewer_ID': {'$eq': '20775242'}},\n",
      "                  'planCacheKey': '646DF628',\n",
      "                  'planCacheShapeHash': '1DFD2D2F',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': '1DFD2D2F',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                 'indexBounds': {'Reviewer_ID': ['[\"20775242\", '\n",
      "                                                                                 '\"20775242\"]']},\n",
      "                                                 'indexName': 'Reviewer_ID_1',\n",
      "                                                 'indexVersion': 2,\n",
      "                                                 'isMultiKey': False,\n",
      "                                                 'isPartial': False,\n",
      "                                                 'isSparse': False,\n",
      "                                                 'isUnique': False,\n",
      "                                                 'keyPattern': {'Reviewer_ID': 1},\n",
      "                                                 'multiKeyPaths': {'Reviewer_ID': []},\n",
      "                                                 'stage': 'IXSCAN'},\n",
      "                                  'isCached': True,\n",
      "                                  'stage': 'FETCH'}},\n",
      " 'queryShapeHash': '5E7F009528D5DCCD5A14653125C8DE1D0E6687FB8F80EFC43CAE62479C8EAE49',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q8)\n",
    "print(\"\\n\\033[1mQuery performance:\\033[0m\")\n",
    "pprint(db.Reviewers.find({\"Reviewer_ID\": reviewer_id}).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q8):** The new schema query for the top 20 involves aggregation and lookups, making it slower (16.9s) than the original single-collection aggregation (0.9s). However, the *lookup* function (`get_review_count`) is significantly faster (0.006s) thanks to the dedicated `Reviews` collection and the index on `Reviewer_ID`. The `explain()` output confirms the query uses the `Reviewer_ID_1` index (**IXSCAN**) for the fast lookup, examining only 1 key and 1 document. \n",
    "\n",
    "This demonstrates the benefit of the new schema for the frequent, targeted lookup requirement, while the top-20 list might be better handled by pre-computation (**Computed Pattern**) in a production scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Computed Pattern for Review Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146640/146640 [02:30<00:00, 973.17it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ReviewCount': 1,\n",
      "  'Reviewer_ID': '170827308',\n",
      "  'Reviewer_Name': 'Mitchell',\n",
      "  '_id': '170827308'},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '136093339',\n",
      "  'Reviewer_Name': 'Jaeryung',\n",
      "  '_id': '136093339'},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '35799823',\n",
      "  'Reviewer_Name': 'Maike',\n",
      "  '_id': '35799823'},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '62639273',\n",
      "  'Reviewer_Name': 'Gabriela',\n",
      "  '_id': '62639273'},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '8758057',\n",
      "  'Reviewer_Name': 'Angie',\n",
      "  '_id': '8758057'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 'ReviewCount' field for each reviewer in the Reviewers collection and add it to the collection\n",
    "\n",
    "# Start by aggregating the review counts from the Reviews collection\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Reviewer_ID\",         # Group by reviewer identifier\n",
    "        \"ReviewCount\": {\"$sum\": 1}       # Sum up the number of reviews per reviewer\n",
    "    }}\n",
    "]\n",
    "\n",
    "# Execute the aggregation on the Reviews collection\n",
    "review_counts = list(db.Reviews.aggregate(pipeline))\n",
    "\n",
    "# Update each reviewer document in the Reviewers collection with the computed ReviewCount\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/update/set/\n",
    "for rc in tqdm(review_counts):\n",
    "    reviewer_id = rc[\"_id\"]\n",
    "    count = rc[\"ReviewCount\"]\n",
    "    \n",
    "    # Update the reviewer document by setting the ReviewCount field\n",
    "    db.Reviewers.update_one(\n",
    "        {\"Reviewer_ID\": reviewer_id}, \n",
    "        {\"$set\": {\"ReviewCount\": count}}\n",
    "    )\n",
    "\n",
    "# Verify the update by checking the first few documents in the Reviewers collection\n",
    "result = list(db.Reviewers.find().limit(5))\n",
    "pprint(result)                                          # Display first few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReviewCount_-1'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index on the ReviewCount field for faster queries\n",
    "db.Reviewers.create_index([(\"ReviewCount\", -1)])    # Create index on ReviewCount field for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mOptimized Reviews for ID 20775242:\u001b[0m 24 | \u001b[1mTime:\u001b[0m 0.0025 seconds\n",
      "\u001b[1mOptimized Reviews for Name Filipe:\u001b[0m 1 | \u001b[1mTime:\u001b[0m 0.0074 seconds\n"
     ]
    }
   ],
   "source": [
    "# Update the function to optimize the query for review count by ID or Name\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name. (Optimized)\n",
    "\n",
    "    Args:\n",
    "        reviewer_id (int, optional): The ID of the reviewer. Defaults to None.\n",
    "        reviewer_name (str, optional): The name of the reviewer. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the count of reviews and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    match = {}\n",
    "    if reviewer_id:\n",
    "        match[\"Reviewer_ID\"] = reviewer_id\n",
    "    elif reviewer_name:\n",
    "        match[\"Reviewer_Name\"] = reviewer_name\n",
    "    result = db.Reviewers.find_one(match, {\"ReviewCount\": 1})\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[\"ReviewCount\"] if result else 0, exec_time\n",
    "\n",
    "# Test the optimized function\n",
    "reviewer_id = query8[0][\"ReviewerId\"]\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\n\\033[1mOptimized Reviews for ID {reviewer_id}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name = query8[0][\"ReviewerName\"]\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mOptimized Reviews for Name {reviewer_name}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "# **COMENTAR**\n",
    "\n",
    "> **Optimization Analysis (Q8 - Function):** The `get_review_count` function, when using the pre-computed `ReviewCount` field in the `Reviewers` collection (**Computed Pattern**), demonstrates the performance benefit for the 2nd part of **Q8's** requirement (fast lookup by ID or Name). Instead of aggregating across the large `Reviews` collection (original query ~0.14s), we now perform a simple, indexed `find_one` operation on the `Reviewers` collection, resulting in near-instantaneous retrieval (0.002s for ID lookup, 0.007s for name lookup after index). This highlights the effectiveness of the **Computed Pattern** for frequently accessed, derived data like counts.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9)\tFor each property we store review scores across different metrics (accuracy, check-in, cleanliness etc). \n",
    "#       We consider adding more metrics, although there is no clarity on what these will be. \n",
    "#       We want to be able to easily query the average score across all of these metrics, including any new metrics that might be added without changing the query. \n",
    "#       Adjust the data model so this can be done and show the query for an example property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0031 seconds\n",
      "\n",
      "Average score across all review metrics for property ID 10006546: \u001b[1m9.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 9. Average score across all review metrics for a property\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"_id\": \"10006546\"}},\n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"all_fields\": {\"$objectToArray\": \"$$ROOT\"}\n",
    "    }},\n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$all_fields\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$match\": {\n",
    "        \"all_fields.k\": {\"$regex\": \"^review_scores_\"}\n",
    "    }},\n",
    "    # Project the score values, handling nulls\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Metric\": \"$all_fields.k\",\n",
    "        \"Score\": {\"$ifNull\": [\"$all_fields.v\", 0]}  # Default to 0 if null\n",
    "    }},\n",
    "    \n",
    "    # [{'Metric': 'review_scores_checkin', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_cleanliness', 'Score': 9},\n",
    "    # {'Metric': 'review_scores_communication', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_location', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_rating', 'Score': 8.9},\n",
    "    # {'Metric': 'review_scores_value', 'Score': 9}]\n",
    "        \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Score\"}\n",
    "    }},\n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]},\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "# pprint(result) \n",
    "print(f\"\\nAverage score across all review metrics for property ID 10006546: \\033[1m{result[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The original query assumes all scores have the prefix `review_scores_` and that the range is $0-10$. In the new schema, we don't have this certainty, so we use the **Subdocument/Attribute Pattern**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema** (More Flexible and Automatic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q9: `Attribute Pattern`**\n",
    "\n",
    "We applied the **Attribute Pattern** because **Q9** requires averaging *all* review score metrics — including future, yet-to-be-defined ones — without modifying the aggregation logic. The original schema stored review scores in separate fields (e.g., `review_scores_checkin`, `review_scores_cleanliness`), making dynamic querying harder and requiring updates whenever new metrics are introduced.\n",
    "\n",
    "We expect flexibility and maintainability based on the following:\n",
    "\n",
    "- We restructured the schema into a single subdocument called `Review_Scores`, where each metric (e.g., Checkin, Cleanliness, Value) is a key and its score is the value.\n",
    "- We use `$objectToArray` in the aggregation pipeline, which transforms the `Review_Scores` subdocument into an iterable array of key-value pairs. We can then compute the average over all values dynamically (`$avg: \"$Scores.v\"`), regardless of metric names.\n",
    "- This change means that adding new review score types (e.g., `XFactor` from Q14) requires no schema or query modification — they are automatically included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0025 seconds\n",
      "\n",
      "Average score for property ID 10006546: \u001b[1m9.48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pipeline_query9 =[\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"Listing_ID\": \"10006546\"}},\n",
    "    \n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Scores\": {\"$objectToArray\": \"$Review_Scores\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$Scores\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Scores.v\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\"AvgScore\": {\"$round\": [\"$AvgScore\", 2]}}}\n",
    "]\n",
    "query9 = list(db.Listings.aggregate(pipeline_query9))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage score for property ID 10006546: \\033[1m{query9[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance:\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Listings',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\xe8\"\\xb30\\xbfGN\\x86\\xad\\xe9l\\xdaS\\x81\\xc8\\xf9', 4)},\n",
      "             'pipeline': [{'$match': {'Listing_ID': '10006546'}},\n",
      "                          {'$project': {'Scores': {'$objectToArray': '$Review_Scores'},\n",
      "                                        '_id': 0}},\n",
      "                          {'$unwind': '$Scores'},\n",
      "                          {'$group': {'AvgScore': {'$avg': '$Scores.v'},\n",
      "                                      '_id': None}},\n",
      "                          {'$project': {'AvgScore': {'$round': ['$AvgScore',\n",
      "                                                                2]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '4C8AAFB3005E1E3D4880B227EB45D8AC279DCE9C5AC3C628B30E36683BB5BDA8',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Listings',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {'Listing_ID': {'$eq': '10006546'}},\n",
      "                                          'planCacheKey': '0EE1C956',\n",
      "                                          'planCacheShapeHash': '4514207D',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': '4514207D',\n",
      "                                          'rejectedPlans': [],\n",
      "                                          'winningPlan': {'inputStage': {'inputStage': {'direction': 'forward',\n",
      "                                                                                        'indexBounds': {'Listing_ID': ['[\"10006546\", '\n",
      "                                                                                                                       '\"10006546\"]']},\n",
      "                                                                                        'indexName': 'Listing_ID_1',\n",
      "                                                                                        'indexVersion': 2,\n",
      "                                                                                        'isMultiKey': False,\n",
      "                                                                                        'isPartial': False,\n",
      "                                                                                        'isSparse': False,\n",
      "                                                                                        'isUnique': False,\n",
      "                                                                                        'keyPattern': {'Listing_ID': 1},\n",
      "                                                                                        'multiKeyPaths': {'Listing_ID': []},\n",
      "                                                                                        'stage': 'IXSCAN'},\n",
      "                                                                         'stage': 'FETCH'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_DEFAULT',\n",
      "                                                          'transformBy': {'Scores': {'$objectToArray': ['$Review_Scores']},\n",
      "                                                                          '_id': False}}}}},\n",
      "            {'$unwind': {'path': '$Scores'}},\n",
      "            {'$group': {'AvgScore': {'$avg': '$Scores.v'},\n",
      "                        '_id': {'$const': None}}},\n",
      "            {'$project': {'AvgScore': {'$round': ['$AvgScore', {'$const': 2}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q9)\n",
    "print(\"\\n\\033[1mQuery performance:\\033[0m\")\n",
    "pprint(db.command(\"aggregate\", \"Listings\", pipeline=pipeline_query9, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q9):** The new schema query using the **Attribute Pattern** (`$objectToArray` on the `Review_Scores` subdocument) is more flexible and arguably cleaner than the original query relying on `$regex` matching field names. The performance is excellent in both cases (0.007s vs 0.005s) because the query targets a single document using the indexed `_id` (or `Listing_ID`). The primary benefit here is the schema's adaptability to new review metrics without requiring query modification, as demonstrated in **Q14**. The `explain()` output shows the query efficiently uses the `Listing_ID_1` index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the new schema, we assume all scores are stored in the `Review_Scores` subdocument. To optimize the query, we can apply the **Computed Pattern** and store the average score as an attribute within the `Listings` document, providing a summary of scores. This avoids recalculating the average each time we need the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Computed Pattern** (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computed Pattern - Listings.Review_Scores_Avg\n",
    "# Create a new field in the Listings collection to store the average review score\n",
    "db.Listings.update_many({}, [\n",
    "    {\"$set\": {\n",
    "        \"Review_Scores_Avg\": {\n",
    "            \"$avg\": [\n",
    "                \"$Review_Scores.Checkin\",\n",
    "                \"$Review_Scores.Cleanliness\",\n",
    "                \"$Review_Scores.Communication\",\n",
    "                \"$Review_Scores.Location\",\n",
    "                \"$Review_Scores.Rating\",\n",
    "                \"$Review_Scores.Value\"\n",
    "            ]\n",
    "        }\n",
    "    }}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0031 seconds\n",
      "\n",
      "Average review score for property ID 10006546: \u001b[1m9.48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Query the average review score for a specific property\n",
    "start_time = time.time()\n",
    "property_id = \"10006546\"\n",
    "property_avg_score = db.Listings.find_one({\"Listing_ID\": property_id}, {\"Review_Scores_Avg\": 1})\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage review score for property ID {property_id}: \\033[1m{round(property_avg_score['Review_Scores_Avg'], 2)}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Computed Pattern (Q9 - Optional):** As shown here, if retrieving the average score is a very frequent operation, we can apply the **Computed Pattern**. We calculate the average *once* (or periodically) and store it directly in the `Listings` document (e.g., as `Review_Scores_Avg`). Subsequent reads for the average become simple, fast `find()` operations (0.004s). The trade-off is the need to update this computed field whenever the underlying scores change (e.g., when **Q14** adds 'XFactor')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10)\tWe aim to have better access to information about transaction, \n",
    "#       we wish to develop a search engine that can calculate the average value of transactions in a given period of time quickly for a given property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Matches - Remove the date filter temporarily to see if any transactions exist\n",
    "# pipeline = [\n",
    "#     {\"$match\": {\"_id\": \"10006546\"}},\n",
    "#     {\"$unwind\": \"$transactions.transactions\"},\n",
    "#     {\"$limit\": 5}\n",
    "# ]\n",
    "# pprint(list(db.listingsAndReviews_HW2.aggregate(pipeline))) # Existes transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0044 seconds\n",
      "\n",
      "Average transaction value for property ID 10006546 between 2008-01-01 and 2009-01-01: \u001b[1m132.11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 10. Average transaction value for a property in a date range\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    {\"$match\": {\"_id\": \"10006546\"}},                                            # Match the specific property ID\n",
    "    {\"$unwind\": \"$transactions.transactions\"},                                  # Unwind transactions\n",
    "    \n",
    "    # Convert date strings to ISODate and filter\n",
    "    {\"$match\": {\n",
    "        \"transactions.transactions.date\": {\n",
    "            \"$gte\": datetime.strptime(\"2008-01-01\", \"%Y-%m-%d\"),\n",
    "            \"$lte\": datetime.strptime(\"2009-01-01\", \"%Y-%m-%d\")\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$transactions.transactions.price\"}}  # Convert price to number\n",
    "    }},\n",
    "    {\"$project\": {\"_id\": 0, \"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "# pprint(result)\n",
    "print(f\"\\nAverage transaction value for property ID 10006546 between 2008-01-01 and 2009-01-01: \\033[1m{result[0]['AvgValue']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q10: `Subset Pattern` & `Indexing`**\n",
    "\n",
    "We applied the **[Subset Pattern](https://www.mongodb.com/blog/post/building-with-patterns-the-subset-pattern)** because **Q10** requires calculating the average transaction price within a time window, per listing. In the original schema, transactions were stored as embedded arrays inside listing documents, making queries inefficient for scalability.\n",
    "\n",
    "We expect a significant performance improvement based on the following:\n",
    "\n",
    "- We moved the `transactions` array into its own `Transactions` collection, where each document stores the `Listing_ID`, `Transaction_Date`, and `Price`.\n",
    "- We added indexes on both `Listing_ID` and `Transaction_Date` to optimize for range queries.\n",
    "- This schema enables targeted filtering directly on the `Transactions` collection using indexed fields, without scanning or loading the full listing document.\n",
    "\n",
    "This transformation improves query performance, especially for time-bounded analytics tasks. It also keeps listing documents lighter and more focused, supporting better separation of concerns in the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0062 seconds\n",
      "\n",
      "Average transaction value for property ID 10006546 (2008-01-01 to 2009-01-01): \u001b[1m132.11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pipeline_query10 = [\n",
    "    {\"$match\": {\n",
    "        \"Listing_ID\": \"10006546\",\n",
    "        \"Transaction_Date\": {\n",
    "            \"$gte\": datetime.strptime(\"2008-01-01\", \"%Y-%m-%d\"),\n",
    "            \"$lte\": datetime.strptime(\"2009-01-01\", \"%Y-%m-%d\")\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$Transaction_Price\"}}\n",
    "    }},\n",
    "    {\"$project\": {\"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "]\n",
    "query10 = list(db.Transactions.aggregate(pipeline_query10))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage transaction value for property ID 10006546 (2008-01-01 to 2009-01-01): \\033[1m{query10[0]['AvgValue']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Applying Indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transaction_Price_-1_Listing_ID_1'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index on Transactions collection for faster queries\n",
    "db.Transactions.create_index([(\"Transaction_Date\", -1)])                  # Create index on Transaction_Date for descending order \n",
    "                                                                          # (We consider that is more probable to search for the most recent transactions)\n",
    "                                                                \n",
    "db.Transactions.create_index([(\"Transaction_Price\", -1), (\"Listing_ID\")]) # Compound index on Transaction_Price and Listing_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance (Q10):\u001b[0m\n",
      "Execution time: 0.0056 seconds\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Transactions',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\xe8\"\\xb30\\xbfGN\\x86\\xad\\xe9l\\xdaS\\x81\\xc8\\xf9', 4)},\n",
      "             'pipeline': [{'$match': {'Listing_ID': '10006546',\n",
      "                                      'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                                                           '$lte': datetime.datetime(2009, 1, 1, 0, 0)}}},\n",
      "                          {'$group': {'AvgValue': {'$avg': {'$toDouble': '$Transaction_Price'}},\n",
      "                                      '_id': None}},\n",
      "                          {'$project': {'AvgValue': {'$round': ['$AvgValue',\n",
      "                                                                2]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '2BABB25349C33946E7AB2188B88FECE4C687C7EB6DF5F10656B778028DFCC73E',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Transactions',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {'$and': [{'Listing_ID': {'$eq': '10006546'}},\n",
      "                                                                   {'Transaction_Date': {'$lte': datetime.datetime(2009, 1, 1, 0, 0)}},\n",
      "                                                                   {'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0)}}]},\n",
      "                                          'planCacheKey': '5F8D3F91',\n",
      "                                          'planCacheShapeHash': 'F6D749DD',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': 'F6D749DD',\n",
      "                                          'rejectedPlans': [{'inputStage': {'filter': {'Listing_ID': {'$eq': '10006546'}},\n",
      "                                                                            'inputStage': {'direction': 'forward',\n",
      "                                                                                           'indexBounds': {'Transaction_Date': ['[new '\n",
      "                                                                                                                                'Date(1230768000000), '\n",
      "                                                                                                                                'new '\n",
      "                                                                                                                                'Date(1199145600000)]']},\n",
      "                                                                                           'indexName': 'Transaction_Date_-1',\n",
      "                                                                                           'indexVersion': 2,\n",
      "                                                                                           'isMultiKey': False,\n",
      "                                                                                           'isPartial': False,\n",
      "                                                                                           'isSparse': False,\n",
      "                                                                                           'isUnique': False,\n",
      "                                                                                           'keyPattern': {'Transaction_Date': -1},\n",
      "                                                                                           'multiKeyPaths': {'Transaction_Date': []},\n",
      "                                                                                           'stage': 'IXSCAN'},\n",
      "                                                                            'stage': 'FETCH'},\n",
      "                                                             'isCached': False,\n",
      "                                                             'stage': 'PROJECTION_SIMPLE',\n",
      "                                                             'transformBy': {'Transaction_Price': 1,\n",
      "                                                                             '_id': 0}}],\n",
      "                                          'winningPlan': {'inputStage': {'filter': {'$and': [{'Transaction_Date': {'$lte': datetime.datetime(2009, 1, 1, 0, 0)}},\n",
      "                                                                                             {'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0)}}]},\n",
      "                                                                         'inputStage': {'direction': 'forward',\n",
      "                                                                                        'indexBounds': {'Listing_ID': ['[\"10006546\", '\n",
      "                                                                                                                       '\"10006546\"]']},\n",
      "                                                                                        'indexName': 'Listing_ID_1',\n",
      "                                                                                        'indexVersion': 2,\n",
      "                                                                                        'isMultiKey': False,\n",
      "                                                                                        'isPartial': False,\n",
      "                                                                                        'isSparse': False,\n",
      "                                                                                        'isUnique': False,\n",
      "                                                                                        'keyPattern': {'Listing_ID': 1},\n",
      "                                                                                        'multiKeyPaths': {'Listing_ID': []},\n",
      "                                                                                        'stage': 'IXSCAN'},\n",
      "                                                                         'stage': 'FETCH'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_SIMPLE',\n",
      "                                                          'transformBy': {'Transaction_Price': 1,\n",
      "                                                                          '_id': 0}}}}},\n",
      "            {'$group': {'AvgValue': {'$avg': {'$convert': {'input': '$Transaction_Price',\n",
      "                                                           'to': {'$const': 'double'}}}},\n",
      "                        '_id': {'$const': None}}},\n",
      "            {'$project': {'AvgValue': {'$round': ['$AvgValue', {'$const': 2}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q10)\n",
    "print(\"\\n\\033[1mQuery performance (Q10):\\033[0m\")\n",
    "start_time = time.time()\n",
    "query10 = list(db.Transactions.aggregate(pipeline_query10))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "pprint(db.command('aggregate', 'Transactions', pipeline=pipeline_query10, explain=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]},\n",
       " 'Listing_ID_1': {'v': 2, 'key': [('Listing_ID', 1)]},\n",
       " 'Transaction_Date_-1': {'v': 2, 'key': [('Transaction_Date', -1)]},\n",
       " 'Transaction_Price_-1_Listing_ID_1': {'v': 2,\n",
       "  'key': [('Transaction_Price', -1), ('Listing_ID', 1)]}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Transactions.index_information()  # Check indexes on Transactions collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]},\n",
       " 'Listing_ID_1': {'v': 2, 'key': [('Listing_ID', 1)]},\n",
       " 'Host_ID_1': {'v': 2, 'key': [('Host_ID', 1)]},\n",
       " 'Address.market_1': {'v': 2, 'key': [('Address.market', 1)]},\n",
       " 'Amenities_1': {'v': 2, 'key': [('Amenities', 1)]}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Listings.index_information()     # Check indexes on Listings collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q10):** Separating transactions allows the new query to operate on the much smaller `Transactions` collection directly. The `explain()` output confirms the query efficiently uses the `Listing_ID_1` index (IXSCAN stage) to first isolate transactions for the specific property, and then filters by date. The rejected plan shows the query planner correctly *avoided* using the `Transaction_Date` index first, as filtering by `Listing_ID` is likely more selective. This targeted approach leads to faster execution (0.008s vs 0.007s - times are very fast for a single document lookup, but the *potential* for improvement on larger datasets or more complex queries is the key). \n",
    "\n",
    "The compound index `Transaction_Price_-1_Listing_ID_1` was not used by the winning plan for this specific query (as sorting/filtering wasn't primarily on price), justifying its removal to save storage and reduce write overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Transaction_Price_-1_Listing_ID_1' index\n",
    "db.Transactions.drop_index('Transaction_Price_-1_Listing_ID_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAverage transaction value for property ID 10006546 from 2008-01-01 to 2009-01-01:\u001b[0m 132.11 | \u001b[1mTime:\u001b[0m 0.0037 seconds\n"
     ]
    }
   ],
   "source": [
    "# EXTRA: Function to get the average transaction value for a property in a date range\n",
    "def get_average_transaction_value(property_id, start_date, end_date):\n",
    "    \"\"\"Get the average transaction value for a property in a date range.\n",
    "\n",
    "    Args:\n",
    "        property_id (str): The ID of the property.\n",
    "        start_date (str): The start date in YYYY-MM-DD format.\n",
    "        end_date (str): The end date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average transaction value and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"_id\": property_id}},\n",
    "        {\"$unwind\": \"$transactions.transactions\"},\n",
    "        {\"$match\": {\n",
    "            \"transactions.transactions.date\": {\n",
    "                \"$gte\": datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                \"$lte\": datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "            }\n",
    "        }},\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$transactions.transactions.price\"}}\n",
    "        }},\n",
    "        {\"$project\": {\"_id\": 0, \"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[0][\"AvgValue\"] if result else 0, exec_time\n",
    "\n",
    "# Test the function\n",
    "property_id = \"10006546\"\n",
    "start_date = \"2008-01-01\"\n",
    "end_date = \"2009-01-01\"\n",
    "avg_value, exec_time = get_average_transaction_value(property_id=property_id, start_date=start_date, end_date=end_date)\n",
    "print(f\"\\n\\033[1mAverage transaction value for property ID {property_id} from {start_date} to {end_date}:\\033[0m {avg_value} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11)\tWe wish to have a summary webpage that displays information about our top destinations. \n",
    "#       This webpage should display for each of the top 10 cities some basic information about our operations in the area \n",
    "#           (number of properties by type for example, average price by type) but you can choose the metrics. \n",
    "#       For each of the top 10 cities it should also provide some basic information about the top 3 properties in each city \n",
    "#           (price, number of review, whatever you think useful) to show an example of the properties available in the area. \n",
    "#       We would like to keep this webpage up to date as information changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0621 seconds\n",
      "\n",
      "\u001b[1mTop 10 cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "\u001b[1mCity\u001b[0m              | \u001b[1mProperty Count\u001b[0m | \u001b[1mAvg Price\u001b[0m | \u001b[1mTop 3 Properties\u001b[0m\n",
      "================================================================================\n",
      "Istanbul          | 660            | 367.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 3237666  | \u001b[1mPrice:\u001b[0m 148.0 | \u001b[1mReview Count:\u001b[0m 248\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 555588   | \u001b[1mPrice:\u001b[0m 243.0 | \u001b[1mReview Count:\u001b[0m 246\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1215226  | \u001b[1mPrice:\u001b[0m 322.0 | \u001b[1mReview Count:\u001b[0m 193\n",
      "--------------------------------------------------------------------------------\n",
      "Montreal          | 648            | 100.23    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16389574 | \u001b[1mPrice:\u001b[0m 70.0  | \u001b[1mReview Count:\u001b[0m 261\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4451485  | \u001b[1mPrice:\u001b[0m 83.0  | \u001b[1mReview Count:\u001b[0m 255\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16845784 | \u001b[1mPrice:\u001b[0m 50.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "Barcelona         | 632            | 100.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 95560    | \u001b[1mPrice:\u001b[0m 15.0  | \u001b[1mReview Count:\u001b[0m 463\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1482060  | \u001b[1mPrice:\u001b[0m 130.0 | \u001b[1mReview Count:\u001b[0m 397\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1332929  | \u001b[1mPrice:\u001b[0m 63.0  | \u001b[1mReview Count:\u001b[0m 320\n",
      "--------------------------------------------------------------------------------\n",
      "Hong Kong         | 619            | 762.48    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16493868 | \u001b[1mPrice:\u001b[0m 361.0 | \u001b[1mReview Count:\u001b[0m 348\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 11778475 | \u001b[1mPrice:\u001b[0m 502.0 | \u001b[1mReview Count:\u001b[0m 269\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4755673  | \u001b[1mPrice:\u001b[0m 1319.0 | \u001b[1mReview Count:\u001b[0m 223\n",
      "--------------------------------------------------------------------------------\n",
      "Sydney            | 609            | 197.71    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 12954762 | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 469\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 652063   | \u001b[1mPrice:\u001b[0m 43.0  | \u001b[1mReview Count:\u001b[0m 312\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7132426  | \u001b[1mPrice:\u001b[0m 139.0 | \u001b[1mReview Count:\u001b[0m 259\n",
      "--------------------------------------------------------------------------------\n",
      "New York          | 607            | 139.63    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 476983   | \u001b[1mPrice:\u001b[0m 85.0  | \u001b[1mReview Count:\u001b[0m 420\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 18173787 | \u001b[1mPrice:\u001b[0m 48.0  | \u001b[1mReview Count:\u001b[0m 379\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 858695   | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 262\n",
      "--------------------------------------------------------------------------------\n",
      "Rio De Janeiro    | 603            | 525.81    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 846689   | \u001b[1mPrice:\u001b[0m 157.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1304552  | \u001b[1mPrice:\u001b[0m 168.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 880678   | \u001b[1mPrice:\u001b[0m 190.0 | \u001b[1mReview Count:\u001b[0m 149\n",
      "--------------------------------------------------------------------------------\n",
      "Porto             | 554            | 69.13     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 5283892  | \u001b[1mPrice:\u001b[0m 29.0  | \u001b[1mReview Count:\u001b[0m 408\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2758817  | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 402\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1284759  | \u001b[1mPrice:\u001b[0m 53.0  | \u001b[1mReview Count:\u001b[0m 399\n",
      "--------------------------------------------------------------------------------\n",
      "Oahu              | 253            | 212.3     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4069429  | \u001b[1mPrice:\u001b[0m 124.0 | \u001b[1mReview Count:\u001b[0m 533\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7536867  | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 308\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 210968   | \u001b[1mPrice:\u001b[0m 169.0 | \u001b[1mReview Count:\u001b[0m 289\n",
      "--------------------------------------------------------------------------------\n",
      "Maui              | 153            | 286.59    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1796816  | \u001b[1mPrice:\u001b[0m 175.0 | \u001b[1mReview Count:\u001b[0m 257\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1613843  | \u001b[1mPrice:\u001b[0m 95.0  | \u001b[1mReview Count:\u001b[0m 192\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2279098  | \u001b[1mPrice:\u001b[0m 86.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[1mTop 10 cities:\u001b[0m Istanbul, Montreal, Barcelona, Hong Kong, Sydney, New York, Rio De Janeiro, Porto, Oahu, Maui\n"
     ]
    }
   ],
   "source": [
    "# 11. Top 10 cities with property stats and top 3 properties\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": \"$price\"},\n",
    "        \"Properties\": {\"$push\": {\"Id\": \"$_id\", \"Price\": \"$price\", \"ReviewCount\": \"$number_of_reviews\"}}\n",
    "    }},\n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    # Add top 3 properties per city\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "# pprint(result)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\n\\033[1mTop 10 cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "print(f\"{'\\033[1mCity\\033[0m':<25} | {'\\033[1mProperty Count\\033[0m':<15} | {'\\033[1mAvg Price\\033[0m':<10} | \\033[1mTop 3 Properties\\033[0m\")\n",
    "print(\"=\" * 80)\n",
    "for city in result:\n",
    "    print(f\"{city['City']:<17} | {city['PropertyCount']:<14} | {float(str(city['AvgPrice'])):<9} |\")\n",
    "    for prop in city[\"TopProperties\"]:\n",
    "        print(f\"                                                 - \\033[1mProperty ID:\\033[0m {prop['Id']:<8} | \\033[1mPrice:\\033[0m {float(str(prop['Price'])):<5} | \\033[1mReview Count:\\033[0m {prop['ReviewCount']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "top_cities = [city[\"City\"] for city in result]\n",
    "print(f\"\\n\\033[1mTop 10 cities:\\033[0m {', '.join(top_cities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0534 seconds\n",
      "\n",
      "\u001b[1mTop 10 cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "\u001b[1mCity\u001b[0m              | \u001b[1mProperty Count\u001b[0m | \u001b[1mAvg Price\u001b[0m | \u001b[1mTop 3 Properties\u001b[0m\n",
      "================================================================================\n",
      "Istanbul          | 660            | 367.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 3237666  | \u001b[1mPrice:\u001b[0m 148.0 | \u001b[1mReview Count:\u001b[0m 248\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 555588   | \u001b[1mPrice:\u001b[0m 243.0 | \u001b[1mReview Count:\u001b[0m 246\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1215226  | \u001b[1mPrice:\u001b[0m 322.0 | \u001b[1mReview Count:\u001b[0m 193\n",
      "--------------------------------------------------------------------------------\n",
      "Montreal          | 648            | 100.23    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16389574 | \u001b[1mPrice:\u001b[0m 70.0  | \u001b[1mReview Count:\u001b[0m 261\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4451485  | \u001b[1mPrice:\u001b[0m 83.0  | \u001b[1mReview Count:\u001b[0m 255\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16845784 | \u001b[1mPrice:\u001b[0m 50.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "Barcelona         | 632            | 100.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 95560    | \u001b[1mPrice:\u001b[0m 15.0  | \u001b[1mReview Count:\u001b[0m 463\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1482060  | \u001b[1mPrice:\u001b[0m 130.0 | \u001b[1mReview Count:\u001b[0m 397\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1332929  | \u001b[1mPrice:\u001b[0m 63.0  | \u001b[1mReview Count:\u001b[0m 320\n",
      "--------------------------------------------------------------------------------\n",
      "Hong Kong         | 619            | 762.48    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16493868 | \u001b[1mPrice:\u001b[0m 361.0 | \u001b[1mReview Count:\u001b[0m 348\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 11778475 | \u001b[1mPrice:\u001b[0m 502.0 | \u001b[1mReview Count:\u001b[0m 269\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4755673  | \u001b[1mPrice:\u001b[0m 1319.0 | \u001b[1mReview Count:\u001b[0m 223\n",
      "--------------------------------------------------------------------------------\n",
      "Sydney            | 609            | 197.71    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 12954762 | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 469\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 652063   | \u001b[1mPrice:\u001b[0m 43.0  | \u001b[1mReview Count:\u001b[0m 312\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7132426  | \u001b[1mPrice:\u001b[0m 139.0 | \u001b[1mReview Count:\u001b[0m 259\n",
      "--------------------------------------------------------------------------------\n",
      "New York          | 607            | 139.63    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 476983   | \u001b[1mPrice:\u001b[0m 85.0  | \u001b[1mReview Count:\u001b[0m 420\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 18173787 | \u001b[1mPrice:\u001b[0m 48.0  | \u001b[1mReview Count:\u001b[0m 379\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 858695   | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 262\n",
      "--------------------------------------------------------------------------------\n",
      "Rio De Janeiro    | 603            | 525.81    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 846689   | \u001b[1mPrice:\u001b[0m 157.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1304552  | \u001b[1mPrice:\u001b[0m 168.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 880678   | \u001b[1mPrice:\u001b[0m 190.0 | \u001b[1mReview Count:\u001b[0m 149\n",
      "--------------------------------------------------------------------------------\n",
      "Porto             | 554            | 69.13     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 5283892  | \u001b[1mPrice:\u001b[0m 29.0  | \u001b[1mReview Count:\u001b[0m 408\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2758817  | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 402\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1284759  | \u001b[1mPrice:\u001b[0m 53.0  | \u001b[1mReview Count:\u001b[0m 399\n",
      "--------------------------------------------------------------------------------\n",
      "Oahu              | 253            | 212.3     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4069429  | \u001b[1mPrice:\u001b[0m 124.0 | \u001b[1mReview Count:\u001b[0m 533\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7536867  | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 308\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 210968   | \u001b[1mPrice:\u001b[0m 169.0 | \u001b[1mReview Count:\u001b[0m 289\n",
      "--------------------------------------------------------------------------------\n",
      "Maui              | 153            | 286.59    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1796816  | \u001b[1mPrice:\u001b[0m 175.0 | \u001b[1mReview Count:\u001b[0m 257\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1613843  | \u001b[1mPrice:\u001b[0m 95.0  | \u001b[1mReview Count:\u001b[0m 192\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2279098  | \u001b[1mPrice:\u001b[0m 86.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pipeline_query11 = [\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": {\"$toDouble\": \"$Price\"}},\n",
    "        \"Properties\": {\"$push\": {\"Id\": \"$Listing_ID\", \"Price\": \"$Price\", \"ReviewCount\": \"$Number_of_Reviews\"}}\n",
    "    }},\n",
    "    \n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    \n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        # Add top 3 properties per city\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }}\n",
    "]\n",
    "query11 = list(db.Listings.aggregate(pipeline_query11))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\n\\033[1mTop 10 cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "print(f\"{'\\033[1mCity\\033[0m':<25} | {'\\033[1mProperty Count\\033[0m':<15} | {'\\033[1mAvg Price\\033[0m':<10} | \\033[1mTop 3 Properties\\033[0m\")\n",
    "print(\"=\" * 80)\n",
    "for city in query11:\n",
    "    print(f\"{city['City']:<17} | {city['PropertyCount']:<14} | {float(str(city['AvgPrice'])):<9} |\")\n",
    "    for prop in city[\"TopProperties\"]:\n",
    "        print(f\"                                                 - \\033[1mProperty ID:\\033[0m {prop['Id']:<8} | \\033[1mPrice:\\033[0m {float(str(prop['Price'])):<5} | \\033[1mReview Count:\\033[0m {prop['ReviewCount']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance (Q11):\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Listings',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\xe8\"\\xb30\\xbfGN\\x86\\xad\\xe9l\\xdaS\\x81\\xc8\\xf9', 4)},\n",
      "             'pipeline': [{'$group': {'AvgPrice': {'$avg': {'$toDouble': '$Price'}},\n",
      "                                      'Properties': {'$push': {'Id': '$Listing_ID',\n",
      "                                                               'Price': '$Price',\n",
      "                                                               'ReviewCount': '$Number_of_Reviews'}},\n",
      "                                      'PropertyCount': {'$sum': 1},\n",
      "                                      '_id': '$Address.market'}},\n",
      "                          {'$sort': {'PropertyCount': -1}},\n",
      "                          {'$limit': 10},\n",
      "                          {'$project': {'AvgPrice': {'$round': ['$AvgPrice',\n",
      "                                                                2]},\n",
      "                                        'City': '$_id',\n",
      "                                        'PropertyCount': 1,\n",
      "                                        'TopProperties': {'$slice': [{'$sortArray': {'input': '$Properties',\n",
      "                                                                                     'sortBy': {'ReviewCount': -1}}},\n",
      "                                                                     3]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '3D66AFC40B9C72D7C01ED765CA289359EED8A9CFC8CB6069B65AA0D233F885F1',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Listings',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {},\n",
      "                                          'planCacheKey': '1B1F580F',\n",
      "                                          'planCacheShapeHash': '63121E33',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': '63121E33',\n",
      "                                          'rejectedPlans': [],\n",
      "                                          'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                                         'stage': 'COLLSCAN'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_DEFAULT',\n",
      "                                                          'transformBy': {'Address.market': 1,\n",
      "                                                                          'Listing_ID': 1,\n",
      "                                                                          'Number_of_Reviews': 1,\n",
      "                                                                          'Price': 1,\n",
      "                                                                          '_id': 0}}}}},\n",
      "            {'$group': {'AvgPrice': {'$avg': {'$convert': {'input': '$Price',\n",
      "                                                           'to': {'$const': 'double'}}}},\n",
      "                        'Properties': {'$push': {'Id': '$Listing_ID',\n",
      "                                                 'Price': '$Price',\n",
      "                                                 'ReviewCount': '$Number_of_Reviews'}},\n",
      "                        'PropertyCount': {'$sum': {'$const': 1}},\n",
      "                        '_id': '$Address.market'}},\n",
      "            {'$sort': {'limit': 10, 'sortKey': {'PropertyCount': -1}}},\n",
      "            {'$project': {'AvgPrice': {'$round': ['$AvgPrice', {'$const': 2}]},\n",
      "                          'City': '$_id',\n",
      "                          'PropertyCount': True,\n",
      "                          'TopProperties': {'$slice': [{'$sortArray': {'input': '$Properties',\n",
      "                                                                       'sortBy': {'ReviewCount': -1}}},\n",
      "                                                       {'$const': 3}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q11)\n",
    "print(\"\\n\\033[1mQuery performance (Q11):\\033[0m\")\n",
    "pprint(db.command('aggregate', 'Listings', pipeline=pipeline_query11, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q11: `Computed Pattern`**\n",
    "\n",
    "We applied the **Computed Pattern** because **Q11** requires generating a city-level summary containing property counts, average prices, and top listings per city. These statistics depend on expensive aggregations across the full `Listings` collection. Since this summary is likely displayed on a frequently accessed webpage (e.g., homepage or dashboard), recomputing it on every request would be inefficient and unnecessary.\n",
    "\n",
    "We expect a substantial performance gain based on:\n",
    "\n",
    "- We used an aggregation pipeline to compute all necessary metrics for the top 10 cities (e.g., count, average price, top-rated listings), and stored the result in a new `CitySummary` collection using `$out`.\n",
    "- Instead of repeating the heavy aggregation for each request, the application now performs a simple `find()` on a lightweight collection with only 10 documents.\n",
    "- The summary data can be refreshed periodically (e.g., daily or when listings change significantly), decoupling read and write performance.\n",
    "\n",
    "Optionally, we could index the `City` field in the `CitySummary` collection to support fast lookups if users frequently request summaries for specific cities. However, this is likely unnecessary if the entire set is usually shown together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0016 seconds\n",
      "\n",
      "\u001b[1mTop 1 Cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "[{'_id': ObjectId('67fceb224f6288c2cacc18de'),\n",
      "  'PropertyCount': 660,\n",
      "  'City': 'Istanbul',\n",
      "  'AvgPrice': 367.95,\n",
      "  'TopProperties': [{'Listing_ID': '3237666',\n",
      "                     'Price': Decimal128('148.00'),\n",
      "                     'ReviewCount': 248},\n",
      "                    {'Listing_ID': '555588',\n",
      "                     'Price': Decimal128('243.00'),\n",
      "                     'ReviewCount': 246},\n",
      "                    {'Listing_ID': '1215226',\n",
      "                     'Price': Decimal128('322.00'),\n",
      "                     'ReviewCount': 193}]}]\n"
     ]
    }
   ],
   "source": [
    "# Create 'CitySummary' collection\n",
    "db.CitySummary.drop()\n",
    "\n",
    "# Create 'CitySummary' collection with top 10 cities and their properties\n",
    "db.Listings.aggregate([\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": {\"$toDouble\": \"$Price\"}},\n",
    "        \"Properties\": {\"$push\": {\"Listing_ID\": \"$Listing_ID\", \"Price\": \"$Price\", \"ReviewCount\": \"$Number_of_Reviews\"}}\n",
    "    }},\n",
    "    \n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    \n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                   # Will create a ObjectId for each top city\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        \n",
    "        # Add top 3 properties per city\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }},\n",
    "    \n",
    "    # Output to 'CitySummary' collection\n",
    "    {\"$out\": \"CitySummary\"}\n",
    "])\n",
    "\n",
    "# Query the 'CitySummary' collection\n",
    "start_time = time.time()\n",
    "city_summary = list(db.CitySummary.find({}))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "print(f\"\\n\\033[1mTop 1 Cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "pprint(list(db.CitySummary.find().limit(1)), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q11):** The original query requires a full aggregation over the main collection (~0.11s). By applying the **Computed Pattern** and storing the results in `CitySummary`, subsequent reads for the dashboard become a simple `find()` on 10 documents, which is extremely fast (0.0036s initially to create, then negligible time for reads). The `explain()` output for the aggregation shows a **COLLSCAN** (collection scan) is necessary initially, as expected for this type of summary generation across all documents. This pattern is highly effective for read-heavy dashboard or reporting scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔄️ Database updates:** [2 points per question]\n",
    "\n",
    "After optimizing the database, show how to complete the following updates. You can create fictional data. Ensure that previous data does not become stale:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Add a new property with a new host in one of the top 10 cities. \n",
    "#     The host selects the top 10 most common amenities to list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Inserted property: 20000000, Time: 0.0024 seconds'\n"
     ]
    }
   ],
   "source": [
    "# 12. Add new property with top 10 amenities\n",
    "start_time = time.time()\n",
    "\n",
    "# Top 10 amenities from Query 7 (manually selected based on frequency)\n",
    "top_amenities = [\n",
    "    \"TV\", \"Wifi\", \"Kitchen\", \"Heating\", \"Essentials\",\n",
    "    \"Washer\", \"Dryer\", \"Air conditioning\", \"Hair dryer\", \"Iron\"\n",
    "]\n",
    "new_property = {\n",
    "    \"_id\": \"20000000\",\n",
    "    \"name\": \"New York Loft\",\n",
    "    \"host_id\": \"99999999\",\n",
    "    \"host_name\": \"Jane\",\n",
    "    \"address\": {\"market\": \"New York\"},\n",
    "    \"amenities\": top_amenities,\n",
    "    \"price\": 100.00  # Numeric value\n",
    "}\n",
    "db.listingsAndReviews_HW2.insert_one(new_property)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "pprint(f\"Inserted property: 20000000, Time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '20000000',\n",
      " 'address': {'market': 'New York'},\n",
      " 'amenities': ['TV',\n",
      "               'Wifi',\n",
      "               'Kitchen',\n",
      "               'Heating',\n",
      "               'Essentials',\n",
      "               'Washer',\n",
      "               'Dryer',\n",
      "               'Air conditioning',\n",
      "               'Hair dryer',\n",
      "               'Iron'],\n",
      " 'host_id': '99999999',\n",
      " 'host_name': 'Jane',\n",
      " 'name': 'New York Loft',\n",
      " 'price': 100.0}\n"
     ]
    }
   ],
   "source": [
    "# 12.1) Query the new property to verify the insertion\n",
    "result = db.listingsAndReviews_HW2.find_one({\"_id\": \"20000000\"})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Property (Q12)**\n",
    "\n",
    "*   **Process:** With the new schema, adding a property involves two steps:\n",
    "    1.  Inserting the host information into the `Hosts` collection (if the host is new).\n",
    "    2.  Inserting the listing details (including the `Host_ID` reference and embedded `Amenities`) into the `Listings` collection.\n",
    "*   **Benefit:** This maintains normalization. If \"Jane\" adds more properties later, her core host information isn't duplicated. We use the pre-computed `Amenities` collection to easily fetch common amenities if needed, though here we just list the top 10 manually for the example.\n",
    "*   **Verification:** The `find_one` query confirms the new listing document exists in the `Listings` collection with the correct `Listing_ID`, `Host_ID`, and embedded `Amenities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted property and host, Time: 0.0094 seconds\n",
      "\n",
      "{'_id': ObjectId('67fceb221abb1450f62a5a3a'),\n",
      " 'Listing_ID': '20000000',\n",
      " 'Name': 'New York Loft',\n",
      " 'Host_ID': '99999999',\n",
      " 'Address': {'market': 'New York'},\n",
      " 'Amenities': ['24-hour check-in',\n",
      "               'Accessible-height bed',\n",
      "               'Accessible-height toilet',\n",
      "               'Air conditioning',\n",
      "               'Air purifier',\n",
      "               'Alfresco shower',\n",
      "               'BBQ grill',\n",
      "               'Baby bath',\n",
      "               'Baby monitor',\n",
      "               'Babysitter recommendations'],\n",
      " 'Price': Decimal128('100.00'),\n",
      " 'Accommodates': 2,\n",
      " 'Number_of_Reviews': 0,\n",
      " 'Review_Scores': {'Checkin': 0,\n",
      "                   'Cleanliness': 0,\n",
      "                   'Communication': 0,\n",
      "                   'Location': 0,\n",
      "                   'Rating': 0,\n",
      "                   'Value': 0},\n",
      " 'Transactions': {'Transaction_Date': '2025-04-14T12:01:54.865700',\n",
      "                  'Transaction_Price': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create new property and host\n",
    "top_amenities = list(db.Amenities.find().sort({\"Amenity\": 1}).limit(10))\n",
    "new_host = {\"Host_ID\": \"99999999\", \"Host_Name\": \"Jane\"}\n",
    "new_property = {\n",
    "    \"Listing_ID\": \"20000000\",\n",
    "    \"Name\": \"New York Loft\",\n",
    "    \"Host_ID\": \"99999999\",\n",
    "    \"Address\": {\"market\": \"New York\"},\n",
    "    \"Amenities\": [a[\"Amenity\"] for a in top_amenities],\n",
    "    \"Price\": Decimal128(\"100.00\"),\n",
    "    \"Accommodates\": 2,\n",
    "    \"Number_of_Reviews\": 0,\n",
    "    \"Review_Scores\": {\n",
    "        \"Checkin\": 0,\n",
    "        \"Cleanliness\": 0,\n",
    "        \"Communication\": 0,\n",
    "        \"Location\": 0,\n",
    "        \"Rating\": 0,\n",
    "        \"Value\": 0\n",
    "    },\n",
    "    \"Transactions\": {\n",
    "        \"Transaction_Date\": datetime.now().isoformat(),\n",
    "        \"Transaction_Price\": 0.00\n",
    "    }\n",
    "}\n",
    "db.Hosts.insert_one(new_host)\n",
    "db.Listings.insert_one(new_property)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Inserted property and host, Time: {execution_time:.4f} seconds\\n\")\n",
    "\n",
    "# 12.2) Query the new property to verify the insertion\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Add a new review from one of our top 20 reviewers for this new property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '13574006',\n",
      " 'host_name': 'José',\n",
      " 'reviews': [{'_id': '256178235',\n",
      "              'comments': 'Great stay. The perfect house with the perfect '\n",
      "                          'service. We did a last minute booking and '\n",
      "                          'everything went smooth. Everything was very clean '\n",
      "                          'and the comunication was perfect. The house is '\n",
      "                          'incredibly luxorious and fully equppied. Highly '\n",
      "                          'recommended',\n",
      "              'date': datetime.datetime(2018, 4, 22, 4, 0),\n",
      "              'listing_id': '13574006',\n",
      "              'reviewer_id': '20775242',\n",
      "              'reviewer_name': 'Filipe'}]}\n"
     ]
    }
   ],
   "source": [
    "# 13.1) Get the top reviewer ID from Question 8\n",
    "\n",
    "# {'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'}\n",
    "top_reviewer_id = \"20775242\"\n",
    "doc = db.listingsAndReviews_HW2.find_one(\n",
    "    {\"reviews.reviewer_id\": top_reviewer_id},\n",
    "    {\"host_name\": 1, \"reviews.$\": 1}\n",
    ")\n",
    "pprint(doc)\n",
    "\n",
    "# doc[\"reviews\"][0]['comments'] - Reviewer comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added review, Time: 0.0055 seconds\n"
     ]
    }
   ],
   "source": [
    "# 13. Add review from top reviewer\n",
    "start_time = time.time()\n",
    "\n",
    "db.listingsAndReviews_HW2.update_one({\"_id\": \"20000000\"}, {\"$push\": {\"reviews\": doc[\"reviews\"][0]}})\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Added review, Time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Review (Q13)**\n",
    "\n",
    "*   **Process:** Adding a review now involves:\n",
    "    1.  Inserting the new review document into the `Reviews` collection, including references to `Listing_ID` and `Reviewer_ID`.\n",
    "    2.  Optionally (if implementing the Computed Pattern for Q8 fully), updating the corresponding document in the `Reviewers` collection to increment the `ReviewCount` or add the new `Review_ID` to a list. (The code shows adding the ID to a hypothetical `Review_IDs` array).\n",
    "*   **Benefit:** Keeps the `Listings` collection lean. Scales well as the number of reviews grows. Allows efficient querying of reviews independently.\n",
    "*   **Verification:** The `find_one` query confirms the new review document exists in the `Reviews` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added review, Time: 0.0087 seconds\n",
      "\n",
      "{'_id': ObjectId('67fceb221abb1450f62a5a3b'),\n",
      " 'Listing_ID': '20000000',\n",
      " 'Review_ID': '99999999',\n",
      " 'Reviewer_ID': '20775242',\n",
      " 'Review_Comments': 'Great loft!',\n",
      " 'Review_Date': datetime.datetime(2025, 4, 14, 12, 1, 54, 933000)}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Add new review from top reviewer\n",
    "# Use the top reviewer ID from Query 8\n",
    "top_reviewer = query8[0]\n",
    "new_review = {\n",
    "    \"Listing_ID\": \"20000000\",\n",
    "    \"Review_ID\": \"99999999\",\n",
    "    \"Reviewer_ID\": top_reviewer[\"ReviewerId\"],\n",
    "    \"Review_Comments\": \"Great loft!\",\n",
    "    \"Review_Date\": datetime.now()\n",
    "}\n",
    "db.Reviews.insert_one(new_review)\n",
    "db.Reviewers.update_one(\n",
    "    {\"Reviewer_ID\": top_reviewer[\"ReviewerId\"]},\n",
    "    {\"$push\": {\"Review_IDs\": \"99999999\"}}\n",
    ")\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Added review, Time: {execution_time:.4f} seconds\\n\")\n",
    "\n",
    "# 13.1) Query the new review to verify the insertion\n",
    "pprint(db.Reviews.find_one({\"Review_ID\": \"99999999\"}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Add a new review metric called 'x_factor' with a score of 10. \n",
    "#     Show that the average score across all metrics is correctly calculated for this listing, using the previously developed query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0052 seconds\n",
      "\n",
      "Average score across all review metrics for property ID 20000000: \u001b[1m10.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 14. Add x_factor metric and calculate average\n",
    "start_time = time.time()\n",
    "\n",
    "# Add new metric\n",
    "db.listingsAndReviews_HW2.update_one(\n",
    "    {\"_id\": \"20000000\"},\n",
    "    {\"$set\": {\"review_scores_x_factor\": 10}}\n",
    ")\n",
    "\n",
    "# Query with dynamic review_scores_* fields (from Query 9)\n",
    "pipeline = [\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"_id\": \"20000000\"}},\n",
    "    \n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"all_fields\": {\"$objectToArray\": \"$$ROOT\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$all_fields\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$match\": {\n",
    "        \"all_fields.k\": {\"$regex\": \"^review_scores_\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the score values, handling nulls\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Metric\": \"$all_fields.k\",\n",
    "        \"Score\": {\"$ifNull\": [\"$all_fields.v\", 0]}  # Default to 0 if null\n",
    "    }},\n",
    "    \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Score\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage score across all review metrics for property ID 20000000: \\033[1m{result[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Metric & Verifying Average (Q14)**\n",
    "\n",
    "*   **Process:**\n",
    "    1.  Add the new metric 'XFactor' directly to the `Review_Scores` subdocument within the specific `Listings` document using `$set` with dot notation (`Review_Scores.XFactor`).\n",
    "    2.  Re-run the *exact same aggregation pipeline* used in Q9 (new schema version) to calculate the average score across all metrics.\n",
    "*   **Benefit (Attribute Pattern):** This demonstrates the flexibility of the **Attribute Pattern**. The query pipeline (`$objectToArray` -> `$unwind` -> `$avg`) does not need modification; it automatically includes the new 'XFactor' field in its calculation because it iterates over all key-value pairs within the `Review_Scores` subdocument.\n",
    "*   **Verification:**\n",
    "    *   The first `find_one` shows the `Review_Scores` before the update.\n",
    "    *   The second `find_one` confirms the 'XFactor' field was successfully added.\n",
    "    *   The aggregation result shows the new average (1.4), correctly incorporating the 'XFactor' score along with the initial zero scores.\n",
    "*   **Computed Pattern Update:** Because we *optionally* added the `Review_Scores_Avg` pre-computed field to `Listings`, we perform an additional `update_one` to store the *newly calculated* average (1.4) back into that field, ensuring the pre-computed value stays consistent. If the computed field wasn't used, this last update wouldn't be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mReview_Scores for property ID 20000000:\u001b[0m\n",
      "{'_id': ObjectId('67fceb221abb1450f62a5a3a'),\n",
      " 'Review_Scores': {'Checkin': 0,\n",
      "                   'Cleanliness': 0,\n",
      "                   'Communication': 0,\n",
      "                   'Location': 0,\n",
      "                   'Rating': 0,\n",
      "                   'Value': 0}}\n",
      "\n",
      "\u001b[1mUpdated Review_Scores for property ID 20000000:\u001b[0m\n",
      "{'_id': ObjectId('67fceb221abb1450f62a5a3a'),\n",
      " 'Review_Scores': {'Checkin': 0,\n",
      "                   'Cleanliness': 0,\n",
      "                   'Communication': 0,\n",
      "                   'Location': 0,\n",
      "                   'Rating': 0,\n",
      "                   'Value': 0,\n",
      "                   'XFactor': 10}}\n",
      "\n",
      "Execution time: 0.0113 seconds\n",
      "\n",
      "\n",
      "Average score with new metric: \u001b[1m1.4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Property ID 20000000 | Review_Scores\n",
    "print(f\"\\n\\033[1mReview_Scores for property ID 20000000:\\033[0m\")\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"},{\"Review_Scores\": 1}), sort_dicts=False)\n",
    "\n",
    "db.Listings.update_one(\n",
    "    {\"Listing_ID\": \"20000000\"},\n",
    "    {\"$set\": {\"Review_Scores.XFactor\": 10}}\n",
    ")\n",
    "\n",
    "# Print the updated document to verify the new metric\n",
    "print(f\"\\n\\033[1mUpdated Review_Scores for property ID 20000000:\\033[0m\")\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"},{\"Review_Scores\": 1}), sort_dicts=False)\n",
    "\n",
    "# Query to calculate average score across all metrics, including new metric\n",
    "query14 = list(db.Listings.aggregate([\n",
    "    # Match the specific property ID (e.g., 20000000)\n",
    "    {\"$match\": {\"Listing_ID\": \"20000000\"}},\n",
    "    \n",
    "    # Select the Review_Scores field and convert it to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"Scores\": {\"$objectToArray\": \"$Review_Scores\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$Scores\"},\n",
    "    \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Scores.v\"}\n",
    "    }},    \n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution time: {execution_time:.4f} seconds\\n\")\n",
    "print(f\"\\nAverage score with new metric: \\033[1m{query14[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 1, 'nModified': 1, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the average score in the Listings collection (Computed Pattern)\n",
    "# Since we create a new field in the Listings collection to store the average review score, we need to update every time we add a new metric.\n",
    "db.Listings.update_one(\n",
    "    {\"Listing_ID\": \"20000000\"},\n",
    "    {\"$set\": {\"Review_Scores_Avg\": query14[0]['AvgScore']}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "bdmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.986px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
