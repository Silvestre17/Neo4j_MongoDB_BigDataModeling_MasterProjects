{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\"><b>Homework 2: AirBnB Document Database</b></font>\n",
    "\n",
    "**Group number:** **`5`**\n",
    "\n",
    "**Group members:**\n",
    "\n",
    "<center>\n",
    "\n",
    "|STUDENT NAME|STUDENT NUMBER|\n",
    "|:---:|:---:|\n",
    "|Alexandre Gon√ßalves|20240738|\n",
    "|Andr√© Silvestre|20240502|\n",
    "|Filipa Pereira|20240509|\n",
    "|Jo√£o Henriques|20240499|\n",
    "|Umeima Mahomed|20240543|\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "**The Homework 2 is comprised of two parts:**\n",
    "1. Data modelling (15 points - $37.5\\%$).\n",
    "2. Queries to database to answer the questions (25 points - $62.5\\%$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- AirBnB Logo  -->\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Airbnb_Logo_B%C3%A9lo.svg/1280px-Airbnb_Logo_B%C3%A9lo.svg.png\" style=\"height: 100px !important;\">\n",
    "    <br>\n",
    "    <!-- Style Text with same style as AirBnB -->\n",
    "    <span style=\"color: #FF5A5F !important; font-size: 30px !important; font-weight: bold !important;\">Document Database</span><span style=\"color: #484848 !important; font-size: 30px !important; font-weight: bold !important;\"> MongoDB - Group 5</span>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>1. Data Modelling</b></font>\n",
    "\n",
    "<font size=\"4\">Congratulations! You‚Äôve been hired as part of the new Data Engineering and Management team in the AirBNB Business Intelligence department. The company is restructuring due to unsatisfactory performance from the previous teams.\n",
    "\n",
    "Before leaving, the head of the Data Modelling department highlighted several issues:\n",
    "\n",
    "**Data Storage**: A lot of data about AirBNB listings is stored in a single document. While this approach has some advantages, it has also caused performance issues. Queries are slow, and the team didn‚Äôt apply patterns, which could improve performance by optimizing the data model. Indexes were also not used.\n",
    "\n",
    "**Reviews Growth**: The number of reviews for AirBNB is growing rapidly. Currently, we overwrite reviews regularly, but the Business Intelligence department will benefit from storing all reviews and analyzing them over time.\n",
    "\n",
    "**Data Errors**: There are errors in the data collection, such as duplicate data entries and incorrect timestamps for transactions. The new team will need to decide how to fix these issues.\n",
    "\n",
    "**Your Role**: In your new role, you‚Äôll need to consider how each database query is used, how often it is needed, and its impact on reads and writes. You should update the database schema to optimize for business use cases. Use tools like embedding, linking, indexes, and patterns to improve the data model. You may need to create new fields, documents, or collections. Be sure to document the pattern you‚Äôre applying and the reasons behind your decisions, especially when dealing with duplication and risks of outdated data.\n",
    "\n",
    "**Key tasks include**:\n",
    "\n",
    "1. Streamlining the data collection process.\n",
    "2. Cleaning up the data and optimizing what will be returned for each use case.\n",
    "3. Applying the correct patterns to speed up common queries.\n",
    "4. Ensuring departments get accurate and relevant information from the database.\n",
    "5. Sharing the updated data model schema with other departments.\n",
    "\n",
    "**Good Practices**: [Check Chapter 6, Mastering MongoDB]\n",
    "\n",
    "1. All newly created fields should have capitalized names.\n",
    "2. New queries should work with the most up-to-date database version. If you make multiple changes, all queries should still work after the final updates.\n",
    "3. For some queries, you may need to change the database schema.\n",
    "4. When you are applying specific patterns, like polymorphic, subset, or bucket, name them accordingly. \n",
    "5. Document each major transformation using this format:\n",
    "*‚ÄúWe applied {transformation name} because {reasoning behind it}. We expect {change/result} based on {observable measure, such as query speed, number of documents returned, index use, etc.}.‚Äù*\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleanup and Schema Adjustments:** [9 points in total]\n",
    "\n",
    "1) Before working on the queries below, review the data and adjust the schema based on the typical use case described.\n",
    "\n",
    "**Typical Use Case**: The most common use of the database is to show property listing information to customers. A query retrieves a listing document from the database. Currently, retrieving a listing takes too long. Decide what information should be included in a typical query and optimize the structure accordingly. For example, customers usually only need a sample of reviews, not all reviews (even though all reviews are stored). They also don‚Äôt need past transaction data. Update the document schema to fit this use case. This might involve creating new collections or documents.\n",
    "\n",
    "**Data Cleanup**: Review the data for any errors (such as transactions that don‚Äôt belong to the listing) or unnecessary duplication, and clean it up where needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>2. Uses for the database</b></font>\n",
    "\n",
    "<font size=\"4\">Different AirBNB departments require different analytics from our common database.\n",
    "Below are the specific questions from various departments: \n",
    "\n",
    "**Standard Difficulty Questions:** [2 points per question]\n",
    "\n",
    "2)\tOnce a month, we reward hosts with recognition. Select three superhosts with at least two listings that can accommodate more than four people.\n",
    "\n",
    "3)\tThe company considers inevsting into property to rent. Which bed type is most common in listings with a waterfront and a dishwasher in New York?\n",
    "\n",
    "4)\tWe're considering hiring someone to write reviews professionally. Who wrote the longest review in New York?\n",
    "\n",
    "5)\tTo assess the security of different areas, what is the biggest and smallest (price-security deposit) difference per number of visitors at a property?\n",
    "\n",
    "6)  Identify areas by whether they are typically used for short breaks, like weekend mini breaks, or whether they are more suitable for long trips. This information support targeted advertising of different customer types. It is not expected to change much over time so we won‚Äôt look to update it, we just require current view. What is the average duration of stay (in nights) per type of property per city (you can use the maximum_nights to measure length of stays)? For each property type return the city with the highest and lowest average value.\n",
    "\n",
    "**Advanced Difficulty Questions (Consider database optimization for these queries):** [3 points per question]\n",
    "\n",
    "7)\tWe are creating a new webpage for hosts when setting up their account. It will list suggested typical amenities. This data will need to be available every time a host registers a property but is not expected to change very much. The starting point for the list will be all unique amenities currently listed in properties (across all documents). Optimise the database for this use case and show how the data should be queried.\n",
    "\n",
    "8)\tWe plan to rtack our reviewers better. We want to create a webpage that shows the top 20 reviewers and the count of the number of reviews of each of these reviewers. This webpage should be kept up to date. It should also have a link to return the number of reviews for a given reviewer ID or Name (show how to query for number of reviews by ID or query quickly).\n",
    "\n",
    "9)\tFor each property we store review scores across different metrics (accuracy, check-in, cleanliness etc). We consider adding more metrics, although there is no clarity on what these will be. We want to be able to easily query the average score across all of these metrics, including any new metrics that might be added without changing the query. Adjust the data model so this can be done and show the query for an example property.\n",
    "\n",
    "10)\tWe aim to have better access to information about transaction, we wish to develop a search engine that can calculate the average value of transactions in a given period of time quickly for a given property.\n",
    "\n",
    "11)\tWe wish to have a summary webpage that displays information about our top destinations. This webpage should display for each of the top 10 cities some basic information about our operations in the area (number of properties by type for example, average price by type) but you can choose the metrics. For each of the top 10 cities it should also provide some basic information about the top 3 properties in each city (price, number of review, whatever you think useful) to show an example of the properties available in the area. We would like to keep this webpage up to date as information changes.\n",
    "\n",
    "**Database updates:** [2 points per question]\n",
    "\n",
    "After optimizing the database, show how to complete the following updates. You can create fictional data. Ensure that previous data does not become stale:\n",
    "\n",
    "12) Add a new property with a new host in one of the top 10 cities. The host selects the top 10 most common amenities to list.\n",
    "\n",
    "13) Add a new review from one of our top 20 reviewers for this new property.\n",
    "\n",
    "14) Add a new review metric called 'x_factor' with a score of 10. Show that the average score across all metrics is correctly calculated for this listing, using the previously developed query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### **Setup**\n",
    "\n",
    "1. run Jupyter \n",
    "2. run Docker\n",
    "3. create MongoDB container in Command Prompt: make sure you don't have 'leftover' container from previous runs\n",
    "\n",
    "        docker run --name mongodb -d -e MONGO_INITDB_ROOT_USERNAME=AzureDiamond -e MONGO_INITDB_ROOT_PASSWORD=hunter2 -p 27017:27017 mongo\n",
    "\n",
    "4. run Studio3T\n",
    "\n",
    "5. create New Connection OR reconnect to existing Connection:\n",
    "\n",
    "    5.A\tIn Studio3T create Connection:\n",
    "            a.\tPress Connection -> New Connection\n",
    "            b.\tInsert credentials into URI field: mongodb://AzureDiamond:hunter2@localhost:27017\n",
    "            c.\tPress Test Connection\n",
    "            d.\tAssign a name to the Connection (top empty line) -> Save\n",
    "            e.\tPress Connect\n",
    "            \n",
    "    5.B In Studio3T reconnect to Connection:\n",
    "            a. press Connect (top left corner)\n",
    "            b. choose MongoDB connection  -> press Connect (MongoDB container must be runnning by this time)\n",
    "            \n",
    "6.\tIn Studio3T import the Database:\n",
    "            a.\tPress Import\n",
    "            b.\tChoose BSON mongodump archive \n",
    "            c.\tFind your database path\n",
    "            d.\tSelect All file formats and choose the database file ‚Äòsampledata.archive‚Äô\n",
    "            e.\tPress Run: be patient while the database loads\n",
    "            f.\tInspect the collections and documents\n",
    "\n",
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## **Important**\n",
    "\n",
    "**NOTE** To avoid confusion between the **`sample_airbnb`** dataset from class and the one from **HW2**, we rename this collection to **`listingsAndReviews_HW2`** in **Studio 3T**.\n",
    "\n",
    "\n",
    "Left Side Menu > Open the *sample_airbnb* database > Click on the collections (you should see **`(2)`**) > Right-click on the **`listingsAndReviews_HW2`** collection > Right-click > ***Rename Collection*** > **`listingsAndReviews_HW2`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T06:00:23.357459Z",
     "start_time": "2023-03-17T06:00:18.165529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database info: Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'sample_airbnb')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sample_airbnb'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Connector\n",
    "\n",
    "# !pip install pymongo\n",
    "# or #!conda install -y pymongo\n",
    "\n",
    "import re                                       # Regular Expressions\n",
    "import time                                     # For calculating time of execution\n",
    "import json                                     # For JSON operations\n",
    "import numpy as np                              # For numerical operations\n",
    "import pandas as pd                             # For data manipulation\n",
    "pd.set_option('display.max_rows', None)         # Display all rows\n",
    "\n",
    "# Disable FutureWarning messages\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from tqdm import tqdm                           # Progress bar\n",
    "from pprint import pprint                       # Pretty print\n",
    "from datetime import datetime                   # Datetime operations\n",
    "\n",
    "# MongoDB\n",
    "import bson\n",
    "from bson.objectid import ObjectId\n",
    "from bson.decimal128 import Decimal128\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connection\n",
    "user=\"AzureDiamond\"\n",
    "password=\"hunter2\"\n",
    "host=\"localhost\"\n",
    "port=\"27017\"\n",
    "protocol=\"mongodb\"\n",
    "client = MongoClient(f\"{protocol}://{user}:{password}@{host}:{port}\")\n",
    "\n",
    "# Database check\n",
    "db = client.sample_airbnb \n",
    "print(f\"Database info: {db}\\n\")\n",
    "db.name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Loading and Inspecting database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-16T22:26:35.207080Z",
     "start_time": "2023-03-16T22:26:34.475720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database contains 2 collections\n",
      "All collections: ['listingsAndReviews_HW2', 'listingsAndReviews']\n",
      "Collection listingsAndReviews_HW2 contains 5555 documents\n"
     ]
    }
   ],
   "source": [
    "# Collections are inside our Database 'sample_analytics'\n",
    "\n",
    "collection_list = db.list_collection_names()\n",
    "\n",
    "print(f\"The database contains {len(collection_list)} collections\")\n",
    "print(f\"All collections: {collection_list[0:]}\")\n",
    "print(f\"Collection {collection_list[0]} contains {db[collection_list[0]].count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[PyMongo documentation](https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAverage document size:\u001b[0m 67.09 KB\n"
     ]
    }
   ],
   "source": [
    "# Estimate average document size\n",
    "cursor = db.listingsAndReviews_HW2.find()                   # Cursor to iterate over documents\n",
    "sizes = [len(bson.BSON.encode(doc)) for doc in cursor]      # Calculate size of each document\n",
    "avg_size_kb = sum(sizes) / len(sizes) / 1024                # Average size in KB\n",
    "print(f\"\\033[1mAverage document size:\\033[0m {avg_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üìö Database Schema**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Data Cleanup and Schema Adjustments:** [9 points in total]\n",
    "\n",
    "# 1) Before working on the queries below, review the data and adjust the schema based on the typical use case described.\n",
    "\n",
    "# **Typical Use Case**: The most common use of the database is to show property listing information to customers. \n",
    "#                       A query retrieves a listing document from the database. Currently, retrieving a listing takes too long. \n",
    "#                       Decide what information should be included in a typical query and optimize the structure accordingly.  \n",
    "#                       For example, customers usually only need a sample of reviews, not all reviews (even though all reviews are stored). \n",
    "#                       They also don‚Äôt need past transaction data. \n",
    "#                       Update the document schema to fit this use case. \n",
    "#                       This might involve creating new collections or documents.\n",
    "\n",
    "# **Data Cleanup**: Review the data for any errors (such as transactions that don't belong to the listing) or unnecessary duplication, and clean it up where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In total, the first document contains 64 top-level fields\n"
     ]
    }
   ],
   "source": [
    "# Find one document in the collection 'listingsAndReviews'\n",
    "document = db.listingsAndReviews_HW2.find_one()\n",
    "# pprint(document)                                                                     # Large output, uncomment to see or open \"airbnb_document.json\" file\n",
    "print(f\"\\nIn total, the first document contains {len(document)} top-level fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA: Save the document to a JSON file (to see the structure more clearly)\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"\n",
    "    Converts non-serializable objects (like Decimal128 and datetime) to strings.\n",
    "    \"\"\"\n",
    "    if isinstance(obj, Decimal128):\n",
    "        return str(obj)\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type '{obj.__class__.__name__}' is not JSON serializable\")\n",
    "\n",
    "def save_to_json_file(document, filename=\"airbnb_document.json\"):\n",
    "    \"\"\"\n",
    "    Saves a MongoDB document to a JSON file, handling non-serializable data types.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(document, f, ensure_ascii=False, indent=4, default=convert_to_serializable)\n",
    "        print(f\"Document saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to JSON file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document saved to airbnb_document.json\n"
     ]
    }
   ],
   "source": [
    "# Save the document from 'listingsAndReviews_HW2' Collection to a JSON file\n",
    "save_to_json_file(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'reviews',\n",
      " 'reviews_copy1',\n",
      " 'reviews_copy2',\n",
      " 'reviews_copy3',\n",
      " 'reviews_copy4',\n",
      " 'reviews_per_month',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transit',\n",
      " 'weekly_price']\n",
      "\n",
      "In total, the collection contains 67 unique top-level fields\n"
     ]
    }
   ],
   "source": [
    "# Query to retrieve all fields names from the collection 'listingsAndReviews' (Using aggregation)\n",
    "# Define the aggregation pipeline\n",
    "pipeline = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},  # Convert document to key-value pairs          | Source: https://www.mongodb.com/docs/manual/reference/aggregation-variables/#mongodb-variable-variable.ROOT\n",
    "    {\"$unwind\": \"$fields\"},                                  # Flatten the fields array                     | Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}                         # Group by field names to get distinct fields  | Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "]\n",
    "\n",
    "# Execute the aggregation\n",
    "result = db.listingsAndReviews_HW2.aggregate(pipeline)\n",
    "\n",
    "# Extract distinct fields from the result\n",
    "fields = [doc[\"_id\"] for doc in result]\n",
    "\n",
    "# Print the list of unique fields\n",
    "pprint(sorted(fields))\n",
    "print(f\"\\nIn total, the collection contains {len(fields)} unique top-level fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The code above just return the **\"top-level\" fields** of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'address.country',\n",
      " 'address.country_code',\n",
      " 'address.government_area',\n",
      " 'address.location',\n",
      " 'address.location.coordinates',\n",
      " 'address.location.is_location_exact',\n",
      " 'address.location.type',\n",
      " 'address.market',\n",
      " 'address.street',\n",
      " 'address.suburb',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'availability.availability_30',\n",
      " 'availability.availability_365',\n",
      " 'availability.availability_60',\n",
      " 'availability.availability_90',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'images.medium_url',\n",
      " 'images.picture_url',\n",
      " 'images.thumbnail_url',\n",
      " 'images.xl_picture_url',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'reviews',\n",
      " 'reviews._id',\n",
      " 'reviews.comments',\n",
      " 'reviews.date',\n",
      " 'reviews.listing_id',\n",
      " 'reviews.reviewer_id',\n",
      " 'reviews.reviewer_name',\n",
      " 'reviews_copy1',\n",
      " 'reviews_copy1._id',\n",
      " 'reviews_copy1.comments',\n",
      " 'reviews_copy1.date',\n",
      " 'reviews_copy1.listing_id',\n",
      " 'reviews_copy1.reviewer_id',\n",
      " 'reviews_copy1.reviewer_name',\n",
      " 'reviews_copy2',\n",
      " 'reviews_copy2._id',\n",
      " 'reviews_copy2.comments',\n",
      " 'reviews_copy2.date',\n",
      " 'reviews_copy2.listing_id',\n",
      " 'reviews_copy2.reviewer_id',\n",
      " 'reviews_copy2.reviewer_name',\n",
      " 'reviews_copy3',\n",
      " 'reviews_copy3._id',\n",
      " 'reviews_copy3.comments',\n",
      " 'reviews_copy3.date',\n",
      " 'reviews_copy3.listing_id',\n",
      " 'reviews_copy3.reviewer_id',\n",
      " 'reviews_copy3.reviewer_name',\n",
      " 'reviews_copy4',\n",
      " 'reviews_copy4._id',\n",
      " 'reviews_copy4.comments',\n",
      " 'reviews_copy4.date',\n",
      " 'reviews_copy4.listing_id',\n",
      " 'reviews_copy4.reviewer_id',\n",
      " 'reviews_copy4.reviewer_name',\n",
      " 'reviews_per_month',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transactions.bucket_end_date',\n",
      " 'transactions.bucket_start_date',\n",
      " 'transactions.transaction_count',\n",
      " 'transactions.transactions',\n",
      " 'transactions.transactions.date',\n",
      " 'transactions.transactions.price',\n",
      " 'transit',\n",
      " 'weekly_price']\n",
      "In total, there are \u001b[1m121 unique fields\u001b[0m in the collection 'listingsAndReviews_HW2'\n"
     ]
    }
   ],
   "source": [
    "# Function to recursively extract all fields from a document (nested dictionaries and lists)\n",
    "def extract_fields(obj, prefix=\"\"):\n",
    "    \"\"\"Recursively extract all fields from a document.\n",
    "\n",
    "    Args:\n",
    "        obj: The object to process (dict, list, or other type). \n",
    "        prefix (str, optional): String prefix for nested fields (e.g., \"address\" becomes \"address.country\"). Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        fields: A set of unique field names found in the document.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty set to store unique fields\n",
    "    fields = set()\n",
    "    \n",
    "    # Check if the object is a dictionary (e.g., a MongoDB document or subdocument)\n",
    "    if isinstance(obj, dict):\n",
    "        # Iterate over field:value pairs in the dictionary\n",
    "        for k, v in obj.items():\n",
    "            # Construct the full field name; no dot if prefix is empty, otherwise add dot separator\n",
    "            full_field = f\"{prefix}{k}\" if not prefix else f\"{prefix}.{k}\"\n",
    "            fields.add(full_field)                                                      # Add the full field to the set\n",
    "            fields.update(extract_fields(v, full_field))                                # Recursively extract fields from the value, using the current field as prefix\n",
    "            \n",
    "    # Check if the object is a list (e.g., an array like 'reviews' or 'amenities')\n",
    "    elif isinstance(obj, list):\n",
    "        # Iterate over each item in the list\n",
    "        for item in obj:\n",
    "            # Recursively extract fields from the item, keeping the same prefix\n",
    "            fields.update(extract_fields(item, prefix))\n",
    "            \n",
    "    return fields\n",
    "\n",
    "# Aggregate to get all documents and process them\n",
    "all_fields = set()\n",
    "for doc in db.listingsAndReviews_HW2.find():\n",
    "    doc_fields = extract_fields(doc)\n",
    "    all_fields.update(doc_fields)\n",
    "\n",
    "# Convert to sorted list for readability\n",
    "unique_fields = sorted(list(all_fields))\n",
    "\n",
    "# Print the list of unique fields\n",
    "pprint(unique_fields)\n",
    "print(f\"In total, there are \\033[1m{len(unique_fields)} unique fields\\033[0m in the collection 'listingsAndReviews_HW2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Initial Data Inspection and Findings**\n",
    "\n",
    "The initial inspection of a sample document and the extraction of all unique field paths (both top-level and nested) reveal a complex structure within the `listingsAndReviews_HW2` collection. We identified **121 unique field paths**, indicating potentially large documents and complexity.\n",
    "\n",
    "Key findings align with the issues mentioned in the homework brief:\n",
    "\n",
    "1.  **Embedded Data & Large Documents:** Significant data is embedded:\n",
    "    *   **Host Information:** Details like `host_name`, `host_about`, `host_location` are repeated for every listing by the same host.\n",
    "    *   **Reviews:** The `reviews` array (and redundant `reviews_copy*` fields) can be very large, directly contributing to the identified performance issues (slow queries) and violating MongoDB's recommendation against unbounded arrays. The average document size is initially ~67 KB, but listings with many reviews are likely much larger.\n",
    "    *   **Transactions:** Transaction data is also embedded within a subdocument.\n",
    "2.  **Redundancy:** The `reviews_copy1` through `reviews_copy4` fields are clear indicators of unnecessary data duplication, wasting storage and complicating updates.\n",
    "3.  **Potential Data Type Issues:** Initial inspection suggests potential inconsistencies (e.g., numbers stored as strings, inconsistent use of `Decimal128`).\n",
    "4.  **Lack of Indexing:** Only the default `_id` index exists, meaning queries filtering or sorting on other fields will require inefficient collection scans.\n",
    "\n",
    "These points confirm the need for schema refactoring to improve performance, scalability, and data integrity. We will address redundancy, data types, and then apply appropriate modeling patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 listings with the most reviews:\n",
      "[{'_id': '4069429', 'reviewCount': 533},\n",
      " {'_id': '12954762', 'reviewCount': 469},\n",
      " {'_id': '95560', 'reviewCount': 463},\n",
      " {'_id': '476983', 'reviewCount': 420},\n",
      " {'_id': '5283892', 'reviewCount': 408}]\n"
     ]
    }
   ],
   "source": [
    "# Count listings with large number of reviews\n",
    "results = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True}}},                                         # Filter documents with 'reviews' field\n",
    "    {\"$project\": {\"reviewCount\": {\"$size\": \"$reviews\"}}},                               # Project the size of 'reviews' array\n",
    "    {\"$sort\": {\"reviewCount\": -1}},                                                     # Sort by review count\n",
    "    {\"$limit\": 5}                                                                       # Limit to top 5\n",
    "])\n",
    "print(\"\\nTop 5 listings with the most reviews:\")\n",
    "pprint(list(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]}}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check current indexes\n",
    "# Source: https://pymongo.readthedocs.io/en/stable/tutorial.html#indexing\n",
    "db.listingsAndReviews_HW2.index_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No fields indexed besides the key `_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üí¨ 1.1 | Confirm if All **`Reviews`** are in the same collection**\n",
    "\n",
    "We first address the obvious data redundancy issue. We suspect the `reviews_copy*` fields are duplicates of the main `reviews` array. We will verify this and then remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing reviews per document: 5555it [00:02, 2024.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "{'execution_time_seconds': 2.8220977783203125,\n",
      " 'mismatches_found': 0,\n",
      " 'total_documents': 5555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify if all copies of reviews contain the same data as 'reviews'\n",
    "def compare_reviews_per_document(verbose=True):\n",
    "    \"\"\"\n",
    "    Compares the 'reviews' array with all 'reviews_copy*' arrays for each document in the collection.\n",
    "    Checks if 'reviews' contains all reviews from the copies (by content) on a per-document basis.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool): If True, prints detailed results for each document as they are processed.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary of the comparison, including counts of mismatches and execution time.\n",
    "\n",
    "    Notes:\n",
    "        - Dynamically detects all fields matching 'reviews_copy*' using $objectToArray.\n",
    "        - Compares full review content (e.g., _id, date, comments) using $setEquals.\n",
    "        - Retains counts for additional insight.\n",
    "        - Uses tqdm for progress tracking.\n",
    "\n",
    "    Sources:\n",
    "        - $group: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "        - $project: https://www.mongodb.com/docs/manual/reference/operator/aggregation/project/\n",
    "        - $unwind: https://www.mongodb.com/docs/manual/reference/operator/aggregation/unwind/\n",
    "        - $objectToArray: https://www.mongodb.com/docs/manual/reference/operator/aggregation/objectToArray/\n",
    "        - $setEquals: https://www.mongodb.com/docs/manual/reference/operator/aggregation/setEquals/\n",
    "        - $filter: https://www.mongodb.com/docs/manual/reference/operator/aggregation/filter/\n",
    "        - $map: https://www.mongodb.com/docs/manual/reference/operator/aggregation/map/\n",
    "        - $reduce: https://www.mongodb.com/docs/manual/reference/operator/aggregation/reduce/\n",
    "        - $concatArrays: https://www.mongodb.com/docs/manual/reference/operator/aggregation/concatArrays/\n",
    "        - $regexMatch: https://www.mongodb.com/docs/manual/reference/operator/aggregation/regexMatch/\n",
    "        - $size: https://www.mongodb.com/docs/manual/reference/operator/aggregation/size/\n",
    "        - $ifNull: https://www.mongodb.com/docs/manual/reference/operator/aggregation/ifNull/\n",
    "    \"\"\"\n",
    "    # Start timing the entire process\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Count total documents for tqdm progress bar\n",
    "    total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "    # Pipeline to process each document individually\n",
    "    pipeline = [\n",
    "        \n",
    "        # Step 1: Group by _id to process each document separately\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$_id\",\n",
    "            \"all_fields\": {\"$first\": \"$$ROOT\"}  # Keep the entire document\n",
    "        }},\n",
    "        \n",
    "        # Step 2: Convert document fields to an array to find reviews_copy* dynamically\n",
    "        {\"$project\": {\n",
    "            \"_id\": 1,\n",
    "            \"reviews\": {\"$ifNull\": [\"$all_fields.reviews\", []]},\n",
    "            \"copy_fields\": {\n",
    "                \"$filter\": {                                                       # Filter fields that start with 'reviews_copy'\n",
    "                    \"input\": {\"$objectToArray\": \"$all_fields\"},\n",
    "                    \"cond\": {\"$regexMatch\": {\"input\": \"$$this.k\", \"regex\": \"^reviews_copy\"}}\n",
    "                }\n",
    "            }\n",
    "        }},\n",
    "        \n",
    "        # Step 3: Extract and compare content\n",
    "        {\"$project\": {\n",
    "            \"reviews_content\": \"$reviews\",                                          # Full content of reviews\n",
    "            \"copy_contents\": {\n",
    "                \"$map\": {                                                           # Extract the value (array) from each reviews_copy* field\n",
    "                    \"input\": \"$copy_fields\", \"in\": {\"$ifNull\": [\"$$this.v\", []]}\n",
    "                }\n",
    "            },\n",
    "            \"reviews_count\": {\"$size\": {\"$ifNull\": [\"$reviews\", []]}},\n",
    "            \"copy_counts\": {\n",
    "                \"$map\": {                                                           # Count reviews in each copy\n",
    "                    \"input\": \"$copy_fields\",\n",
    "                    \"in\": {\"name\": \"$$this.k\", \"count\": {\"$size\": {\"$ifNull\": [\"$$this.v\", []]}}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }},\n",
    "        \n",
    "        # Step 4: Compare content and check containment \n",
    "        {\"$project\": {\n",
    "            \"all_copies_match_reviews\": {\n",
    "                \"$reduce\": {                                                         # Iterate over all copy arrays to compare with reviews\n",
    "                    \"input\": \"$copy_contents\",\n",
    "                    \"initialValue\": True,\n",
    "                    \"in\": {\n",
    "                        \"$and\": [\n",
    "                            \"$$value\",                                               # Previous comparison result\n",
    "                            {\"$setEquals\": [                                         # Compare full content\n",
    "                                \"$reviews_content\",\n",
    "                                {\"$concatArrays\": [\"$reviews_content\", \"$$this\"]}\n",
    "                            ]}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"reviews_count\": 1,                                                     # Return/Project counts for additional insight\n",
    "            \"copy_counts\": 1\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    # Execute pipeline and iterate with tqdm\n",
    "    mismatches = 0                                              # Initialize mismatch counter\n",
    "    cursor = db.listingsAndReviews_HW2.aggregate(pipeline)      # Execute the aggregation pipeline\n",
    "\n",
    "    for doc in tqdm(cursor, desc=\"Comparing reviews per document\"):\n",
    "        doc_id = doc[\"_id\"]\n",
    "        all_match = doc[\"all_copies_match_reviews\"]\n",
    "        reviews_count = doc[\"reviews_count\"]\n",
    "        copy_counts = {item[\"name\"]: item[\"count\"] for item in doc[\"copy_counts\"]}\n",
    "\n",
    "        if not all_match:\n",
    "            mismatches += 1\n",
    "            if verbose:\n",
    "                print(f\"\\nMismatch found in document _id: {doc_id}\")\n",
    "                print(f\"Review counts - reviews: {reviews_count}, copies: {copy_counts}\")\n",
    "                print(\"Content in 'reviews' does not fully match all 'reviews_copy*' arrays.\")\n",
    "        elif verbose:\n",
    "            print(f\"\\nDocument _id: {doc_id} - All 'reviews_copy*' arrays match 'reviews'.\")\n",
    "            print(f\"Review counts - reviews: {reviews_count}, copies: {copy_counts}\")\n",
    "\n",
    "\n",
    "    # Calculate total execution time\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    # Summary of results\n",
    "    summary = {\n",
    "        \"total_documents\": total_docs,\n",
    "        \"mismatches_found\": mismatches,\n",
    "        \"execution_time_seconds\": execution_time\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Run the function\n",
    "result = compare_reviews_per_document(verbose=False)\n",
    "print(\"\\nSummary:\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Result:** The query confirms that for all documents, the content within `reviews_copy*` arrays is identical to the main `reviews` array. This confirms they are redundant.\n",
    "    - **Action:** We will remove the `reviews_copy*` fields from all documents in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents matched: 5555\n",
      "Number of documents modified (fields eliminated): 5555\n",
      "Fields deleted: ['reviews_copy1', 'reviews_copy2', 'reviews_copy3', 'reviews_copy4']\n",
      "Execution time: 0.991 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1.1.1. Delete all 'reviews_copy*' fields from the collection 'listingsAndReviews_HW2'\n",
    "\n",
    "# MongoDB update operation to remove specific 'reviews_copy*' fields\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/method/db.collection.updateMany/\n",
    "\n",
    "# Update operation to unset the specified fields\n",
    "start_time = time.time()                                    # Record start time\n",
    "update_result = db.listingsAndReviews_HW2.update_many(\n",
    "    filter={},                                              # Apply to all documents\n",
    "    update={\"$unset\": {                                     # Unset the specified fields\n",
    "        \"reviews_copy1\": \"\",\n",
    "        \"reviews_copy2\": \"\",\n",
    "        \"reviews_copy3\": \"\",\n",
    "        \"reviews_copy4\": \"\"\n",
    "    }}\n",
    ")\n",
    "execution_time = time.time() - start_time                   # Calculate execution time\n",
    "\n",
    "# Print the update result\n",
    "print(f\"Number of documents matched: {update_result.matched_count}\")\n",
    "print(f\"Number of documents modified (fields eliminated): {update_result.modified_count}\")\n",
    "print(f\"Fields deleted: ['reviews_copy1', 'reviews_copy2', 'reviews_copy3', 'reviews_copy4']\")\n",
    "print(f\"Execution time: {execution_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied **data cleanup by removing redundant fields** (`reviews_copy1` to `reviews_copy4`) because the verification query confirmed they contained identical data to the `reviews` field, leading to unnecessary storage consumption and potential update anomalies. We expect a **reduction in the total collection size and average document size**, leading to **faster reads and writes** when accessing listing documents, as less data needs to be processed or transferred.\n",
    "\n",
    "- The successful removal of these fields is confirmed by the verification query showing **0 documents containing them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with any 'reviews_copy1-4' fields remaining: 0\n",
      "Success: All specified 'reviews_copy*' fields were eliminated.\n"
     ]
    }
   ],
   "source": [
    "# Check to confirm removal\n",
    "remaining = db.listingsAndReviews_HW2.count_documents({\n",
    "    \"$or\": [\n",
    "        {\"reviews_copy1\": {\"$exists\": True}},\n",
    "        {\"reviews_copy2\": {\"$exists\": True}},\n",
    "        {\"reviews_copy3\": {\"$exists\": True}},\n",
    "        {\"reviews_copy4\": {\"$exists\": True}}\n",
    "    ]\n",
    "})\n",
    "print(f\"Documents with any 'reviews_copy1-4' fields remaining: {remaining}\")\n",
    "if remaining == 0:\n",
    "    print(\"Success: All specified 'reviews_copy*' fields were eliminated.\")\n",
    "else:\n",
    "    print(\"Warning: Some 'reviews_copy1-4' fields may still exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **üî¢üî† 1.2 | Inconsistent Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'access', 'accommodates', 'address', 'address.country', 'address.country_code', 'address.government_area', 'address.location', 'address.location.coordinates', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb', 'amenities', 'availability', 'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90', 'bathrooms', 'bed_type', 'bedrooms', 'beds', 'calendar_last_scraped', 'cancellation_policy', 'cleaning_fee', 'description', 'extra_people', 'first_review', 'guests_included', 'host_about', 'host_has_profile_pic', 'host_id', 'host_identity_verified', 'host_is_superhost', 'host_listings_count', 'host_location', 'host_name', 'host_neighbourhood', 'host_picture_url', 'host_response_rate', 'host_response_time', 'host_thumbnail_url', 'host_total_listings_count', 'host_url', 'host_verifications', 'house_rules', 'images', 'images.medium_url', 'images.picture_url', 'images.thumbnail_url', 'images.xl_picture_url', 'interaction', 'last_review', 'last_scraped', 'listing_url', 'maximum_nights', 'minimum_nights', 'monthly_price', 'name', 'neighborhood_overview', 'notes', 'number_of_reviews', 'price', 'property_type', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value', 'reviews', 'reviews._id', 'reviews.comments', 'reviews.date', 'reviews.listing_id', 'reviews.reviewer_id', 'reviews.reviewer_name', 'reviews_per_month', 'room_type', 'security_deposit', 'space', 'summary', 'transactions', 'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count', 'transactions.transactions', 'transactions.transactions.date', 'transactions.transactions.price', 'transit', 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "# Check data types of all fields in the collection 'listingsAndReviews_HW2'\n",
    "start_time = time.time()\n",
    "\n",
    "# Step 1: Extract all top-level fields and their data types (reuse the 'extract_fields' function)\n",
    "\n",
    "# Aggregate to get all documents and process them\n",
    "all_fields = set()\n",
    "for doc in db.listingsAndReviews_HW2.find():\n",
    "    doc_fields = extract_fields(doc)\n",
    "    all_fields.update(doc_fields)\n",
    "\n",
    "# Convert to sorted list for readability\n",
    "unique_fields = sorted(list(all_fields))\n",
    "print(unique_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing types across \u001b[1m5555\u001b[0m documents...\n",
      "Found \u001b[1m93 unique field paths\u001b[0m. DataFrame created with data types.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatypes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.coordinates</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions</th>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_end_date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_start_date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transaction_count</th>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions</th>\n",
       "      <td>list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>Decimal128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     datatypes\n",
       "field                                         \n",
       "_id                                        str\n",
       "access                                     str\n",
       "accommodates                               int\n",
       "address                                   dict\n",
       "address.country                            str\n",
       "address.country_code                       str\n",
       "address.government_area                    str\n",
       "address.location                          dict\n",
       "address.location.coordinates              list\n",
       "address.location.is_location_exact        bool\n",
       "address.location.type                      str\n",
       "address.market                             str\n",
       "address.street                             str\n",
       "address.suburb                             str\n",
       "amenities                                 list\n",
       "availability                              dict\n",
       "availability.availability_30               int\n",
       "availability.availability_365              int\n",
       "availability.availability_60               int\n",
       "availability.availability_90               int\n",
       "bathrooms                           Decimal128\n",
       "bed_type                                   str\n",
       "bedrooms                                   int\n",
       "beds                                       int\n",
       "calendar_last_scraped                 datetime\n",
       "cancellation_policy                        str\n",
       "cleaning_fee                        Decimal128\n",
       "description                                str\n",
       "extra_people                        Decimal128\n",
       "first_review                          datetime\n",
       "guests_included                     Decimal128\n",
       "host_about                                 str\n",
       "host_has_profile_pic                      bool\n",
       "host_id                                    str\n",
       "host_identity_verified                    bool\n",
       "host_is_superhost                         bool\n",
       "host_listings_count                        int\n",
       "host_location                              str\n",
       "host_name                                  str\n",
       "host_neighbourhood                         str\n",
       "host_picture_url                           str\n",
       "host_response_rate                         int\n",
       "host_response_time                         str\n",
       "host_thumbnail_url                         str\n",
       "host_total_listings_count                  int\n",
       "host_url                                   str\n",
       "host_verifications                        list\n",
       "house_rules                                str\n",
       "images                                    dict\n",
       "images.medium_url                          str\n",
       "images.picture_url                         str\n",
       "images.thumbnail_url                       str\n",
       "images.xl_picture_url                      str\n",
       "interaction                                str\n",
       "last_review                           datetime\n",
       "last_scraped                          datetime\n",
       "listing_url                                str\n",
       "maximum_nights                             str\n",
       "minimum_nights                             str\n",
       "monthly_price                       Decimal128\n",
       "name                                       str\n",
       "neighborhood_overview                      str\n",
       "notes                                      str\n",
       "number_of_reviews                          int\n",
       "price                               Decimal128\n",
       "property_type                              str\n",
       "review_scores_checkin                      int\n",
       "review_scores_cleanliness                  int\n",
       "review_scores_communication                int\n",
       "review_scores_location                     int\n",
       "review_scores_rating                       int\n",
       "review_scores_value                        int\n",
       "reviews                                   list\n",
       "reviews._id                                str\n",
       "reviews.comments                           str\n",
       "reviews.date                          datetime\n",
       "reviews.listing_id                         str\n",
       "reviews.reviewer_id                        str\n",
       "reviews.reviewer_name                      str\n",
       "reviews_per_month                          int\n",
       "room_type                                  str\n",
       "security_deposit                    Decimal128\n",
       "space                                      str\n",
       "summary                                    str\n",
       "transactions                              dict\n",
       "transactions.bucket_end_date          datetime\n",
       "transactions.bucket_start_date        datetime\n",
       "transactions.transaction_count             int\n",
       "transactions.transactions                 list\n",
       "transactions.transactions.date        datetime\n",
       "transactions.transactions.price            str\n",
       "transit                                    str\n",
       "weekly_price                        Decimal128"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to Recursively Extract Paths and Types\n",
    "# Source: X. (2025). Grok 3 Beta ‚Äî The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "#         Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_paths_and_types_simple(data, prefix=\"\", path_types_dict=None):\n",
    "    \"\"\"\n",
    "    Recursively finds all field paths and their Python types in a document.\n",
    "    \"\"\"\n",
    "    if path_types_dict is None:\n",
    "        path_types_dict = defaultdict(set)\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        # Handle dictionary (subdocument)\n",
    "        for key, value in data.items():\n",
    "            current_path = f\"{prefix}.{key}\" if prefix else key\n",
    "            # Add the Python type name to the set for this path\n",
    "            path_types_dict[current_path].add(type(value).__name__)\n",
    "            # Recurse if the value is complex (dict or list)\n",
    "            if isinstance(value, (dict, list)):\n",
    "                get_paths_and_types_simple(value, current_path, path_types_dict)\n",
    "                \n",
    "    elif isinstance(data, list):\n",
    "        # Handle list (array)\n",
    "        # Indicate the path exists and contains a list\n",
    "        path_types_dict[prefix].add('list') # Add 'list' type for the path itself\n",
    "        # Recurse into list elements if they are complex\n",
    "        for item in data:\n",
    "            if isinstance(item, (dict, list)):\n",
    "                # Pass the array's prefix to find types *within* its elements\n",
    "                get_paths_and_types_simple(item, prefix, path_types_dict)\n",
    "\n",
    "# --- Process All Documents ---\n",
    "all_field_types_summary = defaultdict(set)\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "print(f\"Analyzing types across \\033[1m{total_docs}\\033[0m documents...\")\n",
    "\n",
    "# Using find() iterates through documents directly\n",
    "# Add tqdm progress bar if desired: from tqdm import tqdm\n",
    "# for document in tqdm(db.listingsAndReviews_HW2.find(), total=total_docs, desc=\"Analyzing docs\"):\n",
    "for document in db.listingsAndReviews_HW2.find():\n",
    "    get_paths_and_types_simple(document, path_types_dict=all_field_types_summary)\n",
    "\n",
    "# --- Create DataFrame ---\n",
    "df_data_list_simple = []\n",
    "\n",
    "# Sort fields alphabetically for consistent output\n",
    "for field in sorted(all_field_types_summary.keys()):\n",
    "    # Join multiple types found for a field into a single string\n",
    "    type_str = \", \".join(sorted(list(all_field_types_summary[field])))\n",
    "    df_data_list_simple.append({\"field\": field, \"datatypes\": type_str})\n",
    "\n",
    "df_types_simple = pd.DataFrame(df_data_list_simple)\n",
    "df_types_simple.set_index(\"field\", inplace=True)\n",
    "print(f\"Found \\033[1m{len(df_types_simple)} unique field paths\\033[0m. DataFrame created with data types.\\n\")\n",
    "df_types_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Data Types Adjustments**\n",
    "\n",
    "Based on the data inspection (**code above** and **Studio3T**), we will make the following adjustments to ensure data consistency and improve query performance:\n",
    "\n",
    "- **`maximum_nights`** and **`minimum_nights`**: Convert from `string` to `int` if they represent numerical values.\n",
    "- **`bathrooms`**: Ensure it is consistently typed as `int`.\n",
    "- **`accommodates`**: Ensure it is consistently typed as `int`.\n",
    "- **`price`**, **`security_deposit`**, **`cleaning_fee`**, **`extra_people`**, **`guests_included`**, **`weekly_price`**, **`monthly_price`**: Ensure these are consistently typed as `decimal`.\n",
    "- **`transactions.transactions.price`**: Convert from `string` to `decimal`.\n",
    "- **`transit`**: If it always contains multiple values that can be separated by a delimiter, we can split it into an array of strings for easier querying.\n",
    "\n",
    ".\n",
    "\n",
    "- **`reviews._id`**, **`reviews.listing_id`**, **`reviews.reviewer_id`**: Ensure these are consistently typed as `ObjectId`.\n",
    "- **`address.location.coordinates`**: Confirm `array`, subfields `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1.2. Convert all fields to the correct data types in the collection 'listingsAndReviews_HW2'\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/convert/\n",
    "#         https://stackoverflow.com/a/56570099\n",
    "\n",
    "# Convert 'maximum_nights' and 'minimum_nights' to int\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},                                                                                         # Update all documents\n",
    "    [{\"$set\": {\"maximum_nights\": { \"$convert\": { \"input\": \"$maximum_nights\", \"to\": \"int\" } }}},\n",
    "     {\"$set\": {\"minimum_nights\": { \"$convert\": { \"input\": \"$minimum_nights\", \"to\": \"int\" } }}}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'minimum_nights': 2, 'maximum_nights': 30}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"maximum_nights\": 1, \"minimum_nights\": 1}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None,\n",
      "  'bathrooms': [Decimal128('0.0'),\n",
      "                Decimal128('8.0'),\n",
      "                Decimal128('2.0'),\n",
      "                Decimal128('1.0'),\n",
      "                Decimal128('7.0'),\n",
      "                Decimal128('16.0'),\n",
      "                Decimal128('3.0'),\n",
      "                Decimal128('2.5'),\n",
      "                Decimal128('5.0'),\n",
      "                Decimal128('9.0'),\n",
      "                Decimal128('3.5'),\n",
      "                Decimal128('5.5'),\n",
      "                Decimal128('4.5'),\n",
      "                Decimal128('4.0'),\n",
      "                Decimal128('0.5'),\n",
      "                Decimal128('1.5'),\n",
      "                Decimal128('6.0')]}]\n"
     ]
    }
   ],
   "source": [
    "# Check if all 'bathrooms' are integers\n",
    "bathrooms_all = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    # Return all 'bathrooms' values\n",
    "    {\"$group\": {\"_id\": None, \"bathrooms\": {\"$addToSet\": \"$bathrooms\"}}}\n",
    "]))\n",
    "\n",
    "# Extract the result\n",
    "pprint(bathrooms_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `bathrooms` field contains `Decimal128` values, including halves (e.g., $0.5$, $1.5$, $2.5$). \n",
    "    - According to Airbnb's help center and community discussions (e.g, https://community.withairbnb.com/t5/Advice-on-your-space/How-to-calculate-Bathrooms/td-p/1437848), a value of $0.5$ typically represents a half-bath (toilet only, no shower/bath).\n",
    "\n",
    "- **Decision:** We will **keep `bathrooms` as `Decimal128`** as the fractional values hold specific meaning within the Airbnb context and represent valid data points. We will not convert it to `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None,\n",
      "  'extra_people': [Decimal128('542.00'),\n",
      "                   Decimal128('90.00'),\n",
      "                   Decimal128('28.00'),\n",
      "                   Decimal128('59.00'),\n",
      "                   Decimal128('1119.00'),\n",
      "                   Decimal128('200.00'),\n",
      "                   Decimal128('107.00'),\n",
      "                   Decimal128('14.00'),\n",
      "                   Decimal128('45.00'),\n",
      "                   Decimal128('76.00'),\n",
      "                   Decimal128('149.00'),\n",
      "                   Decimal128('87.00'),\n",
      "                   Decimal128('600.00'),\n",
      "                   Decimal128('25.00'),\n",
      "                   Decimal128('118.00'),\n",
      "                   Decimal128('73.00'),\n",
      "                   Decimal128('11.00'),\n",
      "                   Decimal128('42.00'),\n",
      "                   Decimal128('220.00'),\n",
      "                   Decimal128('158.00'),\n",
      "                   Decimal128('34.00'),\n",
      "                   Decimal128('65.00'),\n",
      "                   Decimal128('127.00'),\n",
      "                   Decimal128('392.00'),\n",
      "                   Decimal128('175.00'),\n",
      "                   Decimal128('20.00'),\n",
      "                   Decimal128('186.00'),\n",
      "                   Decimal128('31.00'),\n",
      "                   Decimal128('93.00'),\n",
      "                   Decimal128('0.00'),\n",
      "                   Decimal128('530.00'),\n",
      "                   Decimal128('48.00'),\n",
      "                   Decimal128('79.00'),\n",
      "                   Decimal128('110.00'),\n",
      "                   Decimal128('17.00'),\n",
      "                   Decimal128('16.00'),\n",
      "                   Decimal128('250.00'),\n",
      "                   Decimal128('95.00'),\n",
      "                   Decimal128('157.00'),\n",
      "                   Decimal128('112.00'),\n",
      "                   Decimal128('44.00'),\n",
      "                   Decimal128('13.00'),\n",
      "                   Decimal128('30.00'),\n",
      "                   Decimal128('264.00'),\n",
      "                   Decimal128('560.00'),\n",
      "                   Decimal128('140.00'),\n",
      "                   Decimal128('53.00'),\n",
      "                   Decimal128('84.00'),\n",
      "                   Decimal128('22.00'),\n",
      "                   Decimal128('70.00'),\n",
      "                   Decimal128('769.00'),\n",
      "                   Decimal128('101.00'),\n",
      "                   Decimal128('8.00'),\n",
      "                   Decimal128('39.00'),\n",
      "                   Decimal128('132.00'),\n",
      "                   Decimal128('800.00'),\n",
      "                   Decimal128('211.00'),\n",
      "                   Decimal128('19.00'),\n",
      "                   Decimal128('50.00'),\n",
      "                   Decimal128('180.00'),\n",
      "                   Decimal128('1000.00'),\n",
      "                   Decimal128('160.00'),\n",
      "                   Decimal128('36.00'),\n",
      "                   Decimal128('98.00'),\n",
      "                   Decimal128('5.00'),\n",
      "                   Decimal128('270.00'),\n",
      "                   Decimal128('208.00'),\n",
      "                   Decimal128('300.00'),\n",
      "                   Decimal128('393.00'),\n",
      "                   Decimal128('145.00'),\n",
      "                   Decimal128('21.00'),\n",
      "                   Decimal128('83.00'),\n",
      "                   Decimal128('52.00'),\n",
      "                   Decimal128('255.00'),\n",
      "                   Decimal128('131.00'),\n",
      "                   Decimal128('7.00'),\n",
      "                   Decimal128('100.00'),\n",
      "                   Decimal128('968.00'),\n",
      "                   Decimal128('80.00'),\n",
      "                   Decimal128('500.00'),\n",
      "                   Decimal128('49.00'),\n",
      "                   Decimal128('18.00'),\n",
      "                   Decimal128('314.00'),\n",
      "                   Decimal128('97.00'),\n",
      "                   Decimal128('4.00'),\n",
      "                   Decimal128('35.00'),\n",
      "                   Decimal128('66.00'),\n",
      "                   Decimal128('10.00'),\n",
      "                   Decimal128('89.00'),\n",
      "                   Decimal128('120.00'),\n",
      "                   Decimal128('58.00'),\n",
      "                   Decimal128('27.00'),\n",
      "                   Decimal128('230.00'),\n",
      "                   Decimal128('199.00'),\n",
      "                   Decimal128('75.00'),\n",
      "                   Decimal128('179.00'),\n",
      "                   Decimal128('506.00'),\n",
      "                   Decimal128('55.00'),\n",
      "                   Decimal128('24.00'),\n",
      "                   Decimal128('117.00'),\n",
      "                   Decimal128('134.00'),\n",
      "                   Decimal128('72.00'),\n",
      "                   Decimal128('584.00'),\n",
      "                   Decimal128('102.00'),\n",
      "                   Decimal128('9.00'),\n",
      "                   Decimal128('40.00'),\n",
      "                   Decimal128('119.00'),\n",
      "                   Decimal128('150.00'),\n",
      "                   Decimal128('26.00'),\n",
      "                   Decimal128('223.00'),\n",
      "                   Decimal128('550.00'),\n",
      "                   Decimal128('130.00'),\n",
      "                   Decimal128('68.00'),\n",
      "                   Decimal128('37.00'),\n",
      "                   Decimal128('6.00'),\n",
      "                   Decimal128('240.00'),\n",
      "                   Decimal128('85.00'),\n",
      "                   Decimal128('350.00'),\n",
      "                   Decimal128('23.00'),\n",
      "                   Decimal128('54.00'),\n",
      "                   Decimal128('170.00'),\n",
      "                   Decimal128('77.00'),\n",
      "                   Decimal128('46.00'),\n",
      "                   Decimal128('590.00'),\n",
      "                   Decimal128('15.00'),\n",
      "                   Decimal128('280.00'),\n",
      "                   Decimal128('187.00'),\n",
      "                   Decimal128('63.00'),\n",
      "                   Decimal128('125.00'),\n",
      "                   Decimal128('32.00'),\n",
      "                   Decimal128('198.00'),\n",
      "                   Decimal128('900.00'),\n",
      "                   Decimal128('12.00'),\n",
      "                   Decimal128('105.00'),\n",
      "                   Decimal128('2346.00'),\n",
      "                   Decimal128('277.00'),\n",
      "                   Decimal128('60.00'),\n",
      "                   Decimal128('29.00')],\n",
      "  'guests_included': [Decimal128('6'),\n",
      "                      Decimal128('3'),\n",
      "                      Decimal128('2'),\n",
      "                      Decimal128('8'),\n",
      "                      Decimal128('4'),\n",
      "                      Decimal128('1'),\n",
      "                      Decimal128('5'),\n",
      "                      Decimal128('7'),\n",
      "                      Decimal128('9'),\n",
      "                      Decimal128('16'),\n",
      "                      Decimal128('10'),\n",
      "                      Decimal128('13'),\n",
      "                      Decimal128('15'),\n",
      "                      Decimal128('12')]}]\n"
     ]
    }
   ],
   "source": [
    "# Check if all 'guests_included' and 'extra_people' are integers\n",
    "guests_extra_all = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    # Return all 'guests_included' and 'extra_people' values\n",
    "    {\"$group\": {\"_id\": None, \"guests_included\": {\"$addToSet\": \"$guests_included\"}, \"extra_people\": {\"$addToSet\": \"$extra_people\"}}}\n",
    "]))\n",
    "pprint(guests_extra_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'guests_included' and 'extra_people' to int (since they are all integers but in wrong format - Decimal128)\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},                                                                                         # Update all documents\n",
    "    [{\"$set\": {\"guests_included\": { \"$convert\": { \"input\": \"$guests_included\", \"to\": \"int\" } }}},\n",
    "    #  {\"$set\": {\"extra_people\": { \"$convert\": { \"input\": \"$extra_people\", \"to\": \"int\" } }}}    # If u want to convert 'extra_people' as well\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `guests_included` field represents the number of guests included in the base price, which should logically be an integer. The `extra_people` field represents the *monetary charge* for additional guests, making `Decimal128` the appropriate type to handle currency values precisely.\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data type conversion** to the `guests_included` field, changing it from `Decimal128` to `int`, because it represents a count of people, which is inherently an integer. We expect **improved type consistency and potentially slightly more efficient storage and querying** for this field. \n",
    "    - The `extra_people` field remains `Decimal128` as it can represents a monetary value, although in the observations in this database they are coincidentally all integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 2084 documents have 'security_deposit' not as decimal.\n",
      "Warning: 1531 documents have 'cleaning_fee' not as decimal.\n",
      "Warning: 4841 documents have 'weekly_price' not as decimal.\n",
      "Warning: 4899 documents have 'monthly_price' not as decimal.\n"
     ]
    }
   ],
   "source": [
    "# Confirm price-related fields are decimal\n",
    "price_fields = [\"price\", \"security_deposit\", \"cleaning_fee\", \"weekly_price\", \"monthly_price\"]\n",
    "for field in price_fields:\n",
    "    non_decimal = db.listingsAndReviews_HW2.count_documents({field: {\"$not\": {\"$type\": \"decimal\"}}})\n",
    "    if non_decimal > 0:\n",
    "        print(f\"Warning: {non_decimal} documents have '{field}' not as decimal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price': Decimal128('80.00'),\n",
       " 'security_deposit': Decimal128('200.00'),\n",
       " 'cleaning_fee': Decimal128('35.00'),\n",
       " 'weekly_price': None,\n",
       " 'monthly_price': None}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert price-related fields to decimal\n",
    "for field in price_fields:\n",
    "    db.listingsAndReviews_HW2.update_many(\n",
    "        {},                                                                                     # Update all documents\n",
    "        [{\"$set\": {field: { \"$convert\": { \"input\": f\"${field}\", \"to\": \"decimal\" } }}}]\n",
    "    )\n",
    "    \n",
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"price\": 1, \"security_deposit\": 1, \"cleaning_fee\": 1, \"weekly_price\": 1, \"monthly_price\": 1}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We applied **data type conversion** to the price-related fields (`price`, `security_deposit`, `cleaning_fee`, `weekly_price`, `monthly_price`), ensuring they are consistently stored as `Decimal128` (or `double`), because these represent monetary values. Handling `null` or missing values appropriately during conversion (e.g., defaulting to `null` or `0.0` if applicable) ensures accurate financial calculations. We expect **improved query performance for range/comparison queries on prices and reliable aggregation results (like averages)**.\n",
    "\n",
    "**Note:** `weekly_price` and `monthly_price` often appear as `None` after conversion, indicating they were originally missing or `null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transactions': {'transactions': [{'date': datetime.datetime(2008, 8, 12, 0, 0),\n",
       "    'price': Decimal128('132.1063781684291313922585686668753')}]}}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'transactions.transactions.price' to decimal\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},\n",
    "    [{\"$set\": {\n",
    "        # Update the 'transactions.transactions.price' field\n",
    "        \"transactions.transactions\": {\n",
    "            # Check if 'transactions.transactions' is an array\n",
    "            \"$cond\": {\n",
    "                # If it is an array, convert the 'price' field to decimal\n",
    "                \"if\": {\"$isArray\": \"$transactions.transactions\"},\n",
    "                \"then\": {\n",
    "                    # Map over the array and convert the 'price' field to decimal\n",
    "                    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/map/\n",
    "                    \"$map\": {\n",
    "                        \"input\": \"$transactions.transactions\",\n",
    "                        \"as\": \"t\",\n",
    "                        \"in\": {\n",
    "                            \"date\": \"$$t.date\",\n",
    "                            \"price\": {\"$convert\": {\"input\": \"$$t.price\", \"to\": \"decimal\"}}\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                # If not an array, set to empty array\n",
    "                \"else\": []\n",
    "            }\n",
    "        }}}])\n",
    "\n",
    "# Confirm the data type conversion\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"_id\": 0, \"transactions.transactions\": {\"$slice\": [\"$transactions.transactions\", 1]}}}\n",
    "]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We applied **data type conversion** within the nested `transactions.transactions` array, converting the `price` field from `string` to `Decimal128`, because it represents a monetary value. This requires iterating through the array using `$map` within an update pipeline. We expect **accurate financial aggregations (like averages in Q10) and consistent data types** across all transaction records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`transit`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'We are located closest to the M, F, Z and J train. Walking distance '\n",
      "         'to the N, Q,R,W,4,5, 6, AND L'},\n",
      " {'_id': 'Sim, √¥nibus com destino ao centro da cidade e bondinho. Al√©m de '\n",
      "         'ponto de t√°xi e Uber.'},\n",
      " {'_id': 'Havaalanƒ±na 5 dk (arabayla) Otob√ºs duraƒüƒ±na 1 dk(y√ºr√ºyerek) T√ºm '\n",
      "         'otob√ºslerin olduƒüu ana duraƒüa 2 dk )(y√ºr√ºyerek)'},\n",
      " {'_id': 'My condo comes with a parking spot for your exclusive use at no '\n",
      "         'extra charge. To get to the University or the business district '\n",
      "         \"centre in downtown, you either take the bus or subway. You don't \"\n",
      "         'actually need a car as the bus stop is conveniently located outside '\n",
      "         \"our condo while the subway is a 10min walk. There's is a flea market \"\n",
      "         'for fresh produce and a variety of shops close by.'},\n",
      " {'_id': 'Estacionamento f√°cil na via p√∫blica, em frente a casa. F√°cil acesso '\n",
      "         'a transportes p√∫blicos regulares, nomeadamente autocarro e Metro.   '\n",
      "         'Autocarro 602. Esta√ß√£o de Metro mais pr√≥xima - Lidador ( Linha B) A '\n",
      "         'cerca de 3 km do Aeroporto do Porto.'}]\n"
     ]
    }
   ],
   "source": [
    "# Check all possible values for 'transit' field\n",
    "transit_values = list(db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$group\": {\"_id\": \"$transit\"}}\n",
    "]))\n",
    "pprint(transit_values[:5])  # Display the first few values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Analysis:** The `transit` field contains free-form text describing transportation options. It's unstructured and varies significantly in length and detail.\n",
    "    -  **Decision:** For the primary use case (displaying listing info quickly), structuring this field (e.g., splitting into an array) adds complexity without a clear, immediate benefit for the defined queries.\n",
    "       - **Action:** We will **leave the `transit` field as a string**. If future requirements necessitate searching specific transit types (e.g., \"metro\", \"bus\"), further refinement or indexing (like a text index) could be considered then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‚ÅâÔ∏è 1.3 | Missing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 76 unique non-array field paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking non-array fields: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76/76 [00:01<00:00, 68.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Combined Missing Value Analysis (Including Array Subfields) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>4899</td>\n",
       "      <td>88.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>4841</td>\n",
       "      <td>87.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>3080</td>\n",
       "      <td>55.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>2478</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>2453</td>\n",
       "      <td>44.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>2285</td>\n",
       "      <td>41.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>2241</td>\n",
       "      <td>40.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>2232</td>\n",
       "      <td>40.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>2219</td>\n",
       "      <td>39.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>2084</td>\n",
       "      <td>37.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>1923</td>\n",
       "      <td>34.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>1626</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>1531</td>\n",
       "      <td>27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>1475</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>1475</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>1474</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>1473</td>\n",
       "      <td>26.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>1388</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>887</td>\n",
       "      <td>15.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>258</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>95</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>42</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>30</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>13</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>10</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>8</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>7</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>6</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       n       %\n",
       "field                                           \n",
       "images.medium_url                   5555  100.00\n",
       "images.thumbnail_url                5555  100.00\n",
       "images.xl_picture_url               5555  100.00\n",
       "monthly_price                       4899   88.19\n",
       "weekly_price                        4841   87.15\n",
       "notes                               3080   55.45\n",
       "interaction                         2478   44.61\n",
       "access                              2453   44.16\n",
       "house_rules                         2285   41.13\n",
       "neighborhood_overview               2241   40.34\n",
       "transit                             2232   40.18\n",
       "host_about                          2219   39.95\n",
       "security_deposit                    2084   37.52\n",
       "host_neighbourhood                  1923   34.62\n",
       "space                               1626   29.27\n",
       "cleaning_fee                        1531   27.56\n",
       "review_scores_checkin               1475   26.55\n",
       "review_scores_value                 1475   26.55\n",
       "review_scores_communication         1474   26.53\n",
       "review_scores_location              1474   26.53\n",
       "review_scores_rating                1474   26.53\n",
       "review_scores_cleanliness           1473   26.52\n",
       "last_review                         1388   24.99\n",
       "host_response_rate                  1388   24.99\n",
       "first_review                        1388   24.99\n",
       "host_response_time                  1388   24.99\n",
       "address.suburb                       887   15.97\n",
       "summary                              258    4.64\n",
       "description                           95    1.71\n",
       "reviews.comments                      42    0.03\n",
       "amenities                             30    0.54\n",
       "beds                                  13    0.23\n",
       "bathrooms                             10    0.18\n",
       "host_location                          8    0.14\n",
       "name                                   8    0.14\n",
       "host_verifications                     7    0.13\n",
       "address.market                         6    0.11\n",
       "bedrooms                               5    0.09\n",
       "availability.availability_60           0    0.00\n",
       "availability.availability_90           0    0.00\n",
       "availability                           0    0.00\n",
       "availability.availability_30           0    0.00\n",
       "address.location.type                  0    0.00\n",
       "availability.availability_365          0    0.00\n",
       "address.country_code                   0    0.00\n",
       "address.country                        0    0.00\n",
       "address.government_area                0    0.00\n",
       "address.location.is_location_exact     0    0.00\n",
       "accommodates                           0    0.00\n",
       "_id                                    0    0.00\n",
       "address                                0    0.00\n",
       "address.street                         0    0.00\n",
       "bed_type                               0    0.00\n",
       "images                                 0    0.00\n",
       "host_total_listings_count              0    0.00\n",
       "host_name                              0    0.00\n",
       "host_picture_url                       0    0.00\n",
       "host_thumbnail_url                     0    0.00\n",
       "host_url                               0    0.00\n",
       "calendar_last_scraped                  0    0.00\n",
       "extra_people                           0    0.00\n",
       "cancellation_policy                    0    0.00\n",
       "host_has_profile_pic                   0    0.00\n",
       "guests_included                        0    0.00\n",
       "host_id                                0    0.00\n",
       "host_identity_verified                 0    0.00\n",
       "host_is_superhost                      0    0.00\n",
       "host_listings_count                    0    0.00\n",
       "images.picture_url                     0    0.00\n",
       "price                                  0    0.00\n",
       "property_type                          0    0.00\n",
       "number_of_reviews                      0    0.00\n",
       "maximum_nights                         0    0.00\n",
       "listing_url                            0    0.00\n",
       "last_scraped                           0    0.00\n",
       "minimum_nights                         0    0.00\n",
       "room_type                              0    0.00\n",
       "reviews.reviewer_id                    0    0.00\n",
       "reviews.reviewer_name                  0    0.00\n",
       "reviews.date                           0    0.00\n",
       "reviews.listing_id                     0    0.00\n",
       "reviews._id                            0    0.00\n",
       "transactions.transactions.date         0    0.00\n",
       "transactions.transactions.price        0    0.00"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check 'n' and '%' of missing values for all fields in the collection and subdocuments\n",
    "# Source: X. (2025). Grok 3 Beta ‚Äî The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "#         Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "\n",
    "# --- Code for Non-Array Fields ---\n",
    "\n",
    "# Step 1 & 2: Get unique non-array field paths (simplified from your original)\n",
    "# We'll focus on fields NOT starting with 'reviews' or 'transactions.transactions'\n",
    "# A more robust way is needed if nested structures are complex, but this covers the main fields.\n",
    "all_field_paths_orig = set()\n",
    "pipeline_get_fields = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "    {\"$unwind\": \"$fields\"},\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}\n",
    "]\n",
    "cursor_fields = db.listingsAndReviews_HW2.aggregate(pipeline_get_fields)\n",
    "for doc in cursor_fields:\n",
    "     # Exclude the array fields themselves and fields starting with host_\n",
    "     if not doc['_id'].startswith('reviews') and \\\n",
    "        not doc['_id'].startswith('transactions'):                            # Keep only non-array fields\n",
    "        all_field_paths_orig.add(doc['_id'])\n",
    "\n",
    "# Manually add known nested non-array fields if needed (adjust based on schema)\n",
    "all_field_paths_orig.update([\n",
    "    'address.country', 'address.country_code', 'address.government_area', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb',\n",
    "    'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90',\n",
    "    'images.picture_url', 'images.medium_url', 'images.thumbnail_url', 'images.xl_picture_url'\n",
    "])\n",
    "unique_fields_orig = sorted(list(all_field_paths_orig))\n",
    "print(f\"Checking {len(unique_fields_orig)} unique non-array field paths...\")\n",
    "\n",
    "# Step 3: Count missing values for these non-array fields\n",
    "missing_counts_orig = {}\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "for field in tqdm(unique_fields_orig, desc=\"Checking non-array fields\"):\n",
    "    # Count documents where field is missing, null, or empty string\n",
    "    # Note: This check might be slow without indexes on every field\n",
    "    missing = db.listingsAndReviews_HW2.count_documents({\n",
    "        \"$or\": [\n",
    "            {field: {\"$exists\": False}},\n",
    "            {field: None},\n",
    "            {field: \"\"},\n",
    "            {field: []}, # Check for empty arrays if applicable\n",
    "            {field: {}}, # Check for empty objects if applicable\n",
    "        ]\n",
    "    })\n",
    "    missing_counts_orig[field] = missing\n",
    "\n",
    "# Step 4: Create DataFrame for non-array fields\n",
    "df_data_orig = {\n",
    "    \"n\": [missing_counts_orig.get(field, 0) for field in unique_fields_orig],\n",
    "    \"%\": [round((missing_counts_orig.get(field, 0) / total_docs) * 100, 2) if total_docs > 0 else 0 for field in unique_fields_orig]\n",
    "}\n",
    "df_orig = pd.DataFrame(df_data_orig, index=unique_fields_orig)\n",
    "df_orig.index.name = \"field\"\n",
    "\n",
    "# --- Code for Array Subfields ---\n",
    "\n",
    "# 1. Analyze 'reviews' subfields\n",
    "reviews_analysis_pipeline = [\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True, \"$ne\": []}}}, # Only docs with non-empty reviews\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,                    # Group across all unwound reviews\n",
    "        \"TotalReviews\": {\"$sum\": 1},    # Count total reviews\n",
    "        # Check each relevant subfield within the review object\n",
    "        \"MissingComments\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.comments\", None]}, {\"$eq\": [\"$reviews.comments\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewerId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.reviewer_id\", None]}, {\"$eq\": [\"$reviews.reviewer_id\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewerName\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.reviewer_name\", None]}, {\"$eq\": [\"$reviews.reviewer_name\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingDate\": {\"$sum\": {\"$cond\": [{\"$eq\": [\"$reviews.date\", None]}, 1, 0]}},                                             # Date usually only check for null\n",
    "        \"MissingListingId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews.listing_id\", None]}, {\"$eq\": [\"$reviews.listing_id\", \"\"]}]}, 1, 0]}},\n",
    "        \"MissingReviewId\": {\"$sum\": {\"$cond\": [{\"$or\": [{\"$eq\": [\"$reviews._id\", None]}, {\"$eq\": [\"$reviews._id\", \"\"]}]}, 1, 0]}} # Check review _id\n",
    "    }},\n",
    "    # Project into a more readable format for combining later\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"TotalElements\": \"$TotalReviews\",\n",
    "        \"field_stats\": [\n",
    "            {\"field\": \"reviews.comments\", \"n\": \"$MissingComments\"},\n",
    "            {\"field\": \"reviews.reviewer_id\", \"n\": \"$MissingReviewerId\"},\n",
    "            {\"field\": \"reviews.reviewer_name\", \"n\": \"$MissingReviewerName\"},\n",
    "            {\"field\": \"reviews.date\", \"n\": \"$MissingDate\"},\n",
    "            {\"field\": \"reviews.listing_id\", \"n\": \"$MissingListingId\"},\n",
    "            {\"field\": \"reviews._id\", \"n\": \"$MissingReviewId\"}\n",
    "        ]\n",
    "    }}\n",
    "]\n",
    "reviews_missing_result = list(db.listingsAndReviews_HW2.aggregate(reviews_analysis_pipeline))\n",
    "\n",
    "# 2. Analyze 'transactions.transactions' subfields\n",
    "transactions_analysis_pipeline = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}}, # Only docs with non-empty transactions array\n",
    "    {\"$unwind\": \"$transactions.transactions\"},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None, # Group across all unwound transactions\n",
    "        \"TotalTransactions\": {\"$sum\": 1},\n",
    "        \"MissingDate\": {\"$sum\": {\"$cond\": [{\"$eq\": [\"$transactions.transactions.date\", None]}, 1, 0]}},\n",
    "        \"MissingPrice\": {\"$sum\": {\"$cond\": [{\"$or\": [\n",
    "            {\"$eq\": [\"$transactions.transactions.price\", None]},\n",
    "            # Add check for empty string ONLY if price was ever a string\n",
    "            {\"$eq\": [\"$transactions.transactions.price\", \"\"]}\n",
    "        ]}, 1, 0]}}\n",
    "    }},\n",
    "     # Project into a more readable format\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"TotalElements\": \"$TotalTransactions\",\n",
    "        \"field_stats\": [\n",
    "            {\"field\": \"transactions.transactions.date\", \"n\": \"$MissingDate\"},\n",
    "            {\"field\": \"transactions.transactions.price\", \"n\": \"$MissingPrice\"}\n",
    "        ]\n",
    "    }}\n",
    "]\n",
    "transactions_missing_result = list(db.listingsAndReviews_HW2.aggregate(transactions_analysis_pipeline))\n",
    "\n",
    "# 3. Combine results into DataFrame\n",
    "missing_data_combined = {}\n",
    "\n",
    "# Add non-array results\n",
    "for field, row in df_orig.iterrows():\n",
    "    missing_data_combined[field] = {\"n\": row['n'], \"TotalElements\": total_docs}\n",
    "\n",
    "# Add reviews results\n",
    "if reviews_missing_result:\n",
    "    total_reviews = reviews_missing_result[0].get(\"TotalElements\", 0)\n",
    "    for stat in reviews_missing_result[0].get(\"field_stats\", []):\n",
    "        missing_data_combined[stat[\"field\"]] = {\"n\": stat[\"n\"], \"TotalElements\": total_reviews}\n",
    "\n",
    "# Add transactions results\n",
    "if transactions_missing_result:\n",
    "    total_transactions = transactions_missing_result[0].get(\"TotalElements\", 0)\n",
    "    for stat in transactions_missing_result[0].get(\"field_stats\", []):\n",
    "        missing_data_combined[stat[\"field\"]] = {\"n\": stat[\"n\"], \"TotalElements\": total_transactions}\n",
    "\n",
    "# Create final DataFrame\n",
    "df_combined_data = []\n",
    "for field, data in missing_data_combined.items():\n",
    "    n_missing = data.get(\"n\", 0)\n",
    "    total_elements = data.get(\"TotalElements\", 0) # Use specific total for arrays\n",
    "    percent_missing = round((n_missing / total_elements) * 100, 2) if total_elements > 0 else 0\n",
    "    df_combined_data.append({\"field\": field, \"n\": n_missing, \"%\": percent_missing})\n",
    "\n",
    "missing_counts = pd.DataFrame(df_combined_data)\n",
    "missing_counts.set_index(\"field\", inplace=True)\n",
    "missing_counts[\"n\"] = missing_counts[\"n\"].astype(int)  # Ensure 'n' is integer type\n",
    "missing_counts.sort_values(by=\"n\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\n--- Combined Missing Value Analysis (Including Array Subfields) ---\")\n",
    "missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned 'access' from 2453 documents.\n",
      "Cleaned 'address.market' from 6 documents.\n",
      "Cleaned 'address.suburb' from 887 documents.\n",
      "Cleaned 'amenities' from 30 documents.\n",
      "Cleaned 'bathrooms' from 10 documents.\n",
      "Cleaned 'bedrooms' from 5 documents.\n",
      "Cleaned 'beds' from 13 documents.\n",
      "Cleaned 'cleaning_fee' from 1531 documents.\n",
      "Cleaned 'description' from 95 documents.\n",
      "Cleaned 'first_review' from 1388 documents.\n",
      "Cleaned 'host_about' from 2219 documents.\n",
      "Cleaned 'host_location' from 8 documents.\n",
      "Cleaned 'host_neighbourhood' from 1923 documents.\n",
      "Cleaned 'host_response_rate' from 1388 documents.\n",
      "Cleaned 'host_response_time' from 1388 documents.\n",
      "Cleaned 'host_verifications' from 7 documents.\n",
      "Cleaned 'house_rules' from 2285 documents.\n",
      "Cleaned 'images.medium_url' from 5555 documents.\n",
      "Cleaned 'images.thumbnail_url' from 5555 documents.\n",
      "Cleaned 'images.xl_picture_url' from 5555 documents.\n",
      "Cleaned 'interaction' from 2478 documents.\n",
      "Cleaned 'last_review' from 1388 documents.\n",
      "Cleaned 'monthly_price' from 4899 documents.\n",
      "Cleaned 'name' from 8 documents.\n",
      "Cleaned 'neighborhood_overview' from 2241 documents.\n",
      "Cleaned 'notes' from 3080 documents.\n",
      "Cleaned 'review_scores_checkin' from 1475 documents.\n",
      "Cleaned 'review_scores_cleanliness' from 1473 documents.\n",
      "Cleaned 'review_scores_communication' from 1474 documents.\n",
      "Cleaned 'review_scores_location' from 1474 documents.\n",
      "Cleaned 'review_scores_rating' from 1474 documents.\n",
      "Cleaned 'review_scores_value' from 1475 documents.\n",
      "Cleaned 'security_deposit' from 2084 documents.\n",
      "Cleaned 'space' from 1626 documents.\n",
      "Cleaned 'summary' from 258 documents.\n",
      "Cleaned 'transit' from 2232 documents.\n",
      "Cleaned 'weekly_price' from 4841 documents.\n"
     ]
    }
   ],
   "source": [
    "# Clean up - Remove fields with \"\" or None from individual documents\n",
    "fields_to_clean = [field for field in unique_fields_orig if field in missing_counts.index and missing_counts.loc[field, 'n'] > 0]\n",
    "for field in fields_to_clean:\n",
    "    # Remove field where it's \"\" or None\n",
    "    db.listingsAndReviews_HW2.update_many(\n",
    "        {\"$or\": [{field: \"\"}, {field: None}, {field: []}, {field: {}}]},     # Check for empty strings, None, empty arrays, or empty objects\n",
    "        {\"$unset\": {field: \"\"}}                                              # Unset the field from the document if it matches the criteria\n",
    "    )\n",
    "    print(f\"Cleaned '{field}' from {missing_counts.loc[field, 'n']} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We do not treat the `reviews` and `transactions` fields as missing data because they are **arrays of subdocuments**, not simple scalar fields. Analyzing them as \"missing\" at the top level would be misleading ‚Äî the field may exist and simply contain an empty array.\n",
    "  - Instead, we evaluate the **completeness of the data inside** these arrays by unwinding them and checking for missing values within each subdocument (e.g., `review.date`, `transaction.price`). This allows us to capture cases where fields are either null, missing entirely, or empty strings.\n",
    "\n",
    "- Our analysis showed that all `transactions` (n = $311 \\;093$) are fully populated, with **no missing values** in the inspected fields. Among the `reviews` (n = $149\\;793$), we found **42 missing values** in the `comments` field (i.e., either `null` or empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify cleanup\n",
    "post_cleanup_counts = {}\n",
    "for field in fields_to_clean:\n",
    "    \n",
    "    # Count remaining documents with field as None\n",
    "    remaining = db.listingsAndReviews_HW2.count_documents({\n",
    "        field: {\"$eq\": None, \"$exists\": True}\n",
    "    })\n",
    "    post_cleanup_counts[field] = remaining\n",
    "    if remaining > 0:\n",
    "        print(f\"Warning: {remaining} documents still have '{field}' as None and explicitly exist.\")\n",
    "    \n",
    "    # Check for empty strings \n",
    "    empty_str_count = db.listingsAndReviews_HW2.count_documents({\n",
    "        field: {\"$eq\": \"\", \"$exists\": True}\n",
    "    })\n",
    "    if empty_str_count > 0:\n",
    "        print(f\"Note: {empty_str_count} documents still have '{field}' as empty string and explicitly exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The initial check revealed numerous fields with missing (`null`) or empty string (`\"\"`) values, particularly for optional details like `notes`, `interaction`, `host_about`, `security_deposit`, and pricing fields (`weekly_price`, `monthly_price`).\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data cleanup by removing missing/empty fields** using `$unset` for fields identified with `null` or `\"\"` values, because these values often provide no information and can interfere with queries (e.g., type checking, `$exists`). We expect **cleaner data, slightly reduced document size, and more predictable query behavior** when filtering or checking for field existence.\n",
    "\n",
    "\n",
    "The verification confirms that `null` and `\"\"` values were successfully unset from the documents. Fields listed as having `0` remaining `null` or `\"\"` values (where `$exists: true`) are now clean in that regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **‚ô®Ô∏è 1.4 | Data Cleanup - Invalid/Outliers Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'access', 'accommodates', 'address', 'address.country', 'address.country_code', 'address.government_area', 'address.location', 'address.location.coordinates', 'address.location.is_location_exact', 'address.location.type', 'address.market', 'address.street', 'address.suburb', 'amenities', 'availability', 'availability.availability_30', 'availability.availability_365', 'availability.availability_60', 'availability.availability_90', 'bathrooms', 'bed_type', 'bedrooms', 'beds', 'calendar_last_scraped', 'cancellation_policy', 'cleaning_fee', 'description', 'extra_people', 'first_review', 'guests_included', 'host_about', 'host_has_profile_pic', 'host_id', 'host_identity_verified', 'host_is_superhost', 'host_listings_count', 'host_location', 'host_name', 'host_neighbourhood', 'host_picture_url', 'host_response_rate', 'host_response_time', 'host_thumbnail_url', 'host_total_listings_count', 'host_url', 'host_verifications', 'house_rules', 'images', 'images.medium_url', 'images.picture_url', 'images.thumbnail_url', 'images.xl_picture_url', 'interaction', 'last_review', 'last_scraped', 'listing_url', 'maximum_nights', 'minimum_nights', 'monthly_price', 'name', 'neighborhood_overview', 'notes', 'number_of_reviews', 'price', 'property_type', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value', 'reviews', 'reviews._id', 'reviews.comments', 'reviews.date', 'reviews.listing_id', 'reviews.reviewer_id', 'reviews.reviewer_name', 'reviews_per_month', 'room_type', 'security_deposit', 'space', 'summary', 'transactions', 'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count', 'transactions.transactions', 'transactions.transactions.date', 'transactions.transactions.price', 'transit', 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "print(unique_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Statistical Summary Generation ---\n",
      "Analyzing non-array fields...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing main fields: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 [00:01<00:00, 41.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'reviews' subfields...\n",
      "Total review elements to analyze: 149792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing review fields: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'transactions.transactions' subfields...\n",
      "Total transaction elements to analyze: 311093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing transaction fields: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 'amenities'...\n",
      "Total amenity elements to analyze: 121372\n",
      "Analyzing 'host_verifications'...\n",
      "Total verification elements to analyze: 27593\n",
      "\n",
      "--- Final Statistical Summary (Original Collection) ---\n",
      "Total fields: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Distinct Count</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <td>5555</td>\n",
       "      <td>5555</td>\n",
       "      <td>-</td>\n",
       "      <td>10006546</td>\n",
       "      <td>9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access</th>\n",
       "      <td>3102</td>\n",
       "      <td>2988</td>\n",
       "      <td>-</td>\n",
       "      <td>Everything is located in a beautiful and spac...</td>\n",
       "      <td>ÔΩºÔΩ™ÔΩ±ÔΩ∑ÔΩØÔæÅÔæù„ÇÇ„ÅÇ„Çä„Åæ„Åô! Share kitchen is located on 2nd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>5555</td>\n",
       "      <td>16</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country</th>\n",
       "      <td>5555</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Australia</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.country_code</th>\n",
       "      <td>5555</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>AU</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.government_area</th>\n",
       "      <td>5555</td>\n",
       "      <td>418</td>\n",
       "      <td>-</td>\n",
       "      <td>AVer-o-Mar, Amorim e Terroso</td>\n",
       "      <td>√Årvore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.is_location_exact</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.location.type</th>\n",
       "      <td>5555</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>Point</td>\n",
       "      <td>Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.market</th>\n",
       "      <td>5549</td>\n",
       "      <td>14</td>\n",
       "      <td>-</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>The Big Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.street</th>\n",
       "      <td>5555</td>\n",
       "      <td>677</td>\n",
       "      <td>-</td>\n",
       "      <td>ADALAR, Istanbul, Turkey</td>\n",
       "      <td>È¶ôÊ∏Ø, È¶ôÊ∏Ø, Hong Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address.suburb</th>\n",
       "      <td>4668</td>\n",
       "      <td>409</td>\n",
       "      <td>-</td>\n",
       "      <td>Abbotsford/Wareemba</td>\n",
       "      <td>≈ûi≈üli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amenities</th>\n",
       "      <td>121372</td>\n",
       "      <td>185</td>\n",
       "      <td>-</td>\n",
       "      <td>24-hour check-in</td>\n",
       "      <td>translation missing: en.hosting_amenity_50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_30</th>\n",
       "      <td>5555</td>\n",
       "      <td>31</td>\n",
       "      <td>11.82</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_365</th>\n",
       "      <td>5555</td>\n",
       "      <td>366</td>\n",
       "      <td>173.11</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_60</th>\n",
       "      <td>5555</td>\n",
       "      <td>61</td>\n",
       "      <td>26.45</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability.availability_90</th>\n",
       "      <td>5555</td>\n",
       "      <td>91</td>\n",
       "      <td>42.76</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>5545</td>\n",
       "      <td>17</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>Airbed</td>\n",
       "      <td>Real Bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>5550</td>\n",
       "      <td>13</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>5542</td>\n",
       "      <td>19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <td>5555</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>2019-02-11 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <td>5555</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>flexible</td>\n",
       "      <td>super_strict_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleaning_fee</th>\n",
       "      <td>4024</td>\n",
       "      <td>291</td>\n",
       "      <td>94.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>5460</td>\n",
       "      <td>5441</td>\n",
       "      <td>-</td>\n",
       "      <td>Cozy room! It has a double bed, cable ...</td>\n",
       "      <td>Î£∏Ïóê Ï∞ΩÎ¨∏Ïù¥ ÏûàÏñ¥Í¥òÏ†ÅÌï©ÎãàÎã§. tv,Î¨¥ÏÑ†Ïù∏ÌÑ∞ÎÑ∑  Í∏∞Î≥∏ ÌïÑÏàòÌíà Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§ ÏàôÏÜåÎ∞î...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_people</th>\n",
       "      <td>5555</td>\n",
       "      <td>138</td>\n",
       "      <td>22.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2346.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review</th>\n",
       "      <td>4167</td>\n",
       "      <td>1686</td>\n",
       "      <td>-</td>\n",
       "      <td>2009-10-27 04:00:00</td>\n",
       "      <td>2019-03-10 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included</th>\n",
       "      <td>5555</td>\n",
       "      <td>14</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>3336</td>\n",
       "      <td>2949</td>\n",
       "      <td>-</td>\n",
       "      <td>\\n</td>\n",
       "      <td>ÔΩ°</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>5555</td>\n",
       "      <td>5104</td>\n",
       "      <td>-</td>\n",
       "      <td>10002884</td>\n",
       "      <td>99997584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>5555</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_listings_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>132</td>\n",
       "      <td>14.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_location</th>\n",
       "      <td>5547</td>\n",
       "      <td>675</td>\n",
       "      <td>-</td>\n",
       "      <td>New South Wales, Australia</td>\n",
       "      <td>Î∂ÄÏÇ∞, ÎåÄÌïúÎØºÍµ≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>5555</td>\n",
       "      <td>3140</td>\n",
       "      <td>-</td>\n",
       "      <td>(Email hidden by Airbnb)</td>\n",
       "      <td>È¶®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_neighbourhood</th>\n",
       "      <td>3632</td>\n",
       "      <td>446</td>\n",
       "      <td>-</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>≈ûi≈üli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5086</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/defaults/user_pic-225x...</td>\n",
       "      <td>https://a0.muscache.com/im/users/9997988/profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>4167</td>\n",
       "      <td>62</td>\n",
       "      <td>93.12</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>4167</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>a few days or more</td>\n",
       "      <td>within an hour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_thumbnail_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5086</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/defaults/user_pic-50x5...</td>\n",
       "      <td>https://a0.muscache.com/im/users/9997988/profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>132</td>\n",
       "      <td>14.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5104</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.airbnb.com/users/show/10002884</td>\n",
       "      <td>https://www.airbnb.com/users/show/99997584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications</th>\n",
       "      <td>27593</td>\n",
       "      <td>19</td>\n",
       "      <td>-</td>\n",
       "      <td>email</td>\n",
       "      <td>zhima_selfie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house_rules</th>\n",
       "      <td>3270</td>\n",
       "      <td>3112</td>\n",
       "      <td>-</td>\n",
       "      <td>\"Mi casa es su casa\".  When you leave please t...</td>\n",
       "      <td>ÔΩ•No Smoking, ÔΩ•No Pet, ÔΩ•No Party, ÔΩ•No Children ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.medium_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.picture_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5553</td>\n",
       "      <td>-</td>\n",
       "      <td>https://a0.muscache.com/4ea/air/v2//pictures/0...</td>\n",
       "      <td>https://a0.muscache.com/im/pictures/fff8056a-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.thumbnail_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images.xl_picture_url</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction</th>\n",
       "      <td>3077</td>\n",
       "      <td>2916</td>\n",
       "      <td>-</td>\n",
       "      <td>'Ohana Nui means Big Family, which is what we ...</td>\n",
       "      <td>Í∞úÏä§Ìä∏Ïóê Îî∞Îùº..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>4167</td>\n",
       "      <td>809</td>\n",
       "      <td>-</td>\n",
       "      <td>2012-01-06 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_scraped</th>\n",
       "      <td>5555</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>2019-02-11 05:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_url</th>\n",
       "      <td>5555</td>\n",
       "      <td>5555</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.airbnb.com/rooms/10006546</td>\n",
       "      <td>https://www.airbnb.com/rooms/9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>5555</td>\n",
       "      <td>140</td>\n",
       "      <td>1382776.32</td>\n",
       "      <td>1</td>\n",
       "      <td>2147483647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>5555</td>\n",
       "      <td>45</td>\n",
       "      <td>5.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_price</th>\n",
       "      <td>656</td>\n",
       "      <td>309</td>\n",
       "      <td>5391.37</td>\n",
       "      <td>250.0</td>\n",
       "      <td>253384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>5547</td>\n",
       "      <td>5537</td>\n",
       "      <td>-</td>\n",
       "      <td>!5 mins from MTR! Ideal for biz travel / family</td>\n",
       "      <td>ÔΩ°Townhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>3314</td>\n",
       "      <td>3227</td>\n",
       "      <td>-</td>\n",
       "      <td>\"Be happy in Porto\"  offers a quality accommod...</td>\n",
       "      <td>ÔΩ±ÔΩØÔæÑÔæéÔΩ∞Ôæë„Å™Èõ∞Âõ≤Ê∞ó„ÅßÔΩ§Êó•Êú¨‰∫∫„ÅÆ„ÅîÂÆ∂Êóè„ÅåÂ§ö„Åè‰Ωè„Çì„Åß„ÅÑ„ÇãÔΩ¥ÔæòÔΩ±„Åß„ÅôÔΩ°ÊúÄËøë„ÅØ„Åã„Çè„ÅÑ„ÅÑÔΩ∂ÔæåÔΩ™„ÇÇÂ¢ó„Åà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>2475</td>\n",
       "      <td>2381</td>\n",
       "      <td>-</td>\n",
       "      <td>!!!Sejam muito bem vindos!!!</td>\n",
       "      <td>Ôø´  Feel free to smoke in our outdoor area, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>5555</td>\n",
       "      <td>259</td>\n",
       "      <td>27.61</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>5555</td>\n",
       "      <td>649</td>\n",
       "      <td>278.77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>36</td>\n",
       "      <td>-</td>\n",
       "      <td>Aparthotel</td>\n",
       "      <td>Villa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <td>4080</td>\n",
       "      <td>9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <td>4082</td>\n",
       "      <td>8</td>\n",
       "      <td>9.32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_communication</th>\n",
       "      <td>4081</td>\n",
       "      <td>9</td>\n",
       "      <td>9.69</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>4081</td>\n",
       "      <td>8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating</th>\n",
       "      <td>4081</td>\n",
       "      <td>41</td>\n",
       "      <td>93.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_value</th>\n",
       "      <td>4080</td>\n",
       "      <td>9</td>\n",
       "      <td>9.31</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews._id</th>\n",
       "      <td>149792</td>\n",
       "      <td>149792</td>\n",
       "      <td>-</td>\n",
       "      <td>10000121</td>\n",
       "      <td>99999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.comments</th>\n",
       "      <td>149784</td>\n",
       "      <td>146782</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>ÔæúÔΩ≤ÔΩ∑ÔΩ∑ÔæãÔæûÔΩ∞ÔæÅÔΩ§DFS‰ªñÔΩºÔΩÆÔΩØÔæãÔæüÔæùÔΩ∏ÔæûÔæìÔΩ∞Ôæô„Å´Ëøë„ÅèÈùûÂ∏∏„Å´‰æøÂà©„ÅßÊúâ„Çä„Å™„Åå„ÇâÈùô„ÅãÔΩ°ABCÔæèÔΩ∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.date</th>\n",
       "      <td>149792</td>\n",
       "      <td>2778</td>\n",
       "      <td>-</td>\n",
       "      <td>2009-10-27 04:00:00</td>\n",
       "      <td>2019-03-11 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.listing_id</th>\n",
       "      <td>149792</td>\n",
       "      <td>3923</td>\n",
       "      <td>-</td>\n",
       "      <td>10006546</td>\n",
       "      <td>9993190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_id</th>\n",
       "      <td>149792</td>\n",
       "      <td>146640</td>\n",
       "      <td>-</td>\n",
       "      <td>10000032</td>\n",
       "      <td>99998112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews.reviewer_name</th>\n",
       "      <td>149791</td>\n",
       "      <td>32901</td>\n",
       "      <td>-</td>\n",
       "      <td>'Dea</td>\n",
       "      <td>ÔæïÔΩ≥ÔæÄÔæõÔΩ≥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>5555</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>Shared room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security_deposit</th>\n",
       "      <td>3471</td>\n",
       "      <td>213</td>\n",
       "      <td>509.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>3929</td>\n",
       "      <td>3887</td>\n",
       "      <td>-</td>\n",
       "      <td>Cozy room! It has a double bed, cable ...</td>\n",
       "      <td>Ôø´ Second floor studio (you must climb 2 flight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>5297</td>\n",
       "      <td>5259</td>\n",
       "      <td>-</td>\n",
       "      <td>Simply Hostel is, a brand new Licensed ...</td>\n",
       "      <td>Î£∏Ïóê Ï∞ΩÎ¨∏Ïù¥ ÏûàÏñ¥Í¥òÏ†ÅÌï©ÎãàÎã§. tv,Î¨¥ÏÑ†Ïù∏ÌÑ∞ÎÑ∑  Í∏∞Î≥∏ ÌïÑÏàòÌíà Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§ ÏàôÏÜåÎ∞î...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_end_date</th>\n",
       "      <td>5555</td>\n",
       "      <td>208</td>\n",
       "      <td>-</td>\n",
       "      <td>2002-03-05 00:00:00</td>\n",
       "      <td>2017-01-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.bucket_start_date</th>\n",
       "      <td>5555</td>\n",
       "      <td>1362</td>\n",
       "      <td>-</td>\n",
       "      <td>1962-01-08 00:00:00</td>\n",
       "      <td>2015-11-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transaction_count</th>\n",
       "      <td>5555</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.date</th>\n",
       "      <td>311093</td>\n",
       "      <td>8651</td>\n",
       "      <td>-</td>\n",
       "      <td>1962-03-08 00:00:00</td>\n",
       "      <td>2017-01-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactions.transactions.price</th>\n",
       "      <td>311093</td>\n",
       "      <td>73190</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>845.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>3323</td>\n",
       "      <td>3230</td>\n",
       "      <td>-</td>\n",
       "      <td>it is less than 5 minutes walk from Taksim an...</td>\n",
       "      <td>ÎåÄÏ§ë ÍµêÌÜµÏù¥ ÏôÄÏù¥ÏºàÎ†ê ÏÉ§Ìïë ÏåòÌÉÄ ÏóêÏÑú ÎèÑÎ≥¥Î°ú 5 -7 Î∂Ñ ÏßëÍπåÏßÄ, Í¥ÄÍ¥ë Î≤ÑÏä§Í∞Ä ÏàòÏãú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly_price</th>\n",
       "      <td>714</td>\n",
       "      <td>323</td>\n",
       "      <td>1530.9</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59123.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Count  Distinct Count        Mean  \\\n",
       "field                                                                    \n",
       "_id                                   5555            5555           -   \n",
       "access                                3102            2988           -   \n",
       "accommodates                          5555              16        3.51   \n",
       "address.country                       5555               9           -   \n",
       "address.country_code                  5555               9           -   \n",
       "address.government_area               5555             418           -   \n",
       "address.location.is_location_exact    5555               2        0.67   \n",
       "address.location.type                 5555               1           -   \n",
       "address.market                        5549              14           -   \n",
       "address.street                        5555             677           -   \n",
       "address.suburb                        4668             409           -   \n",
       "amenities                           121372             185           -   \n",
       "availability.availability_30          5555              31       11.82   \n",
       "availability.availability_365         5555             366      173.11   \n",
       "availability.availability_60          5555              61       26.45   \n",
       "availability.availability_90          5555              91       42.76   \n",
       "bathrooms                             5545              17        1.29   \n",
       "bed_type                              5555               5           -   \n",
       "bedrooms                              5550              13        1.41   \n",
       "beds                                  5542              19        2.07   \n",
       "calendar_last_scraped                 5555               7           -   \n",
       "cancellation_policy                   5555               5           -   \n",
       "cleaning_fee                          4024             291       94.07   \n",
       "description                           5460            5441           -   \n",
       "extra_people                          5555             138       22.79   \n",
       "first_review                          4167            1686           -   \n",
       "guests_included                       5555              14        1.75   \n",
       "host_about                            3336            2949           -   \n",
       "host_has_profile_pic                  5555               2         1.0   \n",
       "host_id                               5555            5104           -   \n",
       "host_identity_verified                5555               2        0.36   \n",
       "host_is_superhost                     5555               2         0.2   \n",
       "host_listings_count                   5555             132       14.41   \n",
       "host_location                         5547             675           -   \n",
       "host_name                             5555            3140           -   \n",
       "host_neighbourhood                    3632             446           -   \n",
       "host_picture_url                      5555            5086           -   \n",
       "host_response_rate                    4167              62       93.12   \n",
       "host_response_time                    4167               4           -   \n",
       "host_thumbnail_url                    5555            5086           -   \n",
       "host_total_listings_count             5555             132       14.41   \n",
       "host_url                              5555            5104           -   \n",
       "host_verifications                   27593              19           -   \n",
       "house_rules                           3270            3112           -   \n",
       "images.medium_url                        0               0           -   \n",
       "images.picture_url                    5555            5553           -   \n",
       "images.thumbnail_url                     0               0           -   \n",
       "images.xl_picture_url                    0               0           -   \n",
       "interaction                           3077            2916           -   \n",
       "last_review                           4167             809           -   \n",
       "last_scraped                          5555               7           -   \n",
       "listing_url                           5555            5555           -   \n",
       "maximum_nights                        5555             140  1382776.32   \n",
       "minimum_nights                        5555              45        5.56   \n",
       "monthly_price                          656             309     5391.37   \n",
       "name                                  5547            5537           -   \n",
       "neighborhood_overview                 3314            3227           -   \n",
       "notes                                 2475            2381           -   \n",
       "number_of_reviews                     5555             259       27.61   \n",
       "price                                 5555             649      278.77   \n",
       "property_type                         5555              36           -   \n",
       "review_scores_checkin                 4080               9         9.7   \n",
       "review_scores_cleanliness             4082               8        9.32   \n",
       "review_scores_communication           4081               9        9.69   \n",
       "review_scores_location                4081               8         9.6   \n",
       "review_scores_rating                  4081              41        93.1   \n",
       "review_scores_value                   4080               9        9.31   \n",
       "reviews._id                         149792          149792           -   \n",
       "reviews.comments                    149784          146782           -   \n",
       "reviews.date                        149792            2778           -   \n",
       "reviews.listing_id                  149792            3923           -   \n",
       "reviews.reviewer_id                 149792          146640           -   \n",
       "reviews.reviewer_name               149791           32901           -   \n",
       "reviews_per_month                       94               8        1.71   \n",
       "room_type                             5555               3           -   \n",
       "security_deposit                      3471             213      509.43   \n",
       "space                                 3929            3887           -   \n",
       "summary                               5297            5259           -   \n",
       "transactions.bucket_end_date          5555             208           -   \n",
       "transactions.bucket_start_date        5555            1362           -   \n",
       "transactions.transaction_count        5555             100        56.0   \n",
       "transactions.transactions.date      311093            8651           -   \n",
       "transactions.transactions.price     311093           73190        83.0   \n",
       "transit                               3323            3230           -   \n",
       "weekly_price                           714             323      1530.9   \n",
       "\n",
       "                                                                                  Min  \\\n",
       "field                                                                                   \n",
       "_id                                                                          10006546   \n",
       "access                               Everything is located in a beautiful and spac...   \n",
       "accommodates                                                                        1   \n",
       "address.country                                                             Australia   \n",
       "address.country_code                                                               AU   \n",
       "address.government_area                                  AVer-o-Mar, Amorim e Terroso   \n",
       "address.location.is_location_exact                                              False   \n",
       "address.location.type                                                           Point   \n",
       "address.market                                                              Barcelona   \n",
       "address.street                                               ADALAR, Istanbul, Turkey   \n",
       "address.suburb                                                    Abbotsford/Wareemba   \n",
       "amenities                                                            24-hour check-in   \n",
       "availability.availability_30                                                        0   \n",
       "availability.availability_365                                                       0   \n",
       "availability.availability_60                                                        0   \n",
       "availability.availability_90                                                        0   \n",
       "bathrooms                                                                         0.0   \n",
       "bed_type                                                                       Airbed   \n",
       "bedrooms                                                                            0   \n",
       "beds                                                                                0   \n",
       "calendar_last_scraped                                             2019-02-11 05:00:00   \n",
       "cancellation_policy                                                          flexible   \n",
       "cleaning_fee                                                                      0.0   \n",
       "description                                 Cozy room! It has a double bed, cable ...   \n",
       "extra_people                                                                      0.0   \n",
       "first_review                                                      2009-10-27 04:00:00   \n",
       "guests_included                                                                     1   \n",
       "host_about                                                                         \\n   \n",
       "host_has_profile_pic                                                            False   \n",
       "host_id                                                                      10002884   \n",
       "host_identity_verified                                                          False   \n",
       "host_is_superhost                                                               False   \n",
       "host_listings_count                                                                 0   \n",
       "host_location                                              New South Wales, Australia   \n",
       "host_name                                                    (Email hidden by Airbnb)   \n",
       "host_neighbourhood                                                         Abbotsford   \n",
       "host_picture_url                    https://a0.muscache.com/defaults/user_pic-225x...   \n",
       "host_response_rate                                                                  0   \n",
       "host_response_time                                                 a few days or more   \n",
       "host_thumbnail_url                  https://a0.muscache.com/defaults/user_pic-50x5...   \n",
       "host_total_listings_count                                                           0   \n",
       "host_url                                   https://www.airbnb.com/users/show/10002884   \n",
       "host_verifications                                                              email   \n",
       "house_rules                         \"Mi casa es su casa\".  When you leave please t...   \n",
       "images.medium_url                                                                   -   \n",
       "images.picture_url                  https://a0.muscache.com/4ea/air/v2//pictures/0...   \n",
       "images.thumbnail_url                                                                -   \n",
       "images.xl_picture_url                                                               -   \n",
       "interaction                         'Ohana Nui means Big Family, which is what we ...   \n",
       "last_review                                                       2012-01-06 05:00:00   \n",
       "last_scraped                                                      2019-02-11 05:00:00   \n",
       "listing_url                                     https://www.airbnb.com/rooms/10006546   \n",
       "maximum_nights                                                                      1   \n",
       "minimum_nights                                                                      1   \n",
       "monthly_price                                                                   250.0   \n",
       "name                                  !5 mins from MTR! Ideal for biz travel / family   \n",
       "neighborhood_overview               \"Be happy in Porto\"  offers a quality accommod...   \n",
       "notes                                                    !!!Sejam muito bem vindos!!!   \n",
       "number_of_reviews                                                                   0   \n",
       "price                                                                             9.0   \n",
       "property_type                                                              Aparthotel   \n",
       "review_scores_checkin                                                               2   \n",
       "review_scores_cleanliness                                                           2   \n",
       "review_scores_communication                                                         2   \n",
       "review_scores_location                                                              2   \n",
       "review_scores_rating                                                               20   \n",
       "review_scores_value                                                                 2   \n",
       "reviews._id                                                                  10000121   \n",
       "reviews.comments                                                                        \n",
       "reviews.date                                                      2009-10-27 04:00:00   \n",
       "reviews.listing_id                                                           10006546   \n",
       "reviews.reviewer_id                                                          10000032   \n",
       "reviews.reviewer_name                                                            'Dea   \n",
       "reviews_per_month                                                                   1   \n",
       "room_type                                                             Entire home/apt   \n",
       "security_deposit                                                                  0.0   \n",
       "space                                       Cozy room! It has a double bed, cable ...   \n",
       "summary                                    Simply Hostel is, a brand new Licensed ...   \n",
       "transactions.bucket_end_date                                      2002-03-05 00:00:00   \n",
       "transactions.bucket_start_date                                    1962-01-08 00:00:00   \n",
       "transactions.transaction_count                                                      1   \n",
       "transactions.transactions.date                                    1962-03-08 00:00:00   \n",
       "transactions.transactions.price                                                  0.02   \n",
       "transit                              it is less than 5 minutes walk from Taksim an...   \n",
       "weekly_price                                                                     60.0   \n",
       "\n",
       "                                                                                  Max  \n",
       "field                                                                                  \n",
       "_id                                                                           9993190  \n",
       "access                              ÔΩºÔΩ™ÔΩ±ÔΩ∑ÔΩØÔæÅÔæù„ÇÇ„ÅÇ„Çä„Åæ„Åô! Share kitchen is located on 2nd ...  \n",
       "accommodates                                                                       16  \n",
       "address.country                                                         United States  \n",
       "address.country_code                                                               US  \n",
       "address.government_area                                                        √Årvore  \n",
       "address.location.is_location_exact                                               True  \n",
       "address.location.type                                                           Point  \n",
       "address.market                                                         The Big Island  \n",
       "address.street                                                      È¶ôÊ∏Ø, È¶ôÊ∏Ø, Hong Kong  \n",
       "address.suburb                                                                  ≈ûi≈üli  \n",
       "amenities                                  translation missing: en.hosting_amenity_50  \n",
       "availability.availability_30                                                       30  \n",
       "availability.availability_365                                                     365  \n",
       "availability.availability_60                                                       60  \n",
       "availability.availability_90                                                       90  \n",
       "bathrooms                                                                        16.0  \n",
       "bed_type                                                                     Real Bed  \n",
       "bedrooms                                                                           20  \n",
       "beds                                                                               25  \n",
       "calendar_last_scraped                                             2019-03-11 04:00:00  \n",
       "cancellation_policy                                                   super_strict_60  \n",
       "cleaning_fee                                                                   2000.0  \n",
       "description                         Î£∏Ïóê Ï∞ΩÎ¨∏Ïù¥ ÏûàÏñ¥Í¥òÏ†ÅÌï©ÎãàÎã§. tv,Î¨¥ÏÑ†Ïù∏ÌÑ∞ÎÑ∑  Í∏∞Î≥∏ ÌïÑÏàòÌíà Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§ ÏàôÏÜåÎ∞î...  \n",
       "extra_people                                                                   2346.0  \n",
       "first_review                                                      2019-03-10 05:00:00  \n",
       "guests_included                                                                    16  \n",
       "host_about                                                                          ÔΩ°  \n",
       "host_has_profile_pic                                                             True  \n",
       "host_id                                                                      99997584  \n",
       "host_identity_verified                                                           True  \n",
       "host_is_superhost                                                                True  \n",
       "host_listings_count                                                              1198  \n",
       "host_location                                                                Î∂ÄÏÇ∞, ÎåÄÌïúÎØºÍµ≠  \n",
       "host_name                                                                           È¶®  \n",
       "host_neighbourhood                                                              ≈ûi≈üli  \n",
       "host_picture_url                    https://a0.muscache.com/im/users/9997988/profi...  \n",
       "host_response_rate                                                                100  \n",
       "host_response_time                                                     within an hour  \n",
       "host_thumbnail_url                  https://a0.muscache.com/im/users/9997988/profi...  \n",
       "host_total_listings_count                                                        1198  \n",
       "host_url                                   https://www.airbnb.com/users/show/99997584  \n",
       "host_verifications                                                       zhima_selfie  \n",
       "house_rules                         ÔΩ•No Smoking, ÔΩ•No Pet, ÔΩ•No Party, ÔΩ•No Children ...  \n",
       "images.medium_url                                                                   -  \n",
       "images.picture_url                  https://a0.muscache.com/im/pictures/fff8056a-c...  \n",
       "images.thumbnail_url                                                                -  \n",
       "images.xl_picture_url                                                               -  \n",
       "interaction                                                                 Í∞úÏä§Ìä∏Ïóê Îî∞Îùº..  \n",
       "last_review                                                       2019-03-11 04:00:00  \n",
       "last_scraped                                                      2019-03-11 04:00:00  \n",
       "listing_url                                      https://www.airbnb.com/rooms/9993190  \n",
       "maximum_nights                                                             2147483647  \n",
       "minimum_nights                                                                   1250  \n",
       "monthly_price                                                                253384.0  \n",
       "name                                                                       ÔΩ°Townhouse  \n",
       "neighborhood_overview               ÔΩ±ÔΩØÔæÑÔæéÔΩ∞Ôæë„Å™Èõ∞Âõ≤Ê∞ó„ÅßÔΩ§Êó•Êú¨‰∫∫„ÅÆ„ÅîÂÆ∂Êóè„ÅåÂ§ö„Åè‰Ωè„Çì„Åß„ÅÑ„ÇãÔΩ¥ÔæòÔΩ±„Åß„ÅôÔΩ°ÊúÄËøë„ÅØ„Åã„Çè„ÅÑ„ÅÑÔΩ∂ÔæåÔΩ™„ÇÇÂ¢ó„Åà...  \n",
       "notes                               Ôø´  Feel free to smoke in our outdoor area, but...  \n",
       "number_of_reviews                                                                 533  \n",
       "price                                                                         48842.0  \n",
       "property_type                                                                   Villa  \n",
       "review_scores_checkin                                                              10  \n",
       "review_scores_cleanliness                                                          10  \n",
       "review_scores_communication                                                        10  \n",
       "review_scores_location                                                             10  \n",
       "review_scores_rating                                                              100  \n",
       "review_scores_value                                                                10  \n",
       "reviews._id                                                                  99999615  \n",
       "reviews.comments                    ÔæúÔΩ≤ÔΩ∑ÔΩ∑ÔæãÔæûÔΩ∞ÔæÅÔΩ§DFS‰ªñÔΩºÔΩÆÔΩØÔæãÔæüÔæùÔΩ∏ÔæûÔæìÔΩ∞Ôæô„Å´Ëøë„ÅèÈùûÂ∏∏„Å´‰æøÂà©„ÅßÊúâ„Çä„Å™„Åå„ÇâÈùô„ÅãÔΩ°ABCÔæèÔΩ∞...  \n",
       "reviews.date                                                      2019-03-11 04:00:00  \n",
       "reviews.listing_id                                                            9993190  \n",
       "reviews.reviewer_id                                                          99998112  \n",
       "reviews.reviewer_name                                                           ÔæïÔΩ≥ÔæÄÔæõÔΩ≥  \n",
       "reviews_per_month                                                                  10  \n",
       "room_type                                                                 Shared room  \n",
       "security_deposit                                                              39228.0  \n",
       "space                               Ôø´ Second floor studio (you must climb 2 flight...  \n",
       "summary                             Î£∏Ïóê Ï∞ΩÎ¨∏Ïù¥ ÏûàÏñ¥Í¥òÏ†ÅÌï©ÎãàÎã§. tv,Î¨¥ÏÑ†Ïù∏ÌÑ∞ÎÑ∑  Í∏∞Î≥∏ ÌïÑÏàòÌíà Ï§ÄÎπÑÎêòÏñ¥ ÏûàÏäµÎãàÎã§ ÏàôÏÜåÎ∞î...  \n",
       "transactions.bucket_end_date                                      2017-01-09 00:00:00  \n",
       "transactions.bucket_start_date                                    2015-11-28 00:00:00  \n",
       "transactions.transaction_count                                                    100  \n",
       "transactions.transactions.date                                    2017-01-09 00:00:00  \n",
       "transactions.transactions.price                                                 845.8  \n",
       "transit                             ÎåÄÏ§ë ÍµêÌÜµÏù¥ ÏôÄÏù¥ÏºàÎ†ê ÏÉ§Ìïë ÏåòÌÉÄ ÏóêÏÑú ÎèÑÎ≥¥Î°ú 5 -7 Î∂Ñ ÏßëÍπåÏßÄ, Í¥ÄÍ¥ë Î≤ÑÏä§Í∞Ä ÏàòÏãú...  \n",
       "weekly_price                                                                  59123.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a statistical summary for all fields in the collection\n",
    "# Source: Google. (2025). Gemini 2.5 Pro - Gemini Pro. Google DeepMind. https://deepmind.google/technologies/gemini/pro/\n",
    "#         X. (2025). Grok 3 Beta ‚Äî The Age of Reasoning Agents (Mar 07 version)[Large Language Model]. X.ai. https://x.ai/blog/grok-3\n",
    "\n",
    "# --- Configuration ---\n",
    "# Fields within arrays to analyze individually\n",
    "review_subfields = [\"comments\", \"date\", \"listing_id\", \"reviewer_id\", \"reviewer_name\", \"_id\"]\n",
    "transaction_subfields = [\"date\", \"price\"]\n",
    "amenity_subfield = \"amenities\"                      # The array itself contains the strings\n",
    "verification_subfield = \"host_verifications\"        # The array itself contains the strings\n",
    "\n",
    "# Fields to exclude from the main document analysis (handled separately or irrelevant)\n",
    "exclude_from_main = [\"reviews\", \"transactions\", \"amenities\", \"host_verifications\"]\n",
    "\n",
    "print(\"--- Starting Statistical Summary Generation ---\")\n",
    "\n",
    "# --- 1. Analyze Non-Array Fields ---\n",
    "print(\"Analyzing non-array fields...\")\n",
    "\n",
    "# Get unique top-level and simple nested fields first\n",
    "all_main_fields = set()\n",
    "pipeline_get_main_fields = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "    {\"$unwind\": \"$fields\"},\n",
    "    {\"$match\": {\"fields.k\": {\"$nin\": exclude_from_main}}}, # Exclude array roots\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}\n",
    "]\n",
    "cursor_main_fields = db.listingsAndReviews_HW2.aggregate(pipeline_get_main_fields)\n",
    "for doc in cursor_main_fields:\n",
    "    all_main_fields.add(doc['_id'])\n",
    "\n",
    "# Add known nested fields (adjust as needed based on actual schema)\n",
    "all_main_fields.update([\n",
    "    'address.country', 'address.country_code', 'address.government_area',\n",
    "    'address.location.is_location_exact', 'address.location.type',\n",
    "    'address.market', 'address.street', 'address.suburb',\n",
    "    'availability.availability_30', 'availability.availability_365',\n",
    "    'availability.availability_60', 'availability.availability_90',\n",
    "    'images.picture_url', 'images.thumbnail_url', 'images.medium_url', 'images.xl_picture_url',\n",
    "    'transactions.bucket_end_date', 'transactions.bucket_start_date', 'transactions.transaction_count' # Keep transaction summaries\n",
    "])\n",
    "# Remove parent keys if sub-keys exist to avoid double counting structure vs values\n",
    "fields_to_remove = {'address', 'availability', 'images', 'address.location', 'transactions'}\n",
    "unique_main_fields = sorted(list(all_main_fields - fields_to_remove))\n",
    "\n",
    "summary_main = {}\n",
    "total_docs = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "for field in tqdm(unique_main_fields, desc=\"Processing main fields\"):\n",
    "    # Determine field type from a sample document\n",
    "    sample_doc = db.listingsAndReviews_HW2.find_one({field: {\"$exists\": True}}, {field: 1})\n",
    "    field_type = None\n",
    "    field_value_sample = None\n",
    "    if sample_doc and field:\n",
    "        keys = field.split('.')\n",
    "        val = sample_doc\n",
    "        try:\n",
    "            for key in keys:\n",
    "                val = val[key]\n",
    "            field_value_sample = val\n",
    "            if isinstance(field_value_sample, (int, float, Decimal128)):\n",
    "                field_type = 'numeric'\n",
    "            elif isinstance(field_value_sample, datetime):\n",
    "                field_type = 'date'\n",
    "            elif isinstance(field_value_sample, bool):\n",
    "                field_type = 'boolean'\n",
    "            else:\n",
    "                field_type = 'categorical'\n",
    "        except (KeyError, TypeError):\n",
    "            field_type = 'mixed_or_missing'\n",
    "\n",
    "    group_stage = {\n",
    "        \"_id\": None,\n",
    "        \"Count\": {\"$sum\": 1},\n",
    "        \"DistinctCount\": {\"$addToSet\": f\"${field}\"}\n",
    "    }\n",
    "    if field_type == 'numeric':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "        group_stage[\"AvgValue\"] = {\"$avg\": {\"$convert\": {\"input\": f\"${field}\", \"to\": \"double\", \"onError\": None, \"onNull\": None}}}\n",
    "    elif field_type == 'date':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "    elif field_type == 'boolean':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "    elif field_type == 'categorical':\n",
    "        group_stage[\"MinValue\"] = {\"$min\": f\"${field}\"}\n",
    "        group_stage[\"MaxValue\"] = {\"$max\": f\"${field}\"}\n",
    "\n",
    "    pipeline = [\n",
    "        {\"$match\": {field: {\"$exists\": True, \"$ne\": None}}}, # Ensure field exists and is not null\n",
    "        {\"$group\": group_stage},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0,\n",
    "            \"Count\": 1,\n",
    "            \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Mean\": \"$AvgValue\",\n",
    "            \"Min\": \"$MinValue\",\n",
    "            \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        for key in [\"Min\", \"Max\", \"Mean\"]:\n",
    "             if key in stats:\n",
    "                 if isinstance(stats[key], Decimal128):\n",
    "                     stats[key] = float(stats[key].to_decimal())\n",
    "                 if isinstance(stats[key], float):\n",
    "                     stats[key] = round(stats[key], 2)\n",
    "        summary_main[field] = stats\n",
    "    else:\n",
    "        summary_main[field] = {\"Count\": 0, \"DistinctCount\": 0}\n",
    "\n",
    "# --- 2. Analyze 'reviews' Subfields ---\n",
    "print(\"Analyzing 'reviews' subfields...\")\n",
    "summary_reviews = {}\n",
    "pipeline_reviews_base = [\n",
    "    {\"$match\": {\"reviews\": {\"$exists\": True}}},  # Filter for docs with reviews array\n",
    "    {\"$unwind\": \"$reviews\"}                      # Unwind the reviews array\n",
    "]\n",
    "\n",
    "# Count total review elements first\n",
    "pipeline_reviews_count = pipeline_reviews_base + [{\"$count\": \"TotalReviews\"}]\n",
    "total_reviews_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_reviews_count))\n",
    "total_reviews = total_reviews_result[0]['TotalReviews'] if total_reviews_result else 0\n",
    "print(f\"Total review elements to analyze: {total_reviews}\")\n",
    "\n",
    "if total_reviews > 0:\n",
    "    for subfield in tqdm(review_subfields, desc=\"Processing review fields\"):\n",
    "        field_path = f\"reviews.{subfield}\" # Path within the unwound document\n",
    "\n",
    "        # Determine type from sample (using the original collection)\n",
    "        sample_review_doc = db.listingsAndReviews_HW2.find_one({\"reviews\": {\"$exists\": True, \"$ne\": []}}, {\"reviews\": {\"$slice\": 1}})\n",
    "        field_type = None\n",
    "        if sample_review_doc and sample_review_doc.get('reviews'):\n",
    "             review_item = sample_review_doc['reviews'][0]\n",
    "             if subfield in review_item:\n",
    "                 field_value_sample = review_item[subfield]\n",
    "                 if isinstance(field_value_sample, (int, float, Decimal128)): field_type = 'numeric'\n",
    "                 elif isinstance(field_value_sample, datetime): field_type = 'date'\n",
    "                 elif isinstance(field_value_sample, bool): field_type = 'boolean'\n",
    "                 else: field_type = 'categorical'\n",
    "\n",
    "        group_stage = {\n",
    "             \"_id\": None,\n",
    "             \"Count\": {\"$sum\": 1}, # Count matching unwound documents\n",
    "             \"DistinctCount\": {\"$addToSet\": f\"${field_path}\"}\n",
    "        }\n",
    "        if field_type == 'date':\n",
    "             group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "             group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "        elif field_type == 'categorical': # Get Min/Max strings\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "\n",
    "        pipeline = pipeline_reviews_base + [\n",
    "             {\"$match\": {field_path: {\"$exists\": True, \"$ne\": None}}}, # Only where subfield exists and is not null\n",
    "             {\"$group\": group_stage},\n",
    "             {\"$project\": {\n",
    "                 \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "                 \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "             }}\n",
    "        ]\n",
    "\n",
    "        result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "        if result:\n",
    "            stats = result[0]\n",
    "            stats[\"TotalElements\"] = total_reviews\n",
    "            # Clean up Min/Max if they weren't added\n",
    "            if \"Min\" not in stats: stats[\"Min\"] = None\n",
    "            if \"Max\" not in stats: stats[\"Max\"] = None\n",
    "            summary_reviews[field_path] = stats\n",
    "        else:\n",
    "            summary_reviews[field_path] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_reviews}\n",
    "\n",
    "# --- 3. Analyze 'transactions.transactions' Subfields ---\n",
    "print(\"Analyzing 'transactions.transactions' subfields...\")\n",
    "summary_tx = {}\n",
    "pipeline_tx_base = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$transactions.transactions\"}\n",
    "]\n",
    "\n",
    "# Count total transaction elements\n",
    "pipeline_tx_count = pipeline_tx_base + [{\"$count\": \"TotalTransactions\"}]\n",
    "total_tx_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_tx_count))\n",
    "total_transactions = total_tx_result[0]['TotalTransactions'] if total_tx_result else 0\n",
    "print(f\"Total transaction elements to analyze: {total_transactions}\")\n",
    "\n",
    "if total_transactions > 0:\n",
    "    for subfield in tqdm(transaction_subfields, desc=\"Processing transaction fields\"):\n",
    "        field_path = f\"transactions.transactions.{subfield}\"\n",
    "\n",
    "        # Determine type from sample\n",
    "        sample_tx_doc = db.listingsAndReviews_HW2.find_one({\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}, {\"transactions.transactions\": {\"$slice\": 1}})\n",
    "        field_type = None\n",
    "        if sample_tx_doc and sample_tx_doc.get('transactions', {}).get('transactions'):\n",
    "             tx_item = sample_tx_doc['transactions']['transactions'][0]\n",
    "             if subfield in tx_item:\n",
    "                 field_value_sample = tx_item[subfield]\n",
    "                 if isinstance(field_value_sample, (int, float, Decimal128)): field_type = 'numeric'\n",
    "                 elif isinstance(field_value_sample, datetime): field_type = 'date'\n",
    "                 else: field_type = 'categorical'\n",
    "\n",
    "        group_stage = {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": f\"${field_path}\"}\n",
    "        }\n",
    "        if field_type == 'numeric':\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "            group_stage[\"AvgValue\"] = {\"$avg\": {\"$convert\": {\"input\": f\"${field_path}\", \"to\": \"double\", \"onError\": None, \"onNull\": None}}}\n",
    "        elif field_type == 'date':\n",
    "            group_stage[\"MinValue\"] = {\"$min\": f\"${field_path}\"}\n",
    "            group_stage[\"MaxValue\"] = {\"$max\": f\"${field_path}\"}\n",
    "\n",
    "        pipeline = pipeline_tx_base + [\n",
    "             {\"$match\": {field_path: {\"$exists\": True, \"$ne\": None}}},\n",
    "             {\"$group\": group_stage},\n",
    "             {\"$project\": {\n",
    "                 \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "                 \"Mean\": \"$AvgValue\", \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "             }}\n",
    "        ]\n",
    "\n",
    "        result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "        if result:\n",
    "            stats = result[0]\n",
    "            stats[\"TotalElements\"] = total_transactions\n",
    "            for key in [\"Min\", \"Max\", \"Mean\"]:\n",
    "                 if key in stats:\n",
    "                     if isinstance(stats[key], Decimal128):\n",
    "                         stats[key] = float(stats[key].to_decimal())\n",
    "                     if isinstance(stats[key], float):\n",
    "                         stats[key] = round(stats[key], 2)\n",
    "            # Clean up missing keys\n",
    "            if \"Min\" not in stats: stats[\"Min\"] = None\n",
    "            if \"Max\" not in stats: stats[\"Max\"] = None\n",
    "            if \"Mean\" not in stats: stats[\"Mean\"] = None\n",
    "            summary_tx[field_path] = stats\n",
    "        else:\n",
    "            summary_tx[field_path] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_transactions}\n",
    "\n",
    "# --- 4. Analyze 'amenities' ---\n",
    "print(\"Analyzing 'amenities'...\")\n",
    "summary_amen = {}\n",
    "pipeline_amen_base = [\n",
    "    {\"$match\": {\"amenities\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$amenities\"}\n",
    "]\n",
    "pipeline_amen_count = pipeline_amen_base + [{\"$count\": \"TotalAmenities\"}]\n",
    "total_amen_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_amen_count))\n",
    "total_amenities = total_amen_result[0]['TotalAmenities'] if total_amen_result else 0\n",
    "print(f\"Total amenity elements to analyze: {total_amenities}\")\n",
    "\n",
    "if total_amenities > 0:\n",
    "    pipeline = pipeline_amen_base + [\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": \"$amenities\"},\n",
    "            \"MinValue\": {\"$min\": \"$amenities\"},\n",
    "            \"MaxValue\": {\"$max\": \"$amenities\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        stats[\"TotalElements\"] = total_amenities\n",
    "        summary_amen[\"amenities\"] = stats\n",
    "    else:\n",
    "        summary_amen[\"amenities\"] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_amenities}\n",
    "\n",
    "# --- 5. Analyze 'host_verifications' ---\n",
    "print(\"Analyzing 'host_verifications'...\")\n",
    "summary_verif = {}\n",
    "pipeline_verif_base = [\n",
    "    {\"$match\": {\"host_verifications\": {\"$exists\": True}}},\n",
    "    {\"$unwind\": \"$host_verifications\"}\n",
    "]\n",
    "pipeline_verif_count = pipeline_verif_base + [{\"$count\": \"TotalVerifications\"}]\n",
    "total_verif_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_verif_count))\n",
    "total_verifications = total_verif_result[0]['TotalVerifications'] if total_verif_result else 0\n",
    "print(f\"Total verification elements to analyze: {total_verifications}\")\n",
    "\n",
    "if total_verifications > 0:\n",
    "    pipeline = pipeline_verif_base + [\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"Count\": {\"$sum\": 1},\n",
    "            \"DistinctCount\": {\"$addToSet\": \"$host_verifications\"},\n",
    "            \"MinValue\": {\"$min\": \"$host_verifications\"},\n",
    "            \"MaxValue\": {\"$max\": \"$host_verifications\"}\n",
    "        }},\n",
    "        {\"$project\": {\n",
    "            \"_id\": 0, \"Count\": 1, \"DistinctCount\": {\"$size\": \"$DistinctCount\"},\n",
    "            \"Min\": \"$MinValue\", \"Max\": \"$MaxValue\"\n",
    "        }}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    if result:\n",
    "        stats = result[0]\n",
    "        stats[\"TotalElements\"] = total_verifications\n",
    "        summary_verif[\"host_verifications\"] = stats\n",
    "    else:\n",
    "        summary_verif[\"host_verifications\"] = {\"Count\": 0, \"DistinctCount\": 0, \"TotalElements\": total_verifications}\n",
    "\n",
    "# --- 6. Combine and Create Final DataFrame ---\n",
    "summary_combined = {**summary_main, **summary_reviews, **summary_tx, **summary_amen, **summary_verif}\n",
    "\n",
    "df_data_combined = []\n",
    "for field, stats in summary_combined.items():\n",
    "    df_data_combined.append({\n",
    "        \"field\": field,\n",
    "        \"Count\": stats.get(\"Count\", 0),\n",
    "        \"Distinct Count\": stats.get(\"DistinctCount\", 0),\n",
    "        \"Mean\": stats.get(\"Mean\", '-'),\n",
    "        \"Min\": stats.get(\"Min\", '-'),\n",
    "        \"Max\": stats.get(\"Max\", '-')\n",
    "    })\n",
    "\n",
    "df_stats_final = pd.DataFrame(df_data_combined)\n",
    "df_stats_final.set_index(\"field\", inplace=True)\n",
    "df_stats_final.sort_index(inplace=True)\n",
    "df_stats_final.fillna('-', inplace=True)\n",
    "\n",
    "print(\"\\n--- Final Statistical Summary (Original Collection) ---\")\n",
    "print(\"Total fields:\", len(df_stats_final))\n",
    "df_stats_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Analysing the results**\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "The table above provides a statistical summary of the fields in the collection `listingsAndReviews_HW2` including the count of documents, distinct values, mean, minimum, and maximum values for each field.\n",
    "- From the analysis, we can verify that most fields are consistent with our expectations, with the exception of a few fields: `maximum_nights`, `bathrooms`, `bedrooms`, and `price.`\n",
    "\n",
    "<br>\n",
    "\n",
    "**`maximum_nights`**\n",
    "\n",
    "- As shown in the results above, the maximum value for the field **`maximum_nights` is extremely high** ‚Äî specifically, $2\\;147\\;483\\;647$. While we know with certainty that no guest will ever book a stay for this many nights, this value appears in the dataset.\n",
    "  - After reviewing Airbnb‚Äôs official guidelines (**Source:** https://www.airbnb.pt/help/article/880?), it is confirmed that hosts have full freedom to define any number for the `maximum_nights` field. Therefore, such high values are permitted by Airbnb.\n",
    "  - It is likely that some hosts intentionally set extremely high values to signal that there is effectively no maximum stay limit. These values, although unusually large, are still valid in the context of Airbnb‚Äôs platform.\n",
    "  - While these values are valid, in a different context ‚Äî such as modeling guest behavior or predicting average stay length ‚Äî they could be treated as statistical outliers. However, since that is not the goal of our current work, we will not perform any data cleaning or transformation for these records.\n",
    "\n",
    "**`bathrooms`**\n",
    "\n",
    "- As shown in the results above, the minimum value for the field **`bathrooms`** is $0$. In some cases this value makes total sense (**Source:** https://community.withairbnb.com/t5/Advice-on-your-space/bathroom-classification/m-p/1652130) while in others it doesn't. \n",
    "   - Properties with types like ***Camper/RV***, ***Tent*** and ***Shared Room*** may not have private bathrooms indicating that the value $0$ makes sense. On the other hand property types like ***Apartment*** and House are unlikely to have $0$ bathrooms.\n",
    "\n",
    "**`bedrooms`**\n",
    "\n",
    "- As shown in the results above, the minimum value for the field **`bedrooms`** is $0$. \n",
    "  - For properties with types like ***Apartment*** that are **Studios** or **Lofts** this value makes sense potentially reflecting that they share a single open space. \n",
    "  - On the other hand property types like ***House*** are unlikely to have **$0$ bedrooms**.\n",
    "\n",
    "**`price`**\n",
    "\n",
    "- As shown in the results above, the maximum value for the field **`price`** is $48\\;842.0$. The field price indicates the price per night for a listing.\n",
    "  - This value is extremely high and seems unrealistic for a single night stay. \n",
    "  - It is possible that this value is a result of data entry errors or outliers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`maximum_nights`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document with _id: 10911771 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/52473150\n",
      "Document with _id: 19550563 has maximum_nights: 1234567890           | Host URL: https://www.airbnb.com/users/show/137344895\n",
      "Document with _id: 6357527 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/18762837\n",
      "Document with _id: 744242 has maximum_nights: 2147483647           | Host URL: https://www.airbnb.com/users/show/4334558\n"
     ]
    }
   ],
   "source": [
    "# Check cases with 'maximum_nights' more that 1 000 000\n",
    "large_maximum_nights = db.listingsAndReviews_HW2.find({\"maximum_nights\": {\"$gt\": 1_000_000}})\n",
    "for doc in large_maximum_nights:\n",
    "    print(f\"Document with _id: {doc['_id']} has maximum_nights: {doc['maximum_nights']:<20} | Host URL: {doc['host_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`bathrooms`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of listings where number of bathrooms is 0\n",
    "db.listingsAndReviews_HW2.count_documents({\"bathrooms\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a total of $14$ listings with $0$ `bathrooms`. We will investigate the property types of these listings to see if they are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/6250742'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/27201583'}\n",
      "{'property_type': 'Hostel', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/30098437'}\n",
      "{'property_type': 'Camper/RV', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/36714324'}\n",
      "{'property_type': 'Serviced apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/14861546'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/51198195'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/219415974'}\n",
      "{'property_type': 'Bed and breakfast', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/98135964'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/221016656'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/226980154'}\n",
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/283136'}\n",
      "{'property_type': 'House', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/34682013'}\n",
      "{'property_type': 'Apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/494228'}\n",
      "{'property_type': 'Serviced apartment', 'bathrooms': Decimal128('0.0'), 'host_url': 'https://www.airbnb.com/users/show/38468501'}\n"
     ]
    }
   ],
   "source": [
    "# Check cases with 'bathrooms' = 0\n",
    "cursor = db.listingsAndReviews_HW2.find({\"bathrooms\": 0}, projection={\"_id\": 0, \"bathrooms\": 1, \"property_type\": 1, \"host_url\":1})\n",
    "for doc in cursor:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see from the results above, there are some listings with $0$ `bathrooms` with property types that do not make sense (e.g ***House***, ***Apartment***, etc.).\n",
    "  - To further investigate, we would need more information about each listings, access to the database's metadata and to the host_url (links to the listings don't seem to work).\n",
    "  - Hence no changes will be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`bedrooms`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count listings with 0 bedrooms\n",
    "db.listingsAndReviews_HW2.count_documents({\"bedrooms\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see there a total of $496$ listings with $0$ `bedrooms`.\n",
    "    - As they represent almost $10\\%$ of total listings we will analyse the distribution of property types with $0$ `bedrooms` to understand which are correctly described with $0$ `bedrooms` and which aren't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apartment: 305\n",
      "Condominium: 52\n",
      "Loft: 33\n",
      "Serviced apartment: 25\n",
      "House: 19\n",
      "Guest suite: 14\n",
      "Guesthouse: 9\n",
      "Bed and breakfast: 6\n",
      "Boutique hotel: 5\n",
      "Other: 4\n",
      "Townhouse: 3\n",
      "Cottage: 3\n",
      "Hostel: 3\n",
      "Cabin: 3\n",
      "Camper/RV: 2\n",
      "Tiny house: 2\n",
      "Bungalow: 2\n",
      "Pension (South Korea): 1\n",
      "Aparthotel: 1\n",
      "Resort: 1\n",
      "Farm stay: 1\n",
      "Hotel: 1\n",
      "Casa particular (Cuba): 1\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of property types with 0 bedrooms\n",
    "pipeline = [\n",
    "    {\"$match\": {\"bedrooms\": 0}},\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$property_type\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$sort\": {\"count\": -1}}  \n",
    "]\n",
    "\n",
    "results = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "for doc in results:\n",
    "    print(f\"{doc['_id']}: {doc['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see from the results above, there are some listings with $0$ `bedrooms` with property types that do not make sense (e.g ***House*** etc.).\n",
    "  - As explained in the case of bathrooms, to further investigate these cases, we would need more information about each listings, access to the database's metadata and to the **`host_url`** (links to the listings don't seem to work).\n",
    "  - Hence no changes will be made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`price`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'property_type': 'Apartment', 'price': Decimal128('48842.00'), 'host_url': 'https://www.airbnb.com/users/show/118695718'}\n"
     ]
    }
   ],
   "source": [
    "# Find properties that have a price equal to 48842.0 and project _id, property_type, price and host_url\n",
    "cursor = db.listingsAndReviews_HW2.find({\"price\": 48842.0}, projection={\"_id\": 0, \"property_type\": 1, \"price\": 1, \"host_url\":1})\n",
    "for doc in cursor:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Range: 0-100, Count: 2181, Average Price: 59.24\n",
      "Price Range: 101-500, Count: 2627, Average Price: 213.11\n",
      "Price Range: 501-1000, Count: 528, Average Price: 686.03\n",
      "Price Range: 1001-5000, Count: 207, Average Price: 1724.65\n",
      "Price Range: 5001-10000, Count: 6, Average Price: 6149.83\n",
      "Price Range: 10001-20000, Count: 5, Average Price: 10910.80\n",
      "Price Range: 20001-50000, Count: 1, Average Price: 48842.00\n"
     ]
    }
   ],
   "source": [
    "# Distribution of prices across multiple price ranges (bins)\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/bucket/\n",
    "\n",
    "bins = [0, 100, 500, 1000, 5000, 10000, 20000, 50000]\n",
    "labels = [\"0-100\", \"101-500\", \"501-1000\", \"1001-5000\", \"5001-10000\", \"10001-20000\", \"20001-50000\"]\n",
    "pipeline = [\n",
    "    {\"$bucket\": {\n",
    "        \"groupBy\": \"$price\",\n",
    "        \"boundaries\": bins,\n",
    "        \"default\": \"50001+\",  # Default bucket for values above the last boundary\n",
    "        \"output\": {\n",
    "            \"count\": {\"$sum\": 1},\n",
    "            \"average_price\": {\"$avg\": \"$price\"}\n",
    "        }\n",
    "    }}\n",
    "]\n",
    "results = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "for doc in results:\n",
    "    if doc['_id'] == \"50001+\":  # Handle the default bucket\n",
    "        price_range = \"50001+\"\n",
    "    else:\n",
    "        # Map the bucket index to the corresponding label\n",
    "        index = bins.index(doc['_id'])\n",
    "        price_range = labels[index]\n",
    "    \n",
    "    avg_price = float(str(doc['average_price']))  # Convert Decimal128 to string, then to float\n",
    "    print(f\"Price Range: {price_range}, Count: {doc['count']}, Average Price: {avg_price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the results above, we can see that we only have $6$ listings with `price` over $10\\;000$ *per night*\n",
    "  - These most likely correspond to outliers or luxury listings.\n",
    "  - Since we lack the metadata, working `host_url` links to these properties to determine if they are valid, **we will not remove them**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`number_of_reviews`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of documents with mismatch: \u001b[0m 244 (4.39%)\n",
      "[{'_id': '17915459', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '17951038', 'number_of_reviews': 100, 'reviews_length': 0},\n",
      " {'_id': '18040680', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '18121163', 'number_of_reviews': 47, 'reviews_length': 0},\n",
      " {'_id': '18219254', 'number_of_reviews': 99, 'reviews_length': 0},\n",
      " {'_id': '18220498', 'number_of_reviews': 22, 'reviews_length': 0},\n",
      " {'_id': '18353952', 'number_of_reviews': 59, 'reviews_length': 0},\n",
      " {'_id': '18439011', 'number_of_reviews': 35, 'reviews_length': 0},\n",
      " {'_id': '18611535', 'number_of_reviews': 32, 'reviews_length': 0},\n",
      " {'_id': '18712467', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '18730346', 'number_of_reviews': 42, 'reviews_length': 0},\n",
      " {'_id': '18748105', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '18809312', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '19028601', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '19036802', 'number_of_reviews': 87, 'reviews_length': 0},\n",
      " {'_id': '19044796', 'number_of_reviews': 92, 'reviews_length': 0},\n",
      " {'_id': '19061599', 'number_of_reviews': 202, 'reviews_length': 0},\n",
      " {'_id': '19100444', 'number_of_reviews': 32, 'reviews_length': 0},\n",
      " {'_id': '19172215', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '19217460', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '19304849', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '19380085', 'number_of_reviews': 76, 'reviews_length': 0},\n",
      " {'_id': '19486889', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '19499999', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '19536693', 'number_of_reviews': 40, 'reviews_length': 0},\n",
      " {'_id': '19550665', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '19677006', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '19692712', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '19694143', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '19704903', 'number_of_reviews': 61, 'reviews_length': 0},\n",
      " {'_id': '19741944', 'number_of_reviews': 17, 'reviews_length': 0},\n",
      " {'_id': '19760228', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '19779316', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '19780732', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '19781115', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '19803430', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '19820634', 'number_of_reviews': 14, 'reviews_length': 0},\n",
      " {'_id': '19821682', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '19828489', 'number_of_reviews': 49, 'reviews_length': 0},\n",
      " {'_id': '19865003', 'number_of_reviews': 25, 'reviews_length': 0},\n",
      " {'_id': '19866204', 'number_of_reviews': 15, 'reviews_length': 0},\n",
      " {'_id': '19928786', 'number_of_reviews': 42, 'reviews_length': 0},\n",
      " {'_id': '20049287', 'number_of_reviews': 14, 'reviews_length': 0},\n",
      " {'_id': '20071436', 'number_of_reviews': 20, 'reviews_length': 0},\n",
      " {'_id': '20260320', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '20276192', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '20312675', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '20353402', 'number_of_reviews': 53, 'reviews_length': 0},\n",
      " {'_id': '20511510', 'number_of_reviews': 21, 'reviews_length': 0},\n",
      " {'_id': '20567444', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '20611485', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '20669488', 'number_of_reviews': 42, 'reviews_length': 0},\n",
      " {'_id': '20724431', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '20735001', 'number_of_reviews': 30, 'reviews_length': 0},\n",
      " {'_id': '20807522', 'number_of_reviews': 10, 'reviews_length': 0},\n",
      " {'_id': '20809200', 'number_of_reviews': 76, 'reviews_length': 0},\n",
      " {'_id': '20829122', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '21006757', 'number_of_reviews': 30, 'reviews_length': 0},\n",
      " {'_id': '21055635', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '21056118', 'number_of_reviews': 42, 'reviews_length': 0},\n",
      " {'_id': '21103245', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '21180955', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '21322869', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '21389251', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '21522442', 'number_of_reviews': 11, 'reviews_length': 0},\n",
      " {'_id': '21563508', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '21844137', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '21976308', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '21992735', 'number_of_reviews': 10, 'reviews_length': 0},\n",
      " {'_id': '22005538', 'number_of_reviews': 22, 'reviews_length': 0},\n",
      " {'_id': '22042206', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '22094381', 'number_of_reviews': 37, 'reviews_length': 0},\n",
      " {'_id': '22155071', 'number_of_reviews': 19, 'reviews_length': 0},\n",
      " {'_id': '22182637', 'number_of_reviews': 35, 'reviews_length': 0},\n",
      " {'_id': '22199234', 'number_of_reviews': 30, 'reviews_length': 0},\n",
      " {'_id': '22204642', 'number_of_reviews': 34, 'reviews_length': 0},\n",
      " {'_id': '22370001', 'number_of_reviews': 53, 'reviews_length': 0},\n",
      " {'_id': '22382752', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '22891830', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '22919250', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '22978545', 'number_of_reviews': 28, 'reviews_length': 0},\n",
      " {'_id': '23003772', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '23115849', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '23121270', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '23122981', 'number_of_reviews': 27, 'reviews_length': 0},\n",
      " {'_id': '23160633', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '23178393', 'number_of_reviews': 70, 'reviews_length': 0},\n",
      " {'_id': '23180898', 'number_of_reviews': 64, 'reviews_length': 0},\n",
      " {'_id': '23187368', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '23211669', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '23211754', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '23217617', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '23282173', 'number_of_reviews': 40, 'reviews_length': 0},\n",
      " {'_id': '23284399', 'number_of_reviews': 23, 'reviews_length': 0},\n",
      " {'_id': '23300467', 'number_of_reviews': 21, 'reviews_length': 0},\n",
      " {'_id': '23303574', 'number_of_reviews': 10, 'reviews_length': 0},\n",
      " {'_id': '23321866', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '23479384', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '23553008', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '23611001', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '23759457', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '23797007', 'number_of_reviews': 15, 'reviews_length': 0},\n",
      " {'_id': '23803557', 'number_of_reviews': 50, 'reviews_length': 0},\n",
      " {'_id': '23809500', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '23887963', 'number_of_reviews': 29, 'reviews_length': 0},\n",
      " {'_id': '23896389', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '23953865', 'number_of_reviews': 34, 'reviews_length': 0},\n",
      " {'_id': '23989053', 'number_of_reviews': 24, 'reviews_length': 0},\n",
      " {'_id': '24004679', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '24026688', 'number_of_reviews': 49, 'reviews_length': 0},\n",
      " {'_id': '24032849', 'number_of_reviews': 23, 'reviews_length': 0},\n",
      " {'_id': '24049135', 'number_of_reviews': 16, 'reviews_length': 0},\n",
      " {'_id': '24052553', 'number_of_reviews': 40, 'reviews_length': 0},\n",
      " {'_id': '24267275', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '24322799', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '24324367', 'number_of_reviews': 22, 'reviews_length': 0},\n",
      " {'_id': '24340252', 'number_of_reviews': 10, 'reviews_length': 0},\n",
      " {'_id': '24348022', 'number_of_reviews': 24, 'reviews_length': 0},\n",
      " {'_id': '24426527', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '24448278', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '24461559', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '24486669', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '24528857', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '24693627', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '24740074', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '24748967', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '24800927', 'number_of_reviews': 11, 'reviews_length': 0},\n",
      " {'_id': '24819150', 'number_of_reviews': 23, 'reviews_length': 0},\n",
      " {'_id': '24903500', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '25070327', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '25117844', 'number_of_reviews': 11, 'reviews_length': 0},\n",
      " {'_id': '25185445', 'number_of_reviews': 41, 'reviews_length': 0},\n",
      " {'_id': '25217878', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '25233509', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '25418032', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '25448375', 'number_of_reviews': 15, 'reviews_length': 0},\n",
      " {'_id': '25453308', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '25564284', 'number_of_reviews': 19, 'reviews_length': 0},\n",
      " {'_id': '25831839', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '25832582', 'number_of_reviews': 19, 'reviews_length': 0},\n",
      " {'_id': '25996203', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '26113123', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '26120284', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '26120851', 'number_of_reviews': 15, 'reviews_length': 0},\n",
      " {'_id': '26263467', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '26313671', 'number_of_reviews': 15, 'reviews_length': 0},\n",
      " {'_id': '26319639', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '26348233', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '26380958', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '26444105', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '26488006', 'number_of_reviews': 22, 'reviews_length': 0},\n",
      " {'_id': '26488387', 'number_of_reviews': 25, 'reviews_length': 0},\n",
      " {'_id': '26521403', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '26549962', 'number_of_reviews': 9, 'reviews_length': 0},\n",
      " {'_id': '26892349', 'number_of_reviews': 18, 'reviews_length': 0},\n",
      " {'_id': '26916776', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '26942581', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '27011219', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '27020282', 'number_of_reviews': 25, 'reviews_length': 0},\n",
      " {'_id': '27044783', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '27045941', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '27083634', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '27183245', 'number_of_reviews': 20, 'reviews_length': 0},\n",
      " {'_id': '27193598', 'number_of_reviews': 34, 'reviews_length': 0},\n",
      " {'_id': '27270555', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '27298515', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '27347264', 'number_of_reviews': 29, 'reviews_length': 0},\n",
      " {'_id': '27378937', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '27400392', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '27588189', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '27594466', 'number_of_reviews': 9, 'reviews_length': 0},\n",
      " {'_id': '27667701', 'number_of_reviews': 23, 'reviews_length': 0},\n",
      " {'_id': '27784079', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '27899421', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '27978908', 'number_of_reviews': 31, 'reviews_length': 0},\n",
      " {'_id': '27983911', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '28004169', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '28121603', 'number_of_reviews': 11, 'reviews_length': 0},\n",
      " {'_id': '28283159', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '28335993', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '28378574', 'number_of_reviews': 10, 'reviews_length': 0},\n",
      " {'_id': '28429941', 'number_of_reviews': 14, 'reviews_length': 0},\n",
      " {'_id': '28598597', 'number_of_reviews': 21, 'reviews_length': 0},\n",
      " {'_id': '28632184', 'number_of_reviews': 11, 'reviews_length': 0},\n",
      " {'_id': '28680187', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '28750603', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '28795425', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '28825704', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '28858840', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '28904599', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '28926167', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '28956363', 'number_of_reviews': 18, 'reviews_length': 0},\n",
      " {'_id': '28957367', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '29115387', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '29115877', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '29121570', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '29147263', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '29150428', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '29407312', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '29535104', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '29552477', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '29674795', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '29676608', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '29682985', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '29799437', 'number_of_reviews': 7, 'reviews_length': 0},\n",
      " {'_id': '29840058', 'number_of_reviews': 5, 'reviews_length': 0},\n",
      " {'_id': '29870769', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '29872103', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '29879141', 'number_of_reviews': 12, 'reviews_length': 0},\n",
      " {'_id': '29957113', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '30055339', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '30364518', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30365974', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '30366799', 'number_of_reviews': 14, 'reviews_length': 0},\n",
      " {'_id': '30501335', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30522015', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30573409', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30759793', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30763079', 'number_of_reviews': 13, 'reviews_length': 0},\n",
      " {'_id': '30832921', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '30842723', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '31101349', 'number_of_reviews': 3, 'reviews_length': 0},\n",
      " {'_id': '31217862', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '31352359', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '31408169', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '31460245', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '31510270', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '31582808', 'number_of_reviews': 8, 'reviews_length': 0},\n",
      " {'_id': '31666595', 'number_of_reviews': 4, 'reviews_length': 0},\n",
      " {'_id': '31827679', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '31845112', 'number_of_reviews': 6, 'reviews_length': 0},\n",
      " {'_id': '31867873', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '31941328', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '31951516', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32102597', 'number_of_reviews': 9, 'reviews_length': 0},\n",
      " {'_id': '32104830', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32160778', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32178403', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '32287835', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '32362812', 'number_of_reviews': 2, 'reviews_length': 0},\n",
      " {'_id': '32401490', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32459348', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32481559', 'number_of_reviews': 1, 'reviews_length': 0},\n",
      " {'_id': '32537967', 'number_of_reviews': 1, 'reviews_length': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Check if 'number_of_reviews' is equal to the length of 'reviews' array\n",
    "pipeline = [\n",
    "    {\"$project\": {\n",
    "        \"_id\": 1,                                                       # Exclude _id from output\n",
    "        \"number_of_reviews\": 1,                                         # Include number_of_reviews field\n",
    "        \"reviews_length\": {\"$size\": \"$reviews\"}                         # Calculate length of reviews array\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"$expr\": {\"$ne\": [\"$number_of_reviews\", \"$reviews_length\"]}     # Check if number_of_reviews is not equal to length of reviews array\n",
    "    }}\n",
    "]\n",
    "results = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "print(f\"\\033[1mNumber of documents with mismatch: \\033[0m {len(results)} ({len(results)/db.listingsAndReviews_HW2.count_documents({}) * 100:.2f}%)\")\n",
    "pprint(results)\n",
    "# for doc in results:\n",
    "#     print(f\"Number of reviews: {doc['number_of_reviews']}, Reviews array length: {doc['reviews_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_reviews': 100, 'reviews': [], 'reviews_length': 0}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check specific document with _id = 17951038\n",
    "db.listingsAndReviews_HW2.find_one({\"_id\": \"17951038\"}, projection={\"_id\": 0, \"reviews\": 1, \"number_of_reviews\": 1, \"reviews_length\": {\"$size\": \"$reviews\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We noticed that $244$ ($4.39\\%$) listings have a **`number_of_reviews`** that doesn‚Äôt match the actual number of reviews in the reviews array. **For now, we‚Äôre not doing anything** about it because this field is probably just a leftover helper or display field from the past. Since it‚Äôs not causing any issues and fixing it would take extra time and processing, we‚Äôre choosing to leave it as is. If it ever becomes important later, we can clean it up in the background without affecting the system.\n",
    " \n",
    "- Additionally, due to the lack of metadata, we don't know if this mismatch is due to a problem during the web scraping process or due to an out of sync issue.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** The same analysis could be done for **`transactions.transaction_count`** but due to the same reason we will not do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`review_scores_rating`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': '10006546', 'review_scores_rating': 89},\n",
       " {'_id': '1001265', 'review_scores_rating': 84},\n",
       " {'_id': '10021707', 'review_scores_rating': 100},\n",
       " {'_id': '1003530', 'review_scores_rating': 94},\n",
       " {'_id': '10038496', 'review_scores_rating': 98},\n",
       " {'_id': '10047964', 'review_scores_rating': 100},\n",
       " {'_id': '10051164', 'review_scores_rating': 80},\n",
       " {'_id': '10057826', 'review_scores_rating': 88},\n",
       " {'_id': '10059872', 'review_scores_rating': 100},\n",
       " {'_id': '10083468', 'review_scores_rating': 97}]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all cases with 'review_scores_rating' more that 10\n",
    "list(db.listingsAndReviews_HW2.find({'review_scores_rating': {\"$gt\": 10}},      # Query to find documents with 'review_scores_rating' > 10\n",
    "                                    {'_id': 1, 'review_scores_rating': 1})      # Projection to include only '_id' and 'review_scores_rating'\n",
    "     )[:10]  # Display first 10 documents with 'review_scores_rating' > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of documents with 'review_scores_rating' greater than 10:\u001b[0m 4081\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1mNumber of documents with 'review_scores_rating' greater than 10:\\033[0m {len(list(db.listingsAndReviews_HW2.find({'review_scores_rating': {'$gt': 10}})))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize 'review_scores_rating' to be between 0 and 10\n",
    "# We consider that the range of all values is between 0 and 100, so we divide by 10 to normalize the values\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/divide/\n",
    "    [{\"$set\": {\"review_scores_rating\": {\"$divide\": [\"$review_scores_rating\", 10]}}}]\n",
    ")\n",
    "\n",
    "# Check all cases with 'review_scores_rating' more that 10\n",
    "list(db.listingsAndReviews_HW2.find({'review_scores_rating': {\"$gt\": 10}}, {'_id': 1, 'review_scores_rating': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'review_scores_rating': [{'BSONType': 'double'}, {'BSONType': 'null'}]\n"
     ]
    }
   ],
   "source": [
    "# Check if 'review_scores_rating' is decimal after the change\n",
    "review_scores_rating_type = db.listingsAndReviews_HW2.aggregate([\n",
    "    # Only consider documents where the field exists\n",
    "    {\"$match\": {\"review_scores_rating\": {\"$exists\": True}}},\n",
    "    \n",
    "    # Group by the BSON type of the field\n",
    "    {\"$group\": {\"_id\": {\"$type\": \"$review_scores_rating\"}}},\n",
    "    \n",
    "    # Project the type name \n",
    "    {\"$project\": {\"_id\": 0, \"BSONType\": \"$_id\"}}\n",
    "])\n",
    "print(f\"Data type of 'review_scores_rating': {list(review_scores_rating_type)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Analysis:** The `review_scores_rating` field shows values up to 100, while other `review_scores_*` fields (checkin, cleanliness, etc.) are consistently between 0-10. This suggests `review_scores_rating` uses a different scale (0-100).\n",
    "\n",
    "- **Decision & Transformation:**\n",
    "    - We applied **data normalization** to the `review_scores_rating` field by dividing its value by $10$, because its range ($0-100$) was inconsistent with other review scores ($0-10$). Unlike the other scores, this one will be kept in decimal format after normalization, in order to preserve more detailed information. We expect **consistent scaling across all review score metrics**, enabling meaningful calculation of averages (as required in **Q9**).\n",
    "\n",
    "The verification query confirms that no `review_scores_rating` values are now greater than 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`amenities`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate amenities found in document with _id: 1001265\n",
      "['Air conditioning',\n",
      " 'BBQ grill',\n",
      " 'Bed linens',\n",
      " 'Cable TV',\n",
      " 'Coffee maker',\n",
      " 'Cooking basics',\n",
      " 'Disabled parking spot',\n",
      " 'Dishes and silverware',\n",
      " 'Dryer',\n",
      " 'Elevator',\n",
      " 'Essentials',\n",
      " 'Ethernet connection',\n",
      " 'Extra pillows and blankets',\n",
      " 'Free parking on premises',\n",
      " 'Garden or backyard',\n",
      " 'Hair dryer',\n",
      " 'Hangers',\n",
      " 'Hot tub',\n",
      " 'Hot water',\n",
      " 'Iron',\n",
      " 'Kitchen',\n",
      " 'Laptop friendly workspace',\n",
      " 'Lockbox',\n",
      " 'Microwave',\n",
      " 'Pool',\n",
      " 'Refrigerator',\n",
      " 'Self check-in',\n",
      " 'Shampoo',\n",
      " 'Step-free access',\n",
      " 'Step-free access',\n",
      " 'Stove',\n",
      " 'TV',\n",
      " 'Washer',\n",
      " 'Well-lit path to entrance',\n",
      " 'Wide clearance to bed',\n",
      " 'Wifi']\n"
     ]
    }
   ],
   "source": [
    "# Check if 'amenities' only appears in the array once\n",
    "cursor = db.listingsAndReviews_HW2.find({\"amenities\": {\"$exists\": True}})\n",
    "for doc in cursor:\n",
    "    if len(doc['amenities']) != len(set(doc['amenities'])):\n",
    "        print(f\"Duplicate amenities found in document with _id: {doc['_id']}\")\n",
    "        break\n",
    "\n",
    "# Check 'amenities' for duplicates\n",
    "pprint(sorted(list(db.listingsAndReviews_HW2.find({\"_id\": \"1001265\"}, {\"amenities\": 1}))[0]['amenities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Air conditioning',\n",
      " 'BBQ grill',\n",
      " 'Bed linens',\n",
      " 'Cable TV',\n",
      " 'Coffee maker',\n",
      " 'Cooking basics',\n",
      " 'Disabled parking spot',\n",
      " 'Dishes and silverware',\n",
      " 'Dryer',\n",
      " 'Elevator',\n",
      " 'Essentials',\n",
      " 'Ethernet connection',\n",
      " 'Extra pillows and blankets',\n",
      " 'Free parking on premises',\n",
      " 'Garden or backyard',\n",
      " 'Hair dryer',\n",
      " 'Hangers',\n",
      " 'Hot tub',\n",
      " 'Hot water',\n",
      " 'Iron',\n",
      " 'Kitchen',\n",
      " 'Laptop friendly workspace',\n",
      " 'Lockbox',\n",
      " 'Microwave',\n",
      " 'Pool',\n",
      " 'Refrigerator',\n",
      " 'Self check-in',\n",
      " 'Shampoo',\n",
      " 'Step-free access',\n",
      " 'Stove',\n",
      " 'TV',\n",
      " 'Washer',\n",
      " 'Well-lit path to entrance',\n",
      " 'Wide clearance to bed',\n",
      " 'Wifi']\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates from 'amenities' array\n",
    "db.listingsAndReviews_HW2.update_many(\n",
    "    {},\n",
    "    [{\"$set\": {\n",
    "        \"amenities\": {\"$setUnion\": [\"$amenities\", []]}  # Remove duplicates\n",
    "    }}]\n",
    ")\n",
    "\n",
    "# Check 'amenities' for duplicates again\n",
    "pprint(sorted(list(db.listingsAndReviews_HW2.find({\"_id\": \"1001265\"}, {\"amenities\": 1}))[0]['amenities']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`host_verifications`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate \u001b[1mhost_verifications\u001b[0m found\n"
     ]
    }
   ],
   "source": [
    "# Check if 'host_verifications' only appears in the array once\n",
    "cursor = db.listingsAndReviews_HW2.find({\"host_verifications\": {\"$exists\": True}})\n",
    "len_host_verifications_duplicates = 0\n",
    "for doc in cursor:\n",
    "    if len(doc['host_verifications']) != len(set(doc['host_verifications'])):\n",
    "        print(f\"Duplicate host_verifications found in document with _id: {doc['_id']}\")\n",
    "        len_host_verifications_duplicates += 1\n",
    "if len_host_verifications_duplicates > 0:\n",
    "    print(f\"\\033[1mTotal documents with duplicate host_verifications: {len_host_verifications_duplicates}\\033[0m\")\n",
    "else:\n",
    "    print(\"No duplicate \\033[1mhost_verifications\\033[0m found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`transactions`**\n",
    "\n",
    "- We want to check the number of transactions registered before **Airbnb** was founded in **11 August 2008** (Source: https://www.airbnb.pt/about/about-us & https://www.businessofapps.com/data/airbnb-statistics/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of transactions before Airbnb's foundation date:\u001b[0m 5467 (98.42%)\u001b[1m of all documents\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Date of foundation of Airbnb - 11 August 2008\n",
    "airbnb_foundation_date = datetime(2008, 8, 11)\n",
    "\n",
    "# Check if 'transactions.transactions.date' is before the foundation date\n",
    "query = {\n",
    "    \"transactions.transactions\": {\n",
    "        \"$elemMatch\": {\n",
    "            \"date\": {\"$lt\": airbnb_foundation_date}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Count documents with transactions before the foundation date\n",
    "count_before_foundation = db.listingsAndReviews_HW2.count_documents(query)\n",
    "print(f\"\\033[1mNumber of transactions before Airbnb's foundation date:\\033[0m {count_before_foundation} ({count_before_foundation / total_docs:.2%})\\033[1m of all documents\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of transactions before Airbnb's foundation date:\u001b[0m 110837 (35.63%)\n"
     ]
    }
   ],
   "source": [
    "# Pipeline to count the total number of transactions in the collection\n",
    "pipeline_total = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}},\n",
    "    {\"$unwind\": \"$transactions.transactions\"},\n",
    "    {\"$group\": {\"_id\": None, \"totalTransactions\": {\"$sum\": 1}}}\n",
    "]\n",
    "total_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_total))\n",
    "total_transactions = total_result[0][\"totalTransactions\"] if total_result else 0\n",
    "\n",
    "# Pipeline to count transactions with a date before the foundation date\n",
    "pipeline_before = [\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True, \"$ne\": []}}},\n",
    "    {\"$unwind\": \"$transactions.transactions\"},\n",
    "    {\"$match\": {\"transactions.transactions.date\": {\"$lt\": airbnb_foundation_date}}},\n",
    "    {\"$group\": {\"_id\": None, \"countBefore\": {\"$sum\": 1}}}\n",
    "]\n",
    "before_result = list(db.listingsAndReviews_HW2.aggregate(pipeline_before))\n",
    "count_before = before_result[0][\"countBefore\"] if before_result else 0\n",
    "\n",
    "# Calculate the percentage of transactions that occurred before the foundation date\n",
    "percentage = (count_before / total_transactions * 100) if total_transactions > 0 else 0\n",
    "\n",
    "print(f\"\\033[1mNumber of transactions before Airbnb's foundation date:\\033[0m {count_before} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Approximately $35.63\\%$ of the transactions were performed before Airbnb‚Äôs foundation date. This significant proportion indicates that these records represent a considerable amount of historical data, and removing them could result in the loss of valuable information. Additionally, the lack of metadata or context for these transactions makes it difficult to determine their relevance or accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of transactions within the specified date range:\u001b[0m 0 \u001b[1mtransactions\u001b[0m (0.00% of all documents)\n"
     ]
    }
   ],
   "source": [
    "# Verify that each transaction occurs within the 'bucket_start_date' and 'bucket_end_date'\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"listing_id\": 1,\n",
    "            \"BucketStart\": \"$transactions.bucket_start_date\",\n",
    "            \"BucketEnd\": \"$transactions.bucket_end_date\",\n",
    "            \"OutOfRangeTransactions\": {\n",
    "                \"$filter\": {\n",
    "                    \"input\": \"$transactions.transactions\",\n",
    "                    \"as\": \"t\",\n",
    "                    \"cond\": {\n",
    "                        \"$or\": [\n",
    "                            { \"$lt\": [\"$$t.date\", \"$transactions.bucket_start_date\"] },\n",
    "                            { \"$gt\": [\"$$t.date\", \"$transactions.bucket_end_date\"] }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Only return documents with at least one out-of-range transaction\n",
    "    {\"$match\": { \"OutOfRangeTransactions.0\": { \"$exists\": True } }}\n",
    "]\n",
    "\n",
    "# Execute the pipeline\n",
    "out_of_range_docs = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "print(f\"\\033[1mNumber of transactions within the specified date range:\\033[0m {len(out_of_range_docs)} \\033[1mtransactions\\033[0m ({len(out_of_range_docs) / total_docs:.2%} of all documents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the original data model, where transactions (`transactions.transactions`) are **embedded** within the main listing document (`listingsAndReviews_HW2`), **all transactions within that document inherently belong to that listing**. There isn't a `listing_id` field within each individual transaction to verify if it belongs to another listing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Invalid Dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents found with last_scraped < last_review.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'last_scraped' < 'last_review' (Invalid data)\n",
    "invalid_dates = db.listingsAndReviews_HW2.find({\n",
    "    \"$expr\": {\n",
    "        \"$lt\": [\"$last_scraped\", \"$last_review\"]\n",
    "    }\n",
    "})\n",
    "if len(list(invalid_dates)) >  0:\n",
    "    for doc in invalid_dates:\n",
    "        print(f\"Document with _id: {doc['_id']} has last_scraped: {doc['last_scraped']} < last_review: {doc['last_review']}\")\n",
    "else:\n",
    "    print(\"No documents found with last_scraped < last_review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No documents found with first_review > last_review.\n"
     ]
    }
   ],
   "source": [
    "# Check if 'first_review' > 'last_review' (Invalid data)\n",
    "invalid_dates = db.listingsAndReviews_HW2.find({\n",
    "    \"$expr\": {\n",
    "        \"$gt\": [\"$first_review\", \"$last_review\"]\n",
    "    }\n",
    "})\n",
    "if len(list(invalid_dates)) > 0:\n",
    "    for doc in invalid_dates:\n",
    "        print(f\"Document with _id: {doc['_id']} has first_review: {doc['first_review']} > last_review: {doc['last_review']}\")\n",
    "else:\n",
    "    print(\"No documents found with first_review > last_review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents with first_review < transactions.transactions.date: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if 'first_review' < 'transactions.transactions.date' (Invalid data)\n",
    "invalid_dates = db.listingsAndReviews_HW2.find({\n",
    "    \"$expr\": {        \n",
    "        # Check if first_review is less than the date of the first transaction\n",
    "        \"$lt\": [\"$first_review\", {\"$arrayElemAt\": [\"$transactions.transactions.date\", 0]}]\n",
    "    }\n",
    "})\n",
    "if int(len(list(invalid_dates))) > 0:\n",
    "    for doc in invalid_dates:\n",
    "        print(f\"Document with _id: {doc['_id']} has first_review: {doc['first_review']} < transactions.transactions.date: {doc['transactions']['transactions'][0]['date']}\")\n",
    "    \n",
    "print(f\"Number of documents with first_review < transactions.transactions.date: {len(list(invalid_dates))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üìö 1.5 | Data Model Adjustments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three stage approach for data model and final schema design**\n",
    "\n",
    "1. Workload stage\n",
    "2. Relationship assessment\n",
    "3. Patterns\n",
    "\n",
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- Data Model Design Process  -->\n",
    "    <img src=\"./img/DataModels&Schema.png\" height=\"400\" alt=\"Data Model Design Process\" />\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "Based on the **Workload**, **Relationships**, and **Patterns** analysis, we will now implement the new schema design by creating separate collections for `Hosts`, `Reviews`, and `Transactions`, and restructuring the `Listings` collection.\n",
    "\n",
    "**Overall Strategy:** Move large, unbounded, or independently accessed data (**reviews**, **host details**, **transactions**) out of the main listing document into their own collections, using references (`Host_ID`, `Listing_ID`, `Reviewer_ID`) to link them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Workload Stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTotal documents in the collection 'listingsAndReviews_HW2':\u001b[0m 5555\n",
      "\u001b[1mTotal size of the collection 'listingsAndReviews_HW2':\u001b[0m      108183825 bytes (0.101 GB)\n"
     ]
    }
   ],
   "source": [
    "# Determine total number of documents and total size\n",
    "total_documents = db.listingsAndReviews_HW2.count_documents({})\n",
    "\n",
    "stats = db.listingsAndReviews_HW2.database.command(\"collstats\", db.listingsAndReviews_HW2.name)\n",
    "total_size = stats[\"size\"]  # Total document data size in bytes\n",
    "total_size_gb = total_size / (1024 ** 3)\n",
    "\n",
    "print(f\"\\033[1mTotal documents in the collection 'listingsAndReviews_HW2':\\033[0m {total_documents}\")\n",
    "print(f\"\\033[1mTotal size of the collection 'listingsAndReviews_HW2':\\033[0m      {total_size} bytes ({total_size_gb:.3f} GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **üß† Workload Stage Summary**\n",
    "\n",
    "<center>\n",
    "\n",
    "| #    | Step / Question                                       | What it Entails                                                   | Entities Involved                    \n",
    "| :--- | :---------------------------------------------------- | :---------------------------------------------------------------- | :------------------------------------ |\n",
    "| **1** | Assess Data Size                                  | Determine current collection volume and size                       | `listingsAndReviews_HW2`             \n",
    "| **2a**| Most Common Use Case                             | Show property info to customers (core details + sample reviews)    | `Listings`, `Reviews`               \n",
    "| **2b (Q7)** | Unique amenities list for host registration         | Show all unique amenities; rarely changes                         | `Listings`, `Amenities`      \n",
    "| **2c (Q8)** | Top 20 reviewers and fast review count lookup      | Rank reviewers and return count per reviewer                      | `Reviews`, `Reviewers`           \n",
    "| **2d (Q9)** | Average of review scores (dynamic metrics)        | Compute average across all review metrics                         | `Listings`, `Review_Scores` (Subdoc)  |\n",
    "| **2e (Q10)**| Avg transaction value per property for time period | Time-based aggregation on transactions                            | `Transactions`, `Listings`      \n",
    "| **2f (Q11)**| Summary page of top 10 cities + top listings       | Show city-level stats and example listings                        | `Listings`, `Reviews`, `CitySummary` \n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** All the operations that we will do are mostly *reads*, but in real-world cenarios, ***AirBnB*** would have to do a lot of *writes* as well. So, we will try to optimize the database for both reads and writes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Relationships Assessment Stage**\n",
    "\n",
    "1. Identify which entities are related\n",
    "2. Measure quantity of related data (**1:1**, **1:N**, **N:N**)\n",
    "3. Decide whether to embed data or reference  it\n",
    "    - Embed for fast reads & tightly coupled data\n",
    "    - Reference for flexibility & loosely coupled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **üîó Relationships Phase Table (with Correct Embed/Reference Direction)**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **From Entity**         | **To Entity**     | **Relationship Type**                  | **Cardinality** | **Embed or Reference?**                         | **Reasoning** |\n",
    "| :----------------------: | :----------------: | :------------------------------------- | :----------: | :------------------------------------------ | :-------------------------------------------------------------- |\n",
    "| `Listings`               | `Hosts`            | Listing has one Host                   | N:1         | **Reference `Hosts` in `Listings`**         | Avoid duplication; host info reused/updated                  |\n",
    "| `Listings`               | `Reviews`          | Listing has many Reviews               | 1:N         | **Reference `Listings`  in `Reviews`**    | Reviews grow; keeps listing doc lean                          |\n",
    "| `Reviews`                | `Reviewers`        | Review written by one Reviewer         | N:1         | **Reference `Reviewers` in `Reviews`**      | Reviewers write multiple reviews; enables reviewer tracking |\n",
    "| `Listings`               | `Transactions`     | Listing has many Transactions          | 1:N         | **Reference `Listings` in `Transactions`**  | Time-series data; accessed separately                         |\n",
    "| `Listings`               | `Amenities` (array)| Listing has many amenities             | 1:N         | **Embed `Amenities` in `Listings`**        | Small, static data; needed for listing reads                  | \n",
    "| `City` (Optional)        | `Listings`         | City has many listings                 | 1:N         | **Both sides**  | City identified via `Listing.Address.market`; enables grouping/aggregation\n",
    "| `Listings`               | `ReviewScores`   | Listing has one set of review scores | 1:1         | **Embed `Review Scores` in `Listings`**    | Small, core data;                  |\n",
    "\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Patterns Phase**\n",
    "\n",
    "1. Recognize common access or structure patterns in data\n",
    "2. Apply modeling patterns (e.g., bucket, subset, outlier) to optimize for performance, scalability, and simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **‚úÖ Patterns Phase Table**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Use Case / Entity** | **Entity Requirements** | **Applied Pattern (Allowed)** | **Why This Pattern?** | **Context in Project** |\n",
    "|------------------------|-------------------------------|-------------------------------|------------------------|-------------------------|\n",
    "| **Host registration: show common `Amenities`** | Read-heavy, rarely changing list of distinct values       | **Computed Pattern**      | Precompute into `Amenities` collection; avoids scans             | **Q7**        |\n",
    "| **Track top reviewers + `ReviewCount`**       | Aggregate reviews per reviewer; fast lookup needed      | **Computed Pattern**      | Maintain count in `Reviewers` collection; fast access          | **Q8**        |\n",
    "| **Dynamic review metrics per listing**       | New score fields added without fixed schema             | **Attribute Pattern**     | Store scores as key-value pairs; flexible querying            | **Q9**        |\n",
    "| **Calculate average `ReviewsScores`**            | Average multiple, potentially dynamic, score fields |  **Computed  Pattern** |\tStore scores as key-value; allows fast reading | **Q9** |\n",
    "| **Summary of top cities/listings**           | Repeated aggregated reads across many documents         | **Computed Pattern**      | Store precomputed summaries in `CitySummary`; fast reads      | **Q11**            |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Final Schema Design**\n",
    "\n",
    "##### **List of All Collections Required**\n",
    "\n",
    "<center>\n",
    "\n",
    "| **Collection Name**        | **Purpose** |\n",
    "| :---------------------- | :--------------------------------------------------------- |\n",
    "| `Listings`              | Core listing info (`title`, `price`, `amenities`, `scores`, etc.)  |\n",
    "| `Reviews`               | Full detailed reviews (referenced from **`Listings`**)           |\n",
    "| `Reviewers`             | Reviewer profiles with computed review count (referenced from **`Reviews`**) |\n",
    "| `Transactions`          | Kept on the **`Listings`** collection the metadata information and included in the **`Transactions`** collection the history of the transactions |\n",
    "| `Hosts`                 | Host information (referenced from **`Listings`**)                |\n",
    "| `CitySummary` (Optional)| Precomputed metrics for top 10 cities                      |\n",
    "| `Amenities` (Optional)  | List of unique amenities with frequency                    |\n",
    "\n",
    "</center>\n",
    "\n",
    "##### **Overview**\n",
    "\n",
    "<p style=\"text-align: center !important;\">\n",
    "    <!-- Final Schema Design  -->\n",
    "    <img src=\"./img/FinalSchemaDesign.png\" with=\"400\" alt=\"Final Schema Design\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop new collections if they exist to start fresh\n",
    "db.drop_collection(\"Listings\")\n",
    "db.drop_collection(\"Reviews\")\n",
    "db.drop_collection(\"Reviewers\")\n",
    "db.drop_collection(\"Transactions\")\n",
    "db.drop_collection(\"Hosts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Reviews` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '1022200',\n",
      " 'reviews': [{'_id': '277195899',\n",
      "              'date': datetime.datetime(2018, 6, 15, 4, 0),\n",
      "              'listing_id': '1022200',\n",
      "              'reviewer_id': '710109',\n",
      "              'reviewer_name': 'Sylvia',\n",
      "              'comments': 'Great location and lovely facility overall.  A '\n",
      "                          'great deal!'}]}\n"
     ]
    }
   ],
   "source": [
    "# Print one example document of 'reviews' array\n",
    "pprint(db.listingsAndReviews_HW2.find_one({\"_id\": \"1022200\"}, {\"reviews\": 1}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2603702c4a0>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create Reviews collection\n",
    "reviews_fields = [\"_id\", \"reviews\"]\n",
    "\n",
    "# Aggregate to extract reviews and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$unwind\": \"$reviews\"},                                                        # Unwind the 'reviews' array to create a document for each review\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                   # Will create a ObjectId for each review\n",
    "        \"Listing_ID\": \"$_id\",                                                       # Include the listing ID\n",
    "        \"Review_ID\": \"$reviews._id\",                                                # Include the review ID\n",
    "        \"Review_Comments\": \"$reviews.comments\",                                     # Include the review comments\n",
    "        \"Review_Date\": \"$reviews.date\",                                             # Include the review date\n",
    "        \"Reviewer_ID\": \"$reviews.reviewer_id\",                                      # Include the reviewer ID\n",
    "    }},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Reviews\"}                                                             # Output directly to 'Reviews' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Reviews' collection:\u001b[0m 149792\n",
      "\u001b[1mSample document from 'Reviews' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fea80ca6298d01ad052272'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Review_ID': '58663741',\n",
      " 'Review_Comments': 'A casa da Ana e do Gon√ßalo foram o local escolhido para a '\n",
      "                    'passagem de ano com um grupo de amigos. Fomos super bem '\n",
      "                    'recebidos com uma grande simpatia e predisposi√ß√£o a '\n",
      "                    'ajudar com qualquer coisa que fosse necess√°rio.\\r\\n'\n",
      "                    'A casa era ainda melhor do que parecia nas fotos, '\n",
      "                    'totalmente equipada, com mantas, aquecedor e tudo o que '\n",
      "                    'pudessemos precisar.\\r\\n'\n",
      "                    'A localiza√ß√£o n√£o podia ser melhor! N√£o h√° melhor do que '\n",
      "                    'acordar de manh√£ e ao virar da esquina estar a ribeira do '\n",
      "                    'Porto.',\n",
      " 'Review_Date': datetime.datetime(2016, 1, 3, 5, 0),\n",
      " 'Reviewer_ID': '51483096'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Reviews collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Reviews' collection:\\033[0m {db.Reviews.count_documents({})  }\")   # Count the number of documents in the Reviews collection\n",
    "print(f\"\\033[1mSample document from 'Reviews' collection:\\033[0m\")\n",
    "pprint(db.Reviews.find_one(), sort_dicts=False)                                                             # Print one example document from the Reviews collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied the **Referencing** by creating a separate `Reviews` collection. This addresses the issue of the potentially large and unbounded `reviews` array embedded within the original listing documents, which negatively impacted performance. We expect **smaller, faster-loading listing documents**, **improved scalability** as reviews can grow independently, and **efficient querying of reviews** using the indexed `Listing_ID` and `Review_ID` fields. Each document in this collection represents a single review and links back to its corresponding listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Review.Listing_ID and Review.Review_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Reviews.create_index([(\"Listing_ID\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Review_ID_1'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Reviews.create_index([(\"Review_ID\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Reviewers` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop_collection(\"Reviewers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2603702f260>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create Reviewers collection\n",
    "reviewers_fields = [\"_id\", \"reviews.reviewer_id\", \"reviews.reviewer_name\"]\n",
    "\n",
    "# Aggregate to extract unique reviewers and their corresponding review IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$unwind\": \"$reviews\"},                                        # Unwind the 'reviews' array to create a document for each review\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$reviews.reviewer_id\",                              # Group by reviewer ID\n",
    "        \"Reviewer_Name\": {\"$first\": \"$reviews.reviewer_name\"},      # Take the first name (assumes consistency)\n",
    "    }},\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                   # Will create a ObjectId for each reviewer\n",
    "        \"Reviewer_ID\": \"$_id\",                                      # Include reviewer ID\n",
    "        \"Reviewer_Name\": 1,                                         # Include reviewer name\n",
    "        # \"Reviews_Count\"                                           # Computed Pattern that will be create in Q8\n",
    "    }},\n",
    "    # Output directly to 'Reviewers' collection\n",
    "    {\"$out\": \"Reviewers\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Reviewers' collection:\u001b[0m 146640\n",
      "\u001b[1mSample document from 'Reviewers' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fea80ea6298d01ad076b92'),\n",
      " 'Reviewer_Name': 'Frank',\n",
      " 'Reviewer_ID': '99803988'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Reviewers collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Reviewers' collection:\\033[0m {db.Reviewers.count_documents({})}\")        # Count the number of documents in the Reviewers collection\n",
    "print(f\"\\033[1mSample document from 'Reviewers' collection:\\033[0m\")\n",
    "pprint(db.Reviewers.find_one(), sort_dicts=False)                                                                  # Print one example document from the Reviewers collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Normalization/Referencing** by creating a separate `Reviewers` collection. This addresses the need to efficiently track reviewers and their activity (**Q8**) without duplicating reviewer names across potentially numerous reviews in the main `Reviews` collection. Each document in `Reviewers` represents a unique reviewer, identified by `Reviewer_ID`. We expect **improved data consistency** (reviewer names stored once) and **efficient lookups for reviewer-specific information**, especially when combined with the `Reviewer_ID` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reviewer_ID_1'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Reviewers.Reviewer_ID and Reviews.Reviewer_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Reviewers.create_index([(\"Reviewer_ID\")])                                        # Create index on Reviewer_ID field in Reviewers collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reviewer_ID_1'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Reviews.create_index([(\"Reviewer_ID\")])                                          # Create index on Reviewer_ID field in Reviews collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Hosts` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found \u001b[1m17 host_* fields\u001b[0m: \n",
      "\n",
      "['_id',\n",
      " 'host_about',\n",
      " 'host_has_profile_pic',\n",
      " 'host_id',\n",
      " 'host_identity_verified',\n",
      " 'host_is_superhost',\n",
      " 'host_listings_count',\n",
      " 'host_location',\n",
      " 'host_name',\n",
      " 'host_neighbourhood',\n",
      " 'host_picture_url',\n",
      " 'host_response_rate',\n",
      " 'host_response_time',\n",
      " 'host_thumbnail_url',\n",
      " 'host_total_listings_count',\n",
      " 'host_url',\n",
      " 'host_verifications']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create Hosts collection\n",
    "# Extract all fields with \"host_\" prefix\n",
    "host_fields = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},             # Convert document to key-value pairs\n",
    "    {\"$unwind\": \"$fields\"},                                             # Flatten the fields array\n",
    "    {\"$match\": {\"fields.k\": {\"$regex\": \"^host_\"}}},                     # Match fields starting with 'host_'\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}},                                   # Group by field names to get distinct fields\n",
    "])\n",
    "\n",
    "# Convert the aggregation result to a list with only field names\n",
    "host_fields = sorted([doc[\"_id\"] for doc in host_fields])\n",
    "\n",
    "# Add \"_id\" field to host_fields in first position\n",
    "host_fields.insert(0, \"_id\")  # Add \"_id\" field to the beginning of the list\n",
    "\n",
    "# Print the list of host fields\n",
    "print(f\"Found \\033[1m{len(host_fields)} host_* fields\\033[0m: \\n\")\n",
    "pprint(host_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2603cc92090>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Aggregate to extract hosts and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    \n",
    "    # Group documents by host ID to create a document for each host\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$host_id\",                                                         # Group by host ID\n",
    "        \"host_fields\": {\"$first\": \"$$ROOT\"},                                       # Keep the entire document\n",
    "    }},\n",
    "    \n",
    "    # Project the desired fields into the new Hosts collection    \n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                              # Will create a ObjectId for each host\n",
    "        \"Host_ID\": \"$host_fields.host_id\",                                                     # Include the host ID\n",
    "        \"Host_Name\": \"$host_fields.host_name\",                                                 # Include the host name\n",
    "        \"Host_About\": \"$host_fields.host_about\",                                               # Include the host about\n",
    "        \"Host_Location\": \"$host_fields.host_location\",                                         # Include the host location\n",
    "        \"Host_Neighbourhood\": \"$host_fields.host_neighbourhood\",                               # Include the host neighbourhood\n",
    "        \"Host_Picture_URL\": \"$host_fields.host_picture_url\",                                   # Include the host picture URL\n",
    "        \"Host_Thumbnail_URL\": \"$host_fields.host_thumbnail_url\",                               # Include the host thumbnail URL\n",
    "        \"Host_Response_Rate\": \"$host_fields.host_response_rate\",                               # Include the host response rate\n",
    "        \"Host_Response_Time\": \"$host_fields.host_response_time\",                               # Include the host response time\n",
    "        \"Host_Verifications\": \"$host_fields.host_verifications\",                               # Include the host verifications\n",
    "        \"Host_Has_Profile_Pic\": \"$host_fields.host_has_profile_pic\",                           # Include the host has profile pic\n",
    "        \"Host_Identity_Verified\": \"$host_fields.host_identity_verified\",                       # Include the host identity verified\n",
    "        \"Host_Is_Superhost\": \"$host_fields.host_is_superhost\",                                 # Include the host is superhost\n",
    "        \"Host_Listings_Count\": \"$host_fields.host_listings_count\",                             # Include the host listings count\n",
    "        \"Host_Total_Listings_Count\": \"$host_fields.host_total_listings_count\",                 # Include the host total listings count\n",
    "        \"Host_URL\": \"$host_fields.host_url\",                                                   # Include the host URL\n",
    "    }},   \n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Hosts\"}                                                             # Output directly to 'Hosts' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Hosts' collection:\u001b[0m 5104\n",
      "\u001b[1mSample document from 'Hosts' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fea811a6298d01ad09a862'),\n",
      " 'Host_ID': '10002884',\n",
      " 'Host_Name': 'Han',\n",
      " 'Host_About': 'Welcome to my room!',\n",
      " 'Host_Location': 'HK',\n",
      " 'Host_Neighbourhood': 'Mong Kok',\n",
      " 'Host_Picture_URL': 'https://a0.muscache.com/im/users/10002884/profile_pic/1387359746/original.jpg?aki_policy=profile_x_medium',\n",
      " 'Host_Thumbnail_URL': 'https://a0.muscache.com/im/users/10002884/profile_pic/1387359746/original.jpg?aki_policy=profile_small',\n",
      " 'Host_Response_Rate': 100,\n",
      " 'Host_Response_Time': 'within an hour',\n",
      " 'Host_Verifications': ['email', 'phone', 'reviews', 'jumio', 'government_id'],\n",
      " 'Host_Has_Profile_Pic': True,\n",
      " 'Host_Identity_Verified': True,\n",
      " 'Host_Is_Superhost': False,\n",
      " 'Host_Listings_Count': 1,\n",
      " 'Host_Total_Listings_Count': 1,\n",
      " 'Host_URL': 'https://www.airbnb.com/users/show/10002884'}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check the new Hosts collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Hosts' collection:\\033[0m {db.Hosts.count_documents({})}\")  # Count the number of documents in the Hosts collection\n",
    "print(f\"\\033[1mSample document from 'Hosts' collection:\\033[0m\")\n",
    "pprint(db.Hosts.find_one(), sort_dicts=False)                                                        # Print one example document from the Hosts collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Data Normalization/Reference** by creating a separate `Hosts` collection. This eliminates the duplication of host information previously embedded in each listing document. Each document in `Hosts` represents a unique host, identified by `Host_ID`, and is referenced from the `Listings` collection. We expect **improved data integrity (updates to host info only need to happen in one place), reduced overall storage**, and **efficient querying of host-specific information** using the indexed `Host_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All host IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Check if all host IDs are unique\n",
    "host_ids = db.Hosts.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Host_ID\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(host_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate host IDs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Host ID: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All host IDs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host_ID_1'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Hosts.Host_ID index for faster queries (\"Foreign Key\")\n",
    "db.Hosts.create_index([(\"Host_ID\")])  # Create index on Host_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Transactions` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '1022200',\n",
      " 'transactions': {'bucket_end_date': datetime.datetime(2016, 11, 21, 0, 0),\n",
      "                  'bucket_start_date': datetime.datetime(1972, 6, 6, 0, 0),\n",
      "                  'transaction_count': 45,\n",
      "                  'transactions': [{'date': datetime.datetime(2015, 12, 1, 0, 0),\n",
      "                                    'price': Decimal128('29.15849659079999511845926463138312')},\n",
      "                                   {'date': datetime.datetime(1989, 12, 14, 0, 0),\n",
      "                                    'price': Decimal128('0.7724161292822024904580757720395922')},\n",
      "                                   {'date': datetime.datetime(1998, 12, 31, 0, 0),\n",
      "                                    'price': Decimal128('1.295972012182961652371204763767309')},\n",
      "                                   {'date': datetime.datetime(2009, 3, 30, 0, 0),\n",
      "                                    'price': Decimal128('31.52850186521098763137160858605057')},\n",
      "                                   {'date': datetime.datetime(2000, 5, 31, 0, 0),\n",
      "                                    'price': Decimal128('49.18051651563923343246642616577446')},\n",
      "                                   {'date': datetime.datetime(2009, 7, 7, 0, 0),\n",
      "                                    'price': Decimal128('34.65621723737613280036384821869432')},\n",
      "                                   {'date': datetime.datetime(2015, 7, 8, 0, 0),\n",
      "                                    'price': Decimal128('86.22352514753742980246897786855697')},\n",
      "                                   {'date': datetime.datetime(2011, 6, 16, 0, 0),\n",
      "                                    'price': Decimal128('54.43494403571661877094811643473803')},\n",
      "                                   {'date': datetime.datetime(2016, 10, 18, 0, 0),\n",
      "                                    'price': Decimal128('115.5600242040379441732511622831225')},\n",
      "                                   {'date': datetime.datetime(1998, 10, 12, 0, 0),\n",
      "                                    'price': Decimal128('1.206638616530141705496248505369294')},\n",
      "                                   {'date': datetime.datetime(1991, 1, 2, 0, 0),\n",
      "                                    'price': Decimal128('1.361862142742455317190319874498527')},\n",
      "                                   {'date': datetime.datetime(2016, 5, 17, 0, 0),\n",
      "                                    'price': Decimal128('118.1858096895133769521635258570313')},\n",
      "                                   {'date': datetime.datetime(2015, 5, 15, 0, 0),\n",
      "                                    'price': Decimal128('30.67717643739939248348491673823446')},\n",
      "                                   {'date': datetime.datetime(2003, 4, 28, 0, 0),\n",
      "                                    'price': Decimal128('14.79466170541391356607618945417925')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 27, 0, 0),\n",
      "                                    'price': Decimal128('16.81818592088138331064328667707741')},\n",
      "                                   {'date': datetime.datetime(2003, 6, 17, 0, 0),\n",
      "                                    'price': Decimal128('15.01234189362955007140953966882079')},\n",
      "                                   {'date': datetime.datetime(1988, 3, 2, 0, 0),\n",
      "                                    'price': Decimal128('0.7181873554933055903148897414212115')},\n",
      "                                   {'date': datetime.datetime(2015, 10, 30, 0, 0),\n",
      "                                    'price': Decimal128('76.44256410019895042751159053295850')},\n",
      "                                   {'date': datetime.datetime(2007, 12, 17, 0, 0),\n",
      "                                    'price': Decimal128('20.63278087075391198368379264138638')},\n",
      "                                   {'date': datetime.datetime(2011, 7, 13, 0, 0),\n",
      "                                    'price': Decimal128('13.58544794397653809880921471631154')},\n",
      "                                   {'date': datetime.datetime(2015, 6, 22, 0, 0),\n",
      "                                    'price': Decimal128('73.46376878396031884221883956342935')},\n",
      "                                   {'date': datetime.datetime(2015, 2, 11, 0, 0),\n",
      "                                    'price': Decimal128('75.90495979706304296996677294373512')},\n",
      "                                   {'date': datetime.datetime(1979, 4, 20, 0, 0),\n",
      "                                    'price': Decimal128('0.1779933743016186287189128734098630')},\n",
      "                                   {'date': datetime.datetime(1973, 8, 6, 0, 0),\n",
      "                                    'price': Decimal128('0.0561500005424022674560546875')},\n",
      "                                   {'date': datetime.datetime(2004, 7, 28, 0, 0),\n",
      "                                    'price': Decimal128('2.043086696201633412073306317324750')},\n",
      "                                   {'date': datetime.datetime(1985, 5, 14, 0, 0),\n",
      "                                    'price': Decimal128('0.4646852238595403083998292004253016')},\n",
      "                                   {'date': datetime.datetime(2014, 11, 7, 0, 0),\n",
      "                                    'price': Decimal128('19.45859800790097438039083499461412')},\n",
      "                                   {'date': datetime.datetime(2006, 12, 12, 0, 0),\n",
      "                                    'price': Decimal128('13.39928664879049691194268234539777')},\n",
      "                                   {'date': datetime.datetime(2016, 7, 13, 0, 0),\n",
      "                                    'price': Decimal128('33.58402622979829743599111679941415')},\n",
      "                                   {'date': datetime.datetime(1998, 9, 23, 0, 0),\n",
      "                                    'price': Decimal128('16.96044890308613162233086768537759')},\n",
      "                                   {'date': datetime.datetime(2002, 9, 26, 0, 0),\n",
      "                                    'price': Decimal128('9.793800762771049051025329390540719')},\n",
      "                                   {'date': datetime.datetime(2016, 5, 26, 0, 0),\n",
      "                                    'price': Decimal128('118.5466676311641691654585883952677')},\n",
      "                                   {'date': datetime.datetime(1997, 9, 11, 0, 0),\n",
      "                                    'price': Decimal128('6.445615410792042254684020008426159')},\n",
      "                                   {'date': datetime.datetime(2005, 1, 14, 0, 0),\n",
      "                                    'price': Decimal128('21.96567254190052764784013561438769')},\n",
      "                                   {'date': datetime.datetime(2009, 7, 24, 0, 0),\n",
      "                                    'price': Decimal128('9.000573985989589687051193322986364')},\n",
      "                                   {'date': datetime.datetime(2016, 2, 11, 0, 0),\n",
      "                                    'price': Decimal128('21.73591227836645600746123818680644')},\n",
      "                                   {'date': datetime.datetime(2012, 9, 20, 0, 0),\n",
      "                                    'price': Decimal128('68.06032346689130463346373289823532')},\n",
      "                                   {'date': datetime.datetime(2016, 6, 9, 0, 0),\n",
      "                                    'price': Decimal128('30.60337968896972782317789096850901')},\n",
      "                                   {'date': datetime.datetime(2013, 3, 1, 0, 0),\n",
      "                                    'price': Decimal128('11.92923913679549308142213703831657')},\n",
      "                                   {'date': datetime.datetime(2016, 6, 2, 0, 0),\n",
      "                                    'price': Decimal128('80.15773522778474102779000531882047')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 3, 0, 0),\n",
      "                                    'price': Decimal128('16.79925040549669645884023339021950')},\n",
      "                                   {'date': datetime.datetime(1991, 1, 30, 0, 0),\n",
      "                                    'price': Decimal128('1.112550641097352244202056681388057')},\n",
      "                                   {'date': datetime.datetime(2012, 12, 3, 0, 0),\n",
      "                                    'price': Decimal128('16.76913728179111018334879190661013')},\n",
      "                                   {'date': datetime.datetime(2015, 9, 2, 0, 0),\n",
      "                                    'price': Decimal128('63.59945944469900780404714168980717')},\n",
      "                                   {'date': datetime.datetime(2016, 4, 12, 0, 0),\n",
      "                                    'price': Decimal128('35.33423154808716759589515277184545')}]}}\n"
     ]
    }
   ],
   "source": [
    "# Print one example document of 'transactions' array\n",
    "pprint(db.listingsAndReviews_HW2.find_one({\"_id\": \"1022200\"}, {\"transactions\": 1}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create Transactions collection\n",
    "transactions_fields = [\"_id\", \n",
    "                       # \"transactions.bucket_end_date\", \"transactions.bucket_start_date\", \"transactions.transaction_count\", \n",
    "                       \"transactions.transactions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2603ddda690>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate to extract transactions and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$match\": {\"transactions.transactions\": {\"$exists\": True}}},                        # Match documents where 'transactions.transactions' exists\n",
    "    {\"$unwind\": \"$transactions.transactions\"},                                           # Unwind the 'transactions' array to create a document for each transaction\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                        # Will create a ObjectId for each transaction\n",
    "        \"Listing_ID\": \"$_id\",                                                            # Include the listing ID\n",
    "        \"Transaction_ID\": \"$transactions.transactions._id\",                              # Include the transaction ID\n",
    "        \"Transaction_Date\": \"$transactions.transactions.date\",                           # Include the transaction date\n",
    "        \"Transaction_Price\": \"$transactions.transactions.price\"                          # Include the transaction price\n",
    "    }},\n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Transactions\"}                                                             # Output directly to 'Transactions' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Transactions' collection:\u001b[0m 311093\n",
      "\u001b[1mSample document from 'Transactions' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fea811a6298d01ad09bc52'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Transaction_Date': datetime.datetime(2008, 8, 12, 0, 0),\n",
      " 'Transaction_Price': Decimal128('132.1063781684291313922585686668753')}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check the new Transactions collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Transactions' collection:\\033[0m {db.Transactions.count_documents({})}\") # Count the number of documents in the Transactions collection\n",
    "print(f\"\\033[1mSample document from 'Transactions' collection:\\033[0m\")\n",
    "pprint(db.Transactions.find_one(), sort_dicts=False)                                                              # Print one example document from the Transactions collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **Referencing** by creating a separate `Transactions` collection, moving the potentially large and time-sensitive `transactions.transactions` array out of the main listing document. This isolates transaction data for focused querying (like in **Q10**). Each document represents a single transaction and includes a `Listing_ID` reference. We expect **faster reads for the main `Listings` collection**, **improved performance for time-based queries on transactions** (especially with the index on `Listing_ID` and potentially `Transaction_Date`), and **better scalability for transaction data** (as it can grow independently of the listing document and we have limit of 16MB per document).\n",
    "\n",
    "**Note:** We decided to *keep* the `transactions.bucket_end_date`, `transactions.bucket_start_date`, and `transactions.transaction_count` fields within the main `Listings` collection (under the `Transactions` subdocument, but without the nested `transactions` array). These fields provide a useful summary about the transaction history associated with the listing, which might be needed for display without querying the full `Transactions` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1: Check if all (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique\n",
    "transactions_ids = db.Transactions.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": {\"Listing_ID\": \"$Listing_ID\", \"Transaction_Date\": \"$Transaction_Date\", \"Transaction_Price\": \"$Transaction_Price\"},\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(transactions_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate (Listing_ID, Transaction_Date, Transaction_Price) pairs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Pair: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All (Listing_ID, Transaction_Date, Transaction_Price) pairs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create Transactions.Listing_ID index for faster queries (\"Foreign Key\")\n",
    "db.Transactions.create_index([(\"Listing_ID\")])  # Create index on Listing_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Listings` Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop_collection(\"Listings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found \u001b[1m45 listings fields\u001b[0m: \n",
      "\n",
      "['_id',\n",
      " 'access',\n",
      " 'accommodates',\n",
      " 'address',\n",
      " 'amenities',\n",
      " 'availability',\n",
      " 'bathrooms',\n",
      " 'bed_type',\n",
      " 'bedrooms',\n",
      " 'beds',\n",
      " 'calendar_last_scraped',\n",
      " 'cancellation_policy',\n",
      " 'cleaning_fee',\n",
      " 'description',\n",
      " 'extra_people',\n",
      " 'first_review',\n",
      " 'guests_included',\n",
      " 'house_rules',\n",
      " 'images',\n",
      " 'interaction',\n",
      " 'last_review',\n",
      " 'last_scraped',\n",
      " 'listing_url',\n",
      " 'maximum_nights',\n",
      " 'minimum_nights',\n",
      " 'monthly_price',\n",
      " 'name',\n",
      " 'neighborhood_overview',\n",
      " 'notes',\n",
      " 'number_of_reviews',\n",
      " 'price',\n",
      " 'property_type',\n",
      " 'review_scores_checkin',\n",
      " 'review_scores_cleanliness',\n",
      " 'review_scores_communication',\n",
      " 'review_scores_location',\n",
      " 'review_scores_rating',\n",
      " 'review_scores_value',\n",
      " 'room_type',\n",
      " 'security_deposit',\n",
      " 'space',\n",
      " 'summary',\n",
      " 'transactions',\n",
      " 'transit',\n",
      " 'weekly_price']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create Listings collection\n",
    "# Extract all fields except for \"reviews\", \"transactions.transactions\" array, and \"host_\" fields\n",
    "listings_fields = db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},             # Convert document to key-value pairs\n",
    "    {\"$unwind\": \"$fields\"},                                             # Flatten the fields array\n",
    "    {\"$match\": {\n",
    "        \"fields.k\": {\n",
    "            \"$not\": {\n",
    "                \"$regex\": \"^reviews|^transactions\\\\.transactions|^host_\"\n",
    "            }\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\"_id\": \"$fields.k\"}}                                    # Group by field names to get distinct fields\n",
    "])\n",
    "\n",
    "# Convert the aggregation result to a list with only field names\n",
    "listings_fields = sorted([doc[\"_id\"] for doc in listings_fields])\n",
    "\n",
    "# Print the list of listings fields\n",
    "print(f\"Found \\033[1m{len(listings_fields)} listings fields\\033[0m: \\n\")\n",
    "pprint(listings_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x2603ddda720>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Aggregate to extract listings and their corresponding listing IDs\n",
    "db.listingsAndReviews_HW2.aggregate([\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                                                   # Will create a ObjectId for each listing\n",
    "        \"Listing_ID\": \"$_id\",                                                       # Include the listing ID\n",
    "        \"Host_ID\": \"$host_id\",                                                      # Include the host ID\n",
    "        \"Name\": \"$name\",                                                            # Name of the listing\n",
    "        \"Description\": \"$description\",                                              # Description of the listing\n",
    "        \"Summary\": \"$summary\",                                                      # Summary of the listing\n",
    "        \"Space\": \"$space\",                                                          # Space details\n",
    "        \"Property_Type\": \"$property_type\",                                          # Type of property\n",
    "        \"Room_Type\": \"$room_type\",                                                  # Type of room\n",
    "        \"Accommodates\": \"$accommodates\",                                            # Number of guests accommodated\n",
    "        \"Bedrooms\": \"$bedrooms\",                                                    # Number of bedrooms\n",
    "        \"Beds\": \"$beds\",                                                            # Number of beds\n",
    "        \"Bathrooms\": \"$bathrooms\",                                                  # Number of bathrooms\n",
    "        \"Bed_Type\": \"$bed_type\",                                                    # Type of bed\n",
    "        \"Price\": \"$price\",                                                          # Price per night\n",
    "        \"Cleaning_Fee\": \"$cleaning_fee\",                                            # Cleaning fee\n",
    "        \"Security_Deposit\": \"$security_deposit\",                                    # Security deposit\n",
    "        \"Extra_People\": \"$extra_people\",                                            # Extra charges for additional people\n",
    "        \"Weekly_Price\": \"$weekly_price\",                                            # Weekly price\n",
    "        \"Monthly_Price\": \"$monthly_price\",                                          # Monthly price\n",
    "        \"Minimum_Nights\": \"$minimum_nights\",                                        # Minimum nights for booking\n",
    "        \"Maximum_Nights\": \"$maximum_nights\",                                        # Maximum nights for booking\n",
    "        \"Guests_Included\": \"$guests_included\",                                      # Number of guests included in the price\n",
    "        \"Address\": \"$address\",                                                      # Address details\n",
    "        \"Access\": \"$access\",                                                        # Access details\n",
    "        \"Interaction\": \"$interaction\",                                              # Interaction details\n",
    "        \"House_Rules\": \"$house_rules\",                                              # House rules\n",
    "        \"Amenities\": \"$amenities\",                                                  # Amenities provided\n",
    "        \"Availability\": \"$availability\",                                            # Availability details\n",
    "        \"Calendar_Last_Scraped\": \"$calendar_last_scraped\",                          # Last scraped date of the calendar\n",
    "        \"Last_Scraped\": \"$last_scraped\",                                            # Last scraped date of the listing\n",
    "        \"Cancellation_Policy\": \"$cancellation_policy\",                              # Cancellation policy\n",
    "        \"Neighborhood_Overview\": \"$neighborhood_overview\",                          # Overview of the neighborhood\n",
    "        \"Transit\": \"$transit\",                                                      # Transit information\n",
    "        \"Notes\": \"$notes\",                                                          # Additional notes\n",
    "        \"Images\": \"$images\",                                                        # Images of the listing\n",
    "        \"Listing_URL\": \"$listing_url\",                                              # URL of the listing\n",
    "        \"First_Review\": \"$first_review\",                                            # Date of the first review\n",
    "        \"Last_Review\": \"$last_review\",                                              # Date of the last review\n",
    "        \"Number_of_Reviews\": \"$number_of_reviews\",                                  # Total number of reviews\n",
    "        \"Review_Scores_Rating\": \"$review_scores_rating\",                            # Review scores rating\n",
    "        \n",
    "        # Review scores for subdocument | Capitalize and prefix the score name (e.g., \"review_scores__checkin\" -> \"Checkin\")\n",
    "        \"Review_Scores\": {\n",
    "            \"Checkin\": \"$review_scores_checkin\",                                    # Check-in rating\n",
    "            \"Cleanliness\": \"$review_scores_cleanliness\",                            # Cleanliness rating\n",
    "            \"Communication\": \"$review_scores_communication\",                        # Communication rating\n",
    "            \"Location\": \"$review_scores_location\",                                  # Location rating\n",
    "            \"Rating\": \"$review_scores_rating\",                                      # Overall rating\n",
    "            \"Value\": \"$review_scores_value\"                                         # Value rating\n",
    "        },\n",
    "        \n",
    "        \"Transactions\": \"$transactions\"                                             # Transactions details\n",
    "    }},\n",
    "    # Drop the 'transactions.transactions' field from the listings collection\n",
    "    {\"$unset\": \"Transactions.transactions\"},\n",
    "    \n",
    "    # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/out/\n",
    "    {\"$out\": \"Listings\"}                                                            # Output directly to 'Listings' collection in the same database\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mNumber of documents in 'Listings' collection:\u001b[0m 5555\n",
      "\u001b[1mSample document from 'Listings' collection:\u001b[0m\n",
      "{'_id': ObjectId('67fea816a6298d01ad0e7b87'),\n",
      " 'Listing_ID': '10006546',\n",
      " 'Host_ID': '51399391',\n",
      " 'Name': 'Ribeira Charming Duplex',\n",
      " 'Description': 'Fantastic duplex apartment with three bedrooms, located in '\n",
      "                'the historic area of Porto, Ribeira (Cube) - UNESCO World '\n",
      "                'Heritage Site. Centenary building fully rehabilitated, '\n",
      "                'without losing their original character. Privileged views of '\n",
      "                'the Douro River and Ribeira square, our apartment offers the '\n",
      "                'perfect conditions to discover the history and the charm of '\n",
      "                'Porto. Apartment comfortable, charming, romantic and cozy in '\n",
      "                'the heart of Ribeira. Within walking distance of all the most '\n",
      "                'emblematic places of the city of Porto. The apartment is '\n",
      "                'fully equipped to host 8 people, with cooker, oven, washing '\n",
      "                'machine, dishwasher, microwave, coffee machine (Nespresso) '\n",
      "                'and kettle. The apartment is located in a very typical area '\n",
      "                'of the city that allows to cross with the most picturesque '\n",
      "                'population of the city, welcoming, genuine and happy people '\n",
      "                'that fills the streets with his outspoken speech and '\n",
      "                'contagious with your sincere generosity, wrapped in a only '\n",
      "                'parochial spirit. We are always available to help guests',\n",
      " 'Summary': 'Fantastic duplex apartment with three bedrooms, located in the '\n",
      "            'historic area of Porto, Ribeira (Cube) - UNESCO World Heritage '\n",
      "            'Site. Centenary building fully rehabilitated, without losing '\n",
      "            'their original character.',\n",
      " 'Space': 'Privileged views of the Douro River and Ribeira square, our '\n",
      "          'apartment offers the perfect conditions to discover the history and '\n",
      "          'the charm of Porto. Apartment comfortable, charming, romantic and '\n",
      "          'cozy in the heart of Ribeira. Within walking distance of all the '\n",
      "          'most emblematic places of the city of Porto. The apartment is fully '\n",
      "          'equipped to host 8 people, with cooker, oven, washing machine, '\n",
      "          'dishwasher, microwave, coffee machine (Nespresso) and kettle. The '\n",
      "          'apartment is located in a very typical area of the city that allows '\n",
      "          'to cross with the most picturesque population of the city, '\n",
      "          'welcoming, genuine and happy people that fills the streets with his '\n",
      "          'outspoken speech and contagious with your sincere generosity, '\n",
      "          'wrapped in a only parochial spirit.',\n",
      " 'Property_Type': 'House',\n",
      " 'Room_Type': 'Entire home/apt',\n",
      " 'Accommodates': 8,\n",
      " 'Bedrooms': 3,\n",
      " 'Beds': 5,\n",
      " 'Bathrooms': Decimal128('1.0'),\n",
      " 'Bed_Type': 'Real Bed',\n",
      " 'Price': Decimal128('80.00'),\n",
      " 'Cleaning_Fee': Decimal128('35.00'),\n",
      " 'Security_Deposit': Decimal128('200.00'),\n",
      " 'Extra_People': Decimal128('15.00'),\n",
      " 'Minimum_Nights': 2,\n",
      " 'Maximum_Nights': 30,\n",
      " 'Guests_Included': 6,\n",
      " 'Address': {'street': 'Porto, Porto, Portugal',\n",
      "             'government_area': 'Cedofeita, Ildefonso, S√©, Miragaia, Nicolau, '\n",
      "                                'Vit√≥ria',\n",
      "             'market': 'Porto',\n",
      "             'country': 'Portugal',\n",
      "             'country_code': 'PT',\n",
      "             'location': {'type': 'Point',\n",
      "                          'coordinates': [-8.61308, 41.1413],\n",
      "                          'is_location_exact': False}},\n",
      " 'Access': 'We are always available to help guests. The house is fully '\n",
      "           'available to guests. We are always ready to assist guests. when '\n",
      "           'possible we pick the guests at the airport.  This service transfer '\n",
      "           'have a cost per person. We will also have service \"meal at home\" '\n",
      "           'with a diverse menu and the taste of each. Enjoy the moment!',\n",
      " 'Interaction': 'Cot - 10 ‚Ç¨ / night Dog - ‚Ç¨ 7,5 / night',\n",
      " 'House_Rules': 'Make the house your home...',\n",
      " 'Amenities': ['Bed linens',\n",
      "               'Buzzer/wireless intercom',\n",
      "               'Cable TV',\n",
      "               'Cleaning before checkout',\n",
      "               'Coffee maker',\n",
      "               'Cooking basics',\n",
      "               'Dishes and silverware',\n",
      "               'Dishwasher',\n",
      "               'Essentials',\n",
      "               'Extra pillows and blankets',\n",
      "               'Family/kid friendly',\n",
      "               'Fire extinguisher',\n",
      "               'First aid kit',\n",
      "               'Hair dryer',\n",
      "               'Hangers',\n",
      "               'Heating',\n",
      "               'Hot water',\n",
      "               'Iron',\n",
      "               'Kitchen',\n",
      "               'Microwave',\n",
      "               'Oven',\n",
      "               'Pack ‚Äôn Play/travel crib',\n",
      "               'Paid parking off premises',\n",
      "               'Pets allowed',\n",
      "               'Refrigerator',\n",
      "               'Room-darkening shades',\n",
      "               'Smoking allowed',\n",
      "               'Stove',\n",
      "               'TV',\n",
      "               'Washer',\n",
      "               'Waterfront',\n",
      "               'Wifi'],\n",
      " 'Availability': {'availability_30': 28,\n",
      "                  'availability_60': 47,\n",
      "                  'availability_90': 74,\n",
      "                  'availability_365': 239},\n",
      " 'Calendar_Last_Scraped': datetime.datetime(2019, 2, 16, 5, 0),\n",
      " 'Last_Scraped': datetime.datetime(2019, 2, 16, 5, 0),\n",
      " 'Cancellation_Policy': 'moderate',\n",
      " 'Neighborhood_Overview': 'In the neighborhood of the river, you can find '\n",
      "                          'several restaurants as varied flavors, but without '\n",
      "                          'forgetting the so traditional northern food. You '\n",
      "                          'can also find several bars and pubs to unwind after '\n",
      "                          \"a day's visit to the magnificent Port. To enjoy the \"\n",
      "                          'Douro River can board the boats that daily make the '\n",
      "                          'ride of six bridges. You can also embark towards '\n",
      "                          \"R√©gua, Barca d'Alva, Pinh√£o, etc and enjoy the \"\n",
      "                          'Douro Wine Region, World Heritage of Humanity. The '\n",
      "                          \"Infante's house is a few meters and no doubt it \"\n",
      "                          'deserves a visit. They abound grocery stores, '\n",
      "                          'bakeries, etc. to make your meals. Souvenir shop, '\n",
      "                          'wine cellars, etc. to bring some souvenirs.',\n",
      " 'Transit': 'Transport: ‚Ä¢ Metro station and S. Bento railway 5min; ‚Ä¢ Bus stop '\n",
      "            'a 50 meters; ‚Ä¢ Lift Guindais (Funicular) 50 meters; ‚Ä¢ Tuc Tuc-to '\n",
      "            'get around the city; ‚Ä¢ Buses tourist; ‚Ä¢ Cycling through the '\n",
      "            'marginal drive; ‚Ä¢ Cable car in Gaia, overlooking the Port (just '\n",
      "            'cross the bridge).',\n",
      " 'Notes': 'Lose yourself in the narrow streets and staircases zone, have lunch '\n",
      "          'in pubs and typical restaurants, and find the renovated cafes and '\n",
      "          'shops in town. If you like exercise, rent a bicycle in the area and '\n",
      "          'ride along the river to the sea, where it will enter beautiful '\n",
      "          'beaches and terraces for everyone. The area is safe, find the bus '\n",
      "          'stops 1min and metro line 5min. The bustling nightlife is a 10 min '\n",
      "          'walk, where the streets are filled with people and entertainment '\n",
      "          'for all. But Porto is much more than the historical center, here is '\n",
      "          'modern museums, concert halls, clean and cared for beaches and surf '\n",
      "          'all year round. Walk through the Ponte D. Luis and visit the '\n",
      "          'different Caves of Port wine, where you will enjoy the famous port '\n",
      "          'wine. Porto is a spoken city everywhere in the world as the best to '\n",
      "          'be visited and savored by all ... natural beauty, culture, '\n",
      "          'tradition, river, sea, beach, single people, typical food, and we '\n",
      "          'are among those who best receive tourists, confirm! Come visit us '\n",
      "          'and feel at ho',\n",
      " 'Images': {'picture_url': 'https://a0.muscache.com/im/pictures/e83e702f-ef49-40fb-8fa0-6512d7e26e9b.jpg?aki_policy=large'},\n",
      " 'Listing_URL': 'https://www.airbnb.com/rooms/10006546',\n",
      " 'First_Review': datetime.datetime(2016, 1, 3, 5, 0),\n",
      " 'Last_Review': datetime.datetime(2019, 1, 20, 5, 0),\n",
      " 'Number_of_Reviews': 51,\n",
      " 'Review_Scores_Rating': 8.9,\n",
      " 'Review_Scores': {'Checkin': 10,\n",
      "                   'Cleanliness': 9,\n",
      "                   'Communication': 10,\n",
      "                   'Location': 10,\n",
      "                   'Rating': 8.9,\n",
      "                   'Value': 9},\n",
      " 'Transactions': {'bucket_end_date': datetime.datetime(2016, 11, 23, 0, 0),\n",
      "                  'bucket_start_date': datetime.datetime(1979, 10, 4, 0, 0),\n",
      "                  'transaction_count': 21}}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check the new Listings collection\n",
    "print(f\"\\n\\033[1mNumber of documents in 'Listings' collection:\\033[0m {db.Listings.count_documents({})}\")     # Count the number of documents in the Listings collection\n",
    "print(f\"\\033[1mSample document from 'Listings' collection:\\033[0m\")\n",
    "pprint(db.Listings.find_one(), sort_dicts=False)                                                               # Print one example document from the Listings collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We applied **schema restructuring** to create the final `Listings` collection. This involved **removing embedded host details, the full reviews array, and the detailed transactions array**, replacing them with references (`Host_ID`). We **restructured the `review_scores_*` fields into a `Review_Scores` subdocument**, applying the **Attribute Pattern** for flexibility (**Q9**). Key identifying information (`Listing_ID`), frequently accessed data (`Name`, `Price`, `Address`, `Amenities`, etc.), and summary transaction info remain embedded. We expect **significantly faster retrieval of core listing information** for the primary customer-facing use case (**Q1**), as documents are much smaller. The restructured `Review_Scores` allows for flexible querying of score averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All listing IDs are unique.\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1: Check if all listing IDs are unique\n",
    "listings_ids = db.Listings.aggregate([\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Listing_ID\",\n",
    "        \"count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\n",
    "        \"count\": {\"$gt\": 1}\n",
    "    }}\n",
    "])\n",
    "duplicates = list(listings_ids)\n",
    "if duplicates:\n",
    "    print(f\"Warning: Found {len(duplicates)} duplicate listing IDs.\")\n",
    "    for doc in duplicates:\n",
    "        print(f\"Listing ID: {doc['_id']} appears {doc['count']} times.\")\n",
    "else:\n",
    "    print(\"All listing IDs are unique.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listing_ID_1'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Listings.Listing_ID and Listings.Host_ID indexes for faster queries (\"Foreign Key\")\n",
    "db.Listings.create_index([(\"Listing_ID\")])                                      # Create index on Listing_ID field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host_ID_1'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Listings.create_index([(\"Host_ID\")])                                         # Create index on Host_ID field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üîç Queries** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üõãÔ∏èStandard Difficulty Questions** [2 points per question]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)\tOnce a month, we reward hosts with recognition. \n",
    "#       Select three superhosts with at least two listings that can accommodate more than four people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0209 seconds\n",
      "\n",
      "Found \u001b[1m14 superhosts\u001b[0m with at least 2 listings that can accommodate more than 4 people.\n",
      "\n",
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assun√ß√£o De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Daniel                    | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Elite                     | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [14, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Great Vacation Retreats   | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [5, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Jane                      | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 9]\n",
      "\u001b[1mHost Name\u001b[0m: Liiiving                  | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Miguel & Jo√£o             | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 5]\n",
      "\u001b[1mHost Name\u001b[0m: Mindy                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Patty And Beckett         | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [8, 8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Resortica                 | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Wilson&Shan               | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [9, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Yaiza                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 6]\n"
     ]
    }
   ],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for superhosts and listings accommodating > 4\n",
    "    {\"$match\": {\"host_is_superhost\": True, \"accommodates\": {\"$gt\": 4}}},\n",
    "    # Group by host_id to count listings and collect accommodates values\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$host_id\",\n",
    "        \"HostName\": {\"$first\": \"$host_name\"},\n",
    "        \"ListingCount\": {\"$sum\": 1},\n",
    "        \"AccommodatesList\": {\"$push\": \"$accommodates\"}  # Collect all accommodates values\n",
    "    }},\n",
    "    # Filter for hosts with at least 2 listings\n",
    "    {\"$match\": {\"ListingCount\": {\"$gte\": 2}}},\n",
    "    # Sort by host name for consistency\n",
    "    {\"$sort\": {\"HostName\": 1}},\n",
    "    \n",
    "    # Limit to 3 superhosts\n",
    "    # {\"$limit\": 3},\n",
    "    \n",
    "    # Project output without _id\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"HostName\": 1,\n",
    "        \"ListingCount\": 1,\n",
    "        \"AccommodatesList\": 1                           # Include the list of accommodation capacities\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nFound \\033[1m{len(result)} superhosts\\033[0m with at least 2 listings that can accommodate more than 4 people.\\n\")\n",
    "for host in result:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0379 seconds\n",
      "\n",
      "Found \u001b[1m14 superhosts\u001b[0m with at least 2 listings accommodating > 4 people.\n",
      "\n",
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assun√ß√£o De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Daniel                    | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Elite                     | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [14, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Great Vacation Retreats   | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [5, 6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Jane                      | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 9]\n",
      "\u001b[1mHost Name\u001b[0m: Liiiving                  | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Miguel & Jo√£o             | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 5]\n",
      "\u001b[1mHost Name\u001b[0m: Mindy                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [6, 6]\n",
      "\u001b[1mHost Name\u001b[0m: Patty And Beckett         | \u001b[1mListing Count:\u001b[0m 3 | \u001b[1mAccommodates List:\u001b[0m [8, 8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Resortica                 | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Wilson&Shan               | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [9, 8]\n",
      "\u001b[1mHost Name\u001b[0m: Yaiza                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [8, 6]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "query2 = list(db.Hosts.aggregate([\n",
    "    \n",
    "    # Start with Hosts collection to filter superhosts\n",
    "    {\"$match\": {\"Host_Is_Superhost\": True}},\n",
    "    \n",
    "    # Lookup listings for each host\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Listings\",\n",
    "        \"localField\": \"Host_ID\",\n",
    "        \"foreignField\": \"Host_ID\",\n",
    "        \"as\": \"listings\"\n",
    "    }},\n",
    "    \n",
    "    # Filter listings accommodating > 4\n",
    "    {\"$project\": {\n",
    "        \"HostName\": \"$Host_Name\",\n",
    "        \"listings\": {\n",
    "            \"$filter\": {\n",
    "                \"input\": \"$listings\",\n",
    "                \"cond\": {\"$gt\": [\"$$this.Accommodates\", 4]}\n",
    "            }\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group to count listings per host\n",
    "    {\"$project\": {\n",
    "        \"HostName\": 1,\n",
    "        \"ListingCount\": {\"$size\": \"$listings\"},\n",
    "        \"AccommodatesList\": \"$listings.Accommodates\"\n",
    "    }},\n",
    "    \n",
    "    # Filter hosts with at least 2 listings\n",
    "    {\"$match\": {\"ListingCount\": {\"$gte\": 2}}},\n",
    "    \n",
    "    # Sort by name for consistency\n",
    "    {\"$sort\": {\"HostName\": 1}}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nFound \\033[1m{len(query2)} superhosts\\033[0m with at least 2 listings accommodating > 4 people.\\n\")\n",
    "for host in query2:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mHost Name\u001b[0m: Aj                        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [16, 16]\n",
      "\u001b[1mHost Name\u001b[0m: Aline                     | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 12]\n",
      "\u001b[1mHost Name\u001b[0m: Assun√ß√£o De Fatima        | \u001b[1mListing Count:\u001b[0m 2 | \u001b[1mAccommodates List:\u001b[0m [5, 8]\n"
     ]
    }
   ],
   "source": [
    "# Select three superhosts with at least two listings that can accommodate more than four people\n",
    "for host in query2[:3]:\n",
    "    print(f\"\\033[1mHost Name\\033[0m: {host['HostName']:<25} | \\033[1mListing Count:\\033[0m {host['ListingCount']} | \\033[1mAccommodates List:\\033[0m {host['AccommodatesList']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q2):** The new schema query uses a `$lookup` to join `Hosts` and `Listings`. While lookups can introduce overhead compared to querying a single collection, this approach maintains normalized data by avoiding host information duplication. The execution time in the new schema (0.038s) is slightly slower than the original (0.021s) for this specific query. This is expected due to the left outer join operation (**`$lookup`**). However, the **trade-off ensures data integrity and avoids redundancy across the dataset**.\n",
    "\n",
    "\n",
    "**Note:** The Top 3 superhosts presented were selected based on alphabetical order of the host names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3)\tThe company considers investing into property to rent. \n",
    "#       Which bed type is most common in listings with a waterfront and a dishwasher in New York?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0497 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "# 3. Most common bed type in New York listings with waterfront and dishwasher\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"address.market\": \"New York\",\n",
    "        \"amenities\": {\n",
    "            \"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}  # Matches any waterfront variant (case-insensitive)\n",
    "        },\n",
    "        \"amenities\": {\n",
    "            \"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}  # Matches any dishwasher variant (case-insensitive)\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$bed_type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{result[0]['BedType']}\\033[0m with \\033[1m{result[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0410 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query3 = list(db.Listings.aggregate([\n",
    "    \n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"Address.market\": \"New York\",\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}},  # Matches any waterfront variant (case-insensitive)\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}},  # Matches any dishwasher variant (case-insensitive)\n",
    "        \"Bed_Type\": {\"$exists\": True}                                            # Ensure Bed_Type field exists\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Bed_Type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{query3[0]['BedType']}\\033[0m with \\033[1m{query3[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q3):** Both queries yield the same result (**\"Real Bed\"**, count **75**). The new schema query targets the optimized `Listings` collection. Performance is comparable (0.041s vs 0.050s in the original). This indicates that querying the leaner `Listings` collection, even with similar filtering logic on embedded arrays (`Amenities`), maintains performance while offering better overall structure. After adding indexes, the new schema query becomes faster (0.027s). Indexing `Address.market` and `Amenities` provides a clear benefit for this query pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amenities_1'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing 'Address.market' and 'Amenities' fields for faster queries (Single Field Indexes - Text)\n",
    "db.Listings.create_index([(\"Address.market\")])  # Create index on Address.market field\n",
    "db.Listings.create_index([(\"Amenities\")])       # Create index on Amenities field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0268 seconds\n",
      "\n",
      "Most common bed type in New York listings with waterfront and dishwasher is \u001b[1mReal Bed\u001b[0m with \u001b[1m75\u001b[0m occurrences.\n"
     ]
    }
   ],
   "source": [
    "# Re-run the query with indexes\n",
    "start_time = time.time()\n",
    "\n",
    "query3 = list(db.Listings.aggregate([\n",
    "    \n",
    "    # Filter for New York, waterfront, and dishwasher (case-insensitive)\n",
    "    {\"$match\": {\n",
    "        \"Address.market\": \"New York\",\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"waterfront\", \"$options\": \"i\"}},  # Matches any waterfront variant (case-insensitive)\n",
    "        \"Amenities\": {\"$elemMatch\": {\"$regex\": \"dishwasher\", \"$options\": \"i\"}},  # Matches any dishwasher variant (case-insensitive)\n",
    "        \"Bed_Type\": {\"$exists\": True}                                            # Ensure Bed_Type field exists\n",
    "    }},\n",
    "    \n",
    "    # Group by bed_type and count occurrences\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Bed_Type\",\n",
    "        \"Count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"Count\": -1}},\n",
    "    \n",
    "    # Limit to 1 (most common)\n",
    "    {\"$limit\": 1},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"BedType\": \"$_id\",\n",
    "        \"Count\": 1\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nMost common bed type in New York listings with waterfront and dishwasher is \\033[1m{query3[0]['BedType']}\\033[0m with \\033[1m{query3[0]['Count']}\\033[0m occurrences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we expected, the new schema query with indexing on `Address.market` and `Amenities` is faster than the original query, because in this case we are searching for a specific value in the `Amenities` array and `Address.market` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4)\tWe're considering hiring someone to write reviews professionally. \n",
    "#       Who wrote the longest review in New York?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0690 seconds\n",
      "\n",
      "Reviewer who wrote the longest review in New York is: \u001b[1mAngela\u001b[0m with \u001b[1m4665 characters\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 4. Reviewer who wrote the longest review in New York\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for New York\n",
    "    {\"$match\": {\"address.market\": \"New York\"}},\n",
    "    # Unwind reviews array\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    # Project review length and reviewer, handling null comments\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerName\": \"$reviews.reviewer_name\",\n",
    "        \"ReviewLength\": {\"$strLenCP\":                # Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/strLenCP/\n",
    "            {\"$ifNull\": [\"$reviews.comments\", \"\"]}}  # Default to empty string if null\n",
    "    }},\n",
    "    # Sort by length descending\n",
    "    {\"$sort\": {\"ReviewLength\": -1}},\n",
    "    # Limit to 1\n",
    "    {\"$limit\": 1}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline)) # [{'ReviewLength': 4665, 'ReviewerName': 'Angela'}]\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nReviewer who wrote the longest review in New York is: \\033[1m{result[0]['ReviewerName']}\\033[0m with \\033[1m{result[0]['ReviewLength']} characters\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 14.0446 seconds\n",
      "[{'ReviewLength': 4665, 'ReviewerName': 'Angela'}]\n",
      "\n",
      "Reviewer who wrote the longest review in New York is: \u001b[1mAngela\u001b[0m with \u001b[1m4665 characters\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query4 = list(db.Reviews.aggregate([\n",
    "    # Join Reviews with Listings to filter by New York\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Listings\",\n",
    "        \"localField\": \"Listing_ID\",\n",
    "        \"foreignField\": \"Listing_ID\",\n",
    "        \"as\": \"listing\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the listings array to create a document for each review\n",
    "    {\"$unwind\": \"$listing\"},\n",
    "    \n",
    "    # Filter for New York listings\n",
    "    {\"$match\": {\"listing.Address.market\": \"New York\"}},\n",
    "    \n",
    "    # Project review length and reviewer, handling null comments\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Reviewer_ID\": \"$Reviewer_ID\",                                          # Include Reviewer_ID\n",
    "        \"ReviewLength\": {\"$strLenCP\": {\"$ifNull\": [\"$Review_Comments\", \"\"]}}    # Calculate length of review comments (handling nulls)\n",
    "    }},\n",
    "    \n",
    "    # Join Reviews with Reviewers to get reviewer names\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Reviewers\",\n",
    "        \"localField\": \"Reviewer_ID\",\n",
    "        \"foreignField\": \"Reviewer_ID\",\n",
    "        \"as\": \"reviewer\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the reviewers array to create a document for each review\n",
    "    {\"$unwind\": \"$reviewer\"},\n",
    "    \n",
    "    # Project reviewer name\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerName\": \"$reviewer.Reviewer_Name\",\n",
    "        \"ReviewLength\": 1\n",
    "    }},\n",
    "    \n",
    "    # Sort by length descending\n",
    "    {\"$sort\": {\"ReviewLength\": -1}},\n",
    "    \n",
    "    # Limit to 1 (reviewer with longest review)\n",
    "    {\"$limit\": 1}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# pprint(query4)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "pprint(query4, sort_dicts=False)\n",
    "print(f\"\\nReviewer who wrote the longest review in New York is: \\033[1m{query4[0]['ReviewerName']}\\033[0m with \\033[1m{query4[0]['ReviewLength']} characters\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q4):** The new schema query involves lookups between `Reviews`, `Listings` (for the market filter), and `Reviewers`. Although separating collections often improves performance for targeted reads, the multiple `$lookup` stages required here introduce significant overhead compared to the original query which only needed to unwind the embedded `reviews` array. This resulted in a considerably longer execution time (14.04s vs 0.069s). While indexing helps, the cost of joining large collections for *this specific aggregation* outweighs the benefit of smaller individual documents in the `Reviews` collection.\n",
    "\n",
    "> If this query was part of the queries list to consider for optimization (not part of queries to \"consider for database optimization\" - **Q7** to **Q11**),  further optimization (like denormalizing the reviewer name into the **`Reviews`** collection - **Extended Reference Pattern**) might be considered in a real-world scenario. However, the current schema prioritises scalability and avoids data duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\tTo assess the security of different areas, what is the biggest and smallest (price-security deposit) difference per number of visitors at a property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0317 seconds\n",
      "\n",
      "Biggest difference (price - security deposit) per number of visitors: \u001b[1m19229.5\u001b[0m\n",
      "Smallest difference (price - security deposit) per number of visitors: \u001b[1m0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 5. Biggest and smallest (price - security deposit) difference per number of visitors\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Filter for listings with price and security deposit\n",
    "    {\"$match\": {\n",
    "        \"price\": {\"$exists\": True, \"$ne\": None},                                  # Price exists and is not null\n",
    "        \"security_deposit\": {\"$exists\": True, \"$ne\": None}                        # Security deposit exists and is not null\n",
    "    }},\n",
    "    \n",
    "    # Calculate difference per visitor, converting strings to numbers\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"DifferencePerVisitor\": {\n",
    "            \"$divide\": [\n",
    "                {\"$abs\":                                                        # Absolute value of difference\n",
    "                    {\"$subtract\": [\n",
    "                        {\"$toDouble\": {\"$ifNull\": [\"$price\", \"0\"]}},            # Convert price to double, default 0\n",
    "                        {\"$toDouble\": {\"$ifNull\": [\"$security_deposit\", \"0\"]}}  # Convert security_deposit, default 0\n",
    "                    ]}\n",
    "                }\n",
    "                , \"$accommodates\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "    # Group to find min and max\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"MaxDifference\": {\"$max\": \"$DifferencePerVisitor\"},\n",
    "        \"MinDifference\": {\"$min\": \"$DifferencePerVisitor\"}\n",
    "    }},\n",
    "    # Project output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"MaxDifference\": {\"$round\": [\"$MaxDifference\", 2]},\n",
    "        \"MinDifference\": {\"$round\": [\"$MinDifference\", 2]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nBiggest difference (price - security deposit) per number of visitors: \\033[1m{result[0]['MaxDifference']}\\033[0m\")\n",
    "print(f\"Smallest difference (price - security deposit) per number of visitors: \\033[1m{result[0]['MinDifference']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0210 seconds\n",
      "\n",
      "Biggest difference (price - security deposit) per visitor: \u001b[1m19229.5\u001b[0m\n",
      "Smallest difference (price - security deposit) per visitor: \u001b[1m0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query5 = list(db.Listings.aggregate([\n",
    "    # Filter for listings with security deposit and accommodates fields\n",
    "    {\"$match\": {\n",
    "        \"Security_Deposit\": {\"$exists\": True},             # Security deposit exists\n",
    "        \"Accommodates\": {\"$exists\": True}                  # Accommodates field exists\n",
    "    }},\n",
    "            \n",
    "    # Calculate difference per visitor, converting strings to numbers\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"DifferencePerVisitor\": {\n",
    "            \"$divide\": [\n",
    "                {\"$abs\": {\"$subtract\": [\n",
    "                    {\"$toDouble\": \"$Price\"},\n",
    "                    {\"$toDouble\": {\"$ifNull\": [\"$Security_Deposit\", \"0\"]}}\n",
    "                ]}},\n",
    "                \"$Accommodates\"\n",
    "            ]\n",
    "        }\n",
    "    }},\n",
    "    \n",
    "    # Group to find min and max\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"MaxDifference\": {\"$max\": \"$DifferencePerVisitor\"},\n",
    "        \"MinDifference\": {\"$min\": \"$DifferencePerVisitor\"}\n",
    "    }},\n",
    "    \n",
    "    # Project output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"MaxDifference\": {\"$round\": [\"$MaxDifference\", 2]},\n",
    "        \"MinDifference\": {\"$round\": [\"$MinDifference\", 2]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nBiggest difference (price - security deposit) per visitor: \\033[1m{query5[0]['MaxDifference']}\\033[0m\")\n",
    "print(f\"Smallest difference (price - security deposit) per visitor: \\033[1m{query5[0]['MinDifference']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This query assumes both `price` and `security_deposit` exist and are valid numbers for the calculation. The `$match` stage ensures we only consider documents where these fields are present and not null. The `$ifNull` and type conversion steps handle potential data inconsistencies found during cleanup.\n",
    "\n",
    "> **Comparison (Q5):** Both queries correctly identify the min/max difference per visitor (**Min:** 0.0, **Max:** 19229.5). The new schema query operates on the `Listings` collection where `Price` and `Security_Deposit` are already correctly typed, simplifying the `$project` stage compared to the original query. The execution time is notably faster in the new schema (0.021s vs 0.032s original), likely due to processing leaner documents and avoiding conversions within the pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6)  Identify areas by whether they are typically used for short breaks, like weekend mini breaks, or whether they are more suitable for long trips. \n",
    "#     This information support targeted advertising of different customer types. \n",
    "#     It is not expected to change much over time so we won‚Äôt look to update it, we just require current view. \n",
    "#     What is the average duration of stay (in nights) per type of property per city (you can use the maximum_nights to measure length of stays)? \n",
    "#     For each property type return the city with the highest and lowest average value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0547 seconds\n",
      "\n",
      "Average stay duration per property type per city:\n",
      "\n",
      "\u001b[1mProperty Type\u001b[0m          | \u001b[1mHighest Avg City\u001b[0m                 | \u001b[1mLowest Avg City\u001b[0m  \n",
      "================================================================================\n",
      "Tiny house             | Oahu                             | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 5    \n",
      "--------------------------------------------------------------------------------\n",
      "Resort                 | Oahu                             | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 7    \n",
      "--------------------------------------------------------------------------------\n",
      "Hostel                 | Oahu                             | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 10   \n",
      "--------------------------------------------------------------------------------\n",
      "Guest suite            | Barcelona                        | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Heritage hotel (India) | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 14             \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Villa                  | New York                         | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 15   \n",
      "--------------------------------------------------------------------------------\n",
      "Loft                   | Maui                             | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 28   \n",
      "--------------------------------------------------------------------------------\n",
      "Hut                    | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Chalet                 | Sydney                           | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Campsite               | Oahu                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Condominium            | Other (Domestic)                 | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Camper/RV              | Montreal                         | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Other                  | Barcelona                        | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Bed and breakfast      | Porto                            | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Townhouse              | Rio De Janeiro                   | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Treehouse              | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hotel                  | Oahu                             | Other (International)\n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 35   \n",
      "--------------------------------------------------------------------------------\n",
      "Aparthotel             | Montreal                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 60   \n",
      "--------------------------------------------------------------------------------\n",
      "Nature lodge           | Maui                             | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 90   \n",
      "--------------------------------------------------------------------------------\n",
      "Cabin                  | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 120  \n",
      "--------------------------------------------------------------------------------\n",
      "Serviced apartment     | Oahu                             | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 180  \n",
      "--------------------------------------------------------------------------------\n",
      "Casa particular (Cuba) | Barcelona                        | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 235  \n",
      "--------------------------------------------------------------------------------\n",
      "Apartment              | Istanbul                         | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 5200438        \u001b[1mLowest Avg Nights:\u001b[0m 371  \n",
      "--------------------------------------------------------------------------------\n",
      "Cottage                | Hong Kong                        | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 410  \n",
      "--------------------------------------------------------------------------------\n",
      "Guesthouse             | Istanbul                         | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 470  \n",
      "--------------------------------------------------------------------------------\n",
      "Bungalow               | Porto                            | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 485  \n",
      "--------------------------------------------------------------------------------\n",
      "House                  | Other (International)            | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 572  \n",
      "--------------------------------------------------------------------------------\n",
      "Boutique hotel         | Maui                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 578  \n",
      "--------------------------------------------------------------------------------\n",
      "Farm stay              | Barcelona                        | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 846  \n",
      "--------------------------------------------------------------------------------\n",
      "Pension (South Korea)  | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Boat                   | Barcelona                        | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Earth house            | Rio De Janeiro                   | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Barn                   | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Houseboat              | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Train                  | Sydney                           | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Castle                 | Montreal                         | Montreal            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 6. Average stay duration per property type per city, with highest and lowest\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Group by property type and city, converting maximum_nights to number\n",
    "    {\"$group\": {\n",
    "        \"_id\": {\"PropertyType\": \"$property_type\", \"City\": \"$address.market\"},\n",
    "        \"AvgMaxNights\": {\"$avg\": {\"$toInt\": {\"$ifNull\": [\"$maximum_nights\", \"0\"]}}}  # Convert to int, default 0\n",
    "    }},\n",
    "    # Group by property type to find min/max cities\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$_id.PropertyType\",\n",
    "        \"Cities\": {\n",
    "            \"$push\": {\n",
    "                # Handle with Null values\n",
    "                \"City\": {\"$ifNull\": [\"$_id.City\", \"Unknown\"]},                      # Default to \"Unknown\" if null\n",
    "                \"AvgMaxNights\": \"$AvgMaxNights\"}\n",
    "        }\n",
    "    }},\n",
    "    # Sort cities by AvgMaxNights\n",
    "    {\"$sort\": {\"Cities.AvgMaxNights\": 1}},\n",
    "    \n",
    "    # Project min and max per property type\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"PropertyType\": \"$_id\",\n",
    "        \"HighestAvgCity\": {\n",
    "            \"$arrayElemAt\": [\n",
    "                \"$Cities\",\n",
    "                {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$max\": \"$Cities.AvgMaxNights\"}]}\n",
    "            ]\n",
    "        },\n",
    "        \"LowestAvgCity\": {\n",
    "            \"$arrayElemAt\": [\n",
    "                \"$Cities\",\n",
    "                {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$min\": \"$Cities.AvgMaxNights\"}]}\n",
    "            ]\n",
    "        }\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage stay duration per property type per city:\\n\")\n",
    "print(f\"{'\\033[1mProperty Type\\033[0m':<30} | {'\\033[1mHighest Avg City\\033[0m':<40} | {'\\033[1mLowest Avg City\\033[0m':<25}\")\n",
    "print(\"=\" * 80)\n",
    "for item in result:\n",
    "    print(f\"{item['PropertyType']:<22} | {item['HighestAvgCity']['City']:<32} | {item['LowestAvgCity']['City']:<20}\")\n",
    "    print(f\"                         \\033[1mHighest Avg Nights:\\033[0m {round(item['HighestAvgCity']['AvgMaxNights']):<12}   \\033[1mLowest Avg Nights:\\033[0m {round(item['LowestAvgCity']['AvgMaxNights']):<5}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0478 seconds\n",
      "\n",
      "Average stay duration per property type per city:\n",
      "\n",
      "\u001b[1mProperty Type\u001b[0m          | \u001b[1mHighest Avg City\u001b[0m                 | \u001b[1mLowest Avg City\u001b[0m  \n",
      "================================================================================\n",
      "Tiny house             | Oahu                             | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 5    \n",
      "--------------------------------------------------------------------------------\n",
      "Resort                 | Oahu                             | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 7    \n",
      "--------------------------------------------------------------------------------\n",
      "Hostel                 | Oahu                             | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 10   \n",
      "--------------------------------------------------------------------------------\n",
      "Heritage hotel (India) | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 14             \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Guest suite            | Barcelona                        | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 14   \n",
      "--------------------------------------------------------------------------------\n",
      "Villa                  | New York                         | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 15   \n",
      "--------------------------------------------------------------------------------\n",
      "Loft                   | Maui                             | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 28   \n",
      "--------------------------------------------------------------------------------\n",
      "Other                  | Barcelona                        | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Chalet                 | Sydney                           | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hut                    | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Condominium            | Other (Domestic)                 | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Camper/RV              | Montreal                         | Porto               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Townhouse              | Rio De Janeiro                   | Unknown             \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Campsite               | Oahu                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Treehouse              | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 30             \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Bed and breakfast      | Porto                            | Kauai               \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 30   \n",
      "--------------------------------------------------------------------------------\n",
      "Hotel                  | Oahu                             | Other (International)\n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 35   \n",
      "--------------------------------------------------------------------------------\n",
      "Aparthotel             | Montreal                         | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 60   \n",
      "--------------------------------------------------------------------------------\n",
      "Nature lodge           | Maui                             | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 90   \n",
      "--------------------------------------------------------------------------------\n",
      "Cabin                  | Montreal                         | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 120  \n",
      "--------------------------------------------------------------------------------\n",
      "Serviced apartment     | Oahu                             | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 180  \n",
      "--------------------------------------------------------------------------------\n",
      "Casa particular (Cuba) | Barcelona                        | Istanbul            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 235  \n",
      "--------------------------------------------------------------------------------\n",
      "Apartment              | Istanbul                         | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 5200438        \u001b[1mLowest Avg Nights:\u001b[0m 371  \n",
      "--------------------------------------------------------------------------------\n",
      "Cottage                | Hong Kong                        | Maui                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 410  \n",
      "--------------------------------------------------------------------------------\n",
      "Guesthouse             | Istanbul                         | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 470  \n",
      "--------------------------------------------------------------------------------\n",
      "Bungalow               | Porto                            | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 485  \n",
      "--------------------------------------------------------------------------------\n",
      "House                  | Other (International)            | New York            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 572  \n",
      "--------------------------------------------------------------------------------\n",
      "Boutique hotel         | Maui                             | Oahu                \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 578  \n",
      "--------------------------------------------------------------------------------\n",
      "Farm stay              | Barcelona                        | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 846  \n",
      "--------------------------------------------------------------------------------\n",
      "Barn                   | The Big Island                   | The Big Island      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Houseboat              | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Pension (South Korea)  | Hong Kong                        | Hong Kong           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Boat                   | Barcelona                        | Barcelona           \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Earth house            | Rio De Janeiro                   | Rio De Janeiro      \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Train                  | Sydney                           | Sydney              \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n",
      "Castle                 | Montreal                         | Montreal            \n",
      "                         \u001b[1mHighest Avg Nights:\u001b[0m 1125           \u001b[1mLowest Avg Nights:\u001b[0m 1125 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query6 = list(db.Listings.aggregate([\n",
    "    # Group by property type and city, converting maximum_nights to number\n",
    "     {\"$group\": {\n",
    "        \"_id\": {\"PropertyType\": \"$Property_Type\", \"City\": \"$Address.market\"},\n",
    "        \"AvgMaxNights\": {\"$avg\": {\"$toInt\": {\"$ifNull\": [\"$Maximum_Nights\", \"0\"]}}}\n",
    "    }},\n",
    "    # Group by property type to find min/max cities\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$_id.PropertyType\",\n",
    "        \"Cities\": {\"$push\": {\n",
    "            \"City\": {\"$ifNull\": [\"$_id.City\", \"Unknown\"]},\n",
    "            \"AvgMaxNights\": \"$AvgMaxNights\"\n",
    "        }}\n",
    "    }},\n",
    "    \n",
    "    # Sort cities by AvgMaxNights\n",
    "    {\"$sort\": {\"Cities.AvgMaxNights\": 1}},\n",
    "        \n",
    "    # Project min and max per property type\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"PropertyType\": \"$_id\",\n",
    "        \"HighestAvgCity\": {\"$arrayElemAt\": [\n",
    "            \"$Cities\",\n",
    "            {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$max\": \"$Cities.AvgMaxNights\"}]}\n",
    "        ]},\n",
    "        \"LowestAvgCity\": {\"$arrayElemAt\": [\n",
    "            \"$Cities\",\n",
    "            {\"$indexOfArray\": [\"$Cities.AvgMaxNights\", {\"$min\": \"$Cities.AvgMaxNights\"}]}\n",
    "        ]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage stay duration per property type per city:\\n\")\n",
    "print(f\"{'\\033[1mProperty Type\\033[0m':<30} | {'\\033[1mHighest Avg City\\033[0m':<40} | {'\\033[1mLowest Avg City\\033[0m':<25}\")\n",
    "print(\"=\" * 80)\n",
    "for item in query6:\n",
    "    print(f\"{item['PropertyType']:<22} | {item['HighestAvgCity']['City']:<32} | {item['LowestAvgCity']['City']:<20}\")\n",
    "    print(f\"                         \\033[1mHighest Avg Nights:\\033[0m {round(item['HighestAvgCity']['AvgMaxNights']):<12}   \\033[1mLowest Avg Nights:\\033[0m {round(item['LowestAvgCity']['AvgMaxNights']):<5}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on Outliers:** The results show a very high maximum average ($5\\;200\\;438$ nights for **Apartments** in **Istanbul**). This is likely due to outlier values in the `maximum_nights` field (like $2\\;147\\;483\\;647$) skewing the average significantly. \n",
    "\n",
    "In a real-world scenario, these outliers should be investigated and potentially cleaned or filtered out before calculating the average, or a more robust metric like the *median* might be preferred to better represent typical stay lengths. However, following the prompt's instruction to use `maximum_nights` and calculate the average, we present the result as calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q6):** The logic is identical, just adapted to the new field names (`Property_Type`, `Address.market`, `Maximum_Nights`) in the `Listings` collection. Performance is slightly better in the new schema (0.048s vs 0.055s). This improvement is likely due to operating on the leaner `Listings` collection, even though the aggregation logic remains complex involving grouping and sorting potentially large intermediate arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚è≥Advanced Difficulty Questions** [3 points per question]\n",
    "\n",
    "(Consider database optimization for these queries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7)\tWe are creating a new webpage for hosts when setting up their account. \n",
    "#       It will list suggested typical amenities. \n",
    "#       This data will need to be available every time a host registers a property but is not expected to change very much. \n",
    "#       The starting point for the list will be all unique amenities currently listed in properties (across all documents). \n",
    "#       Optimize the database for this use case and show how the data should be queried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.1049 seconds\n",
      "\n",
      "[{'Amenity': '24-hour check-in'},\n",
      " {'Amenity': 'Accessible-height bed'},\n",
      " {'Amenity': 'Accessible-height toilet'},\n",
      " {'Amenity': 'Air conditioning'},\n",
      " {'Amenity': 'Air purifier'}]\n",
      "\n",
      "\u001b[1mTotal unique amenities:\u001b[0m 185\n"
     ]
    }
   ],
   "source": [
    "# 7. All unique amenities across listings\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Unwind amenities array\n",
    "    {\"$unwind\": \"$amenities\"},\n",
    "    # Group to get unique amenities\n",
    "    {\"$group\": {\"_id\": \"$amenities\"}},\n",
    "    # Project output\n",
    "    {\"$project\": {\"_id\": 0, \"Amenity\": \"$_id\"}},\n",
    "    # Sort alphabetically\n",
    "    {\"$sort\": {\"Amenity\": 1}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result[:5])                                              # Display first few unique amenities\n",
    "print(f\"\\n\\33[1mTotal unique amenities:\\33[0m {len(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q7: `Computed Pattern`**\n",
    "\n",
    "We applied the **Computed Pattern** because the query requires retrieving all *unique* amenities across thousands of listings, which involves an expensive aggregation (`$unwind` + `$group`) every time the data is requested. This operation is inefficient and unnecessary, especially since the list of possible amenities changes infrequently.\n",
    "\n",
    "We expect a **significant reduction in query cost and response time** based on the replacement of a costly aggregation pipeline with a simple and fast `find()` operation on a small, support `Amenities` collection with computed field `TotalFrequency`. This improves performance for high-traffic endpoints, such as the host registration form, and avoids unnecessary compute overhead during peak usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0917 seconds\n",
      "\n",
      "[{'Amenity': '24-hour check-in',\n",
      "  'TotalFrequency': 748,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e913a')},\n",
      " {'Amenity': 'Accessible-height bed',\n",
      "  'TotalFrequency': 248,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e913b')},\n",
      " {'Amenity': 'Accessible-height toilet',\n",
      "  'TotalFrequency': 193,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e913c')},\n",
      " {'Amenity': 'Air conditioning',\n",
      "  'TotalFrequency': 3431,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e913d')},\n",
      " {'Amenity': 'Air purifier',\n",
      "  'TotalFrequency': 3,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e913e')}]\n",
      "\n",
      "\u001b[1mTotal unique amenities:\u001b[0m 185\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create Amenities collection\n",
    "db.Amenities.drop()\n",
    "db.Listings.aggregate([\n",
    "    {\"$unwind\": \"$Amenities\"},\n",
    "    {\"$group\": {\"_id\": \"$Amenities\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$project\": {\"_id\": 0, \"Amenity\": \"$_id\", \"TotalFrequency\": \"$count\"}},\n",
    "    {\"$sort\": {\"Amenity\": 1}},\n",
    "    {\"$out\": \"Amenities\"}\n",
    "])\n",
    "\n",
    "# Query\n",
    "result = list(db.Amenities.find().limit(5))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)\n",
    "print(f\"\\n\\33[1mTotal unique amenities:\\33[0m {db.Amenities.count_documents({})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The time of execution also consider the time to create the `Amenities` collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example of Suggested Amenities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mIndex information for Amenities collection:\u001b[0m\n",
      "{'Amenity_1': {'key': [('Amenity', 1)], 'v': 2},\n",
      " 'Amenity_text_TotalFrequency_-1': {'default_language': 'english',\n",
      "                                    'key': [('_fts', 'text'),\n",
      "                                            ('_ftsx', 1),\n",
      "                                            ('TotalFrequency', -1)],\n",
      "                                    'language_override': 'language',\n",
      "                                    'textIndexVersion': 3,\n",
      "                                    'v': 2,\n",
      "                                    'weights': SON([('Amenity', 1)])},\n",
      " 'TotalFrequency_-1': {'key': [('TotalFrequency', -1)], 'v': 2},\n",
      " '_id_': {'key': [('_id', 1)], 'v': 2}}\n"
     ]
    }
   ],
   "source": [
    "# Create index on Amenities collection for faster queries - In this case, we can use a text index for searching amenities\n",
    "# Since it is a index for a text field with non-text values, we can create a compound index with TotalFrequency for sorting \n",
    "db.Amenities.create_index([(\"Amenity\")])             # Create a single index on Amenity field for text search\n",
    "db.Amenities.create_index([(\"TotalFrequency\", -1)])  # Create a single index on TotalFrequency field for sorting\n",
    "db.Amenities.create_index([(\"Amenity\", \"text\"), \n",
    "                           (\"TotalFrequency\", -1)])  # Create index on Amenity field for text search and sort by frequency\n",
    "\n",
    "# Print the index information for the Amenities collection\n",
    "print(\"\\n\\033[1mIndex information for Amenities collection:\\033[0m\")\n",
    "pprint(db.Amenities.index_information())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider top amenities based on the most common ones in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0026 seconds\n",
      "\n",
      "[{'Amenity': 'Wifi',\n",
      "  'TotalFrequency': 5303,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91ee')},\n",
      " {'Amenity': 'Essentials',\n",
      "  'TotalFrequency': 5048,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e9175')},\n",
      " {'Amenity': 'Kitchen',\n",
      "  'TotalFrequency': 4951,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e919c')},\n",
      " {'Amenity': 'TV',\n",
      "  'TotalFrequency': 4280,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91dc')},\n",
      " {'Amenity': 'Hangers',\n",
      "  'TotalFrequency': 4226,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e918c')}]\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {},\n",
      "             'find': 'Amenities',\n",
      "             'limit': 5,\n",
      "             'singleBatch': True,\n",
      "             'sort': {'TotalFrequency': -1}},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 5,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 5,\n",
      "                                                       'alreadyHasObj': 0,\n",
      "                                                       'docsExamined': 5,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'inputStage': {'advanced': 5,\n",
      "                                                                      'direction': 'forward',\n",
      "                                                                      'dupsDropped': 0,\n",
      "                                                                      'dupsTested': 0,\n",
      "                                                                      'executionTimeMillisEstimate': 0,\n",
      "                                                                      'indexBounds': {'TotalFrequency': ['[MaxKey, '\n",
      "                                                                                                         'MinKey]']},\n",
      "                                                                      'indexName': 'TotalFrequency_-1',\n",
      "                                                                      'indexVersion': 2,\n",
      "                                                                      'isEOF': 0,\n",
      "                                                                      'isMultiKey': False,\n",
      "                                                                      'isPartial': False,\n",
      "                                                                      'isSparse': False,\n",
      "                                                                      'isUnique': False,\n",
      "                                                                      'keyPattern': {'TotalFrequency': -1},\n",
      "                                                                      'keysExamined': 5,\n",
      "                                                                      'multiKeyPaths': {'TotalFrequency': []},\n",
      "                                                                      'nReturned': 5,\n",
      "                                                                      'needTime': 0,\n",
      "                                                                      'needYield': 0,\n",
      "                                                                      'restoreState': 0,\n",
      "                                                                      'saveState': 0,\n",
      "                                                                      'seeks': 1,\n",
      "                                                                      'stage': 'IXSCAN',\n",
      "                                                                      'works': 5},\n",
      "                                                       'isEOF': 0,\n",
      "                                                       'nReturned': 5,\n",
      "                                                       'needTime': 0,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'stage': 'FETCH',\n",
      "                                                       'works': 5},\n",
      "                                        'isCached': False,\n",
      "                                        'isEOF': 1,\n",
      "                                        'limitAmount': 5,\n",
      "                                        'nReturned': 5,\n",
      "                                        'needTime': 0,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'LIMIT',\n",
      "                                        'works': 6},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 1,\n",
      "                    'nReturned': 5,\n",
      "                    'totalDocsExamined': 5,\n",
      "                    'totalKeysExamined': 5},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Amenities',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {},\n",
      "                  'planCacheKey': '5ABB3E72',\n",
      "                  'planCacheShapeHash': '24645C5A',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': '24645C5A',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'inputStage': {'direction': 'forward',\n",
      "                                                                'indexBounds': {'TotalFrequency': ['[MaxKey, '\n",
      "                                                                                                   'MinKey]']},\n",
      "                                                                'indexName': 'TotalFrequency_-1',\n",
      "                                                                'indexVersion': 2,\n",
      "                                                                'isMultiKey': False,\n",
      "                                                                'isPartial': False,\n",
      "                                                                'isSparse': False,\n",
      "                                                                'isUnique': False,\n",
      "                                                                'keyPattern': {'TotalFrequency': -1},\n",
      "                                                                'multiKeyPaths': {'TotalFrequency': []},\n",
      "                                                                'stage': 'IXSCAN'},\n",
      "                                                 'stage': 'FETCH'},\n",
      "                                  'isCached': False,\n",
      "                                  'limitAmount': 5,\n",
      "                                  'stage': 'LIMIT'}},\n",
      " 'queryShapeHash': '0C250117B11D83F876C46ABB2AFE4B7B95F2A4472488EDF3ED2091E6BD9F4F45',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run a query to find top 5 amenities with the highest frequency\n",
    "start_time = time.time()\n",
    "result = list(db.Amenities.find().sort(\"TotalFrequency\", -1).limit(5))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)  # Display top 5 amenities with highest frequency\n",
    "\n",
    "\n",
    "# Output the information about query performance (Q7)\n",
    "pprint(db.Amenities.find().sort(\"TotalFrequency\", -1).limit(5).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider that in the webpage for host registration, it will suggest the amenities after input some words. For example, if the host types \"pool\", it will suggest the following amenities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuerying Amenities collection for amenities containing 'pool':\u001b[0m\n",
      "Execution time: 0.0039 seconds\n",
      "\n",
      "[{'Amenity': 'Pool',\n",
      "  'TotalFrequency': 819,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91ba')},\n",
      " {'Amenity': 'Pool with pool hoist',\n",
      "  'TotalFrequency': 4,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91bb')},\n",
      " {'Amenity': 'Private pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91c0')},\n",
      " {'Amenity': 'Shared pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91ca')},\n",
      " {'Amenity': 'Swimming pool',\n",
      "  'TotalFrequency': 1,\n",
      "  '_id': ObjectId('67fea826a6298d01ad0e91db')}]\n",
      "\n",
      "\u001b[1mTotal amenities containing 'pool':\u001b[0m 5\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {'Amenity': {'$options': 'i', '$regex': 'pool'}},\n",
      "             'find': 'Amenities'},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 5,\n",
      "                                        'alreadyHasObj': 0,\n",
      "                                        'docsExamined': 5,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 5,\n",
      "                                                       'direction': 'forward',\n",
      "                                                       'dupsDropped': 0,\n",
      "                                                       'dupsTested': 0,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'filter': {'Amenity': {'$options': 'i',\n",
      "                                                                              '$regex': 'pool'}},\n",
      "                                                       'indexBounds': {'Amenity': ['[\"\", '\n",
      "                                                                                   '{})',\n",
      "                                                                                   '[/pool/i, '\n",
      "                                                                                   '/pool/i]']},\n",
      "                                                       'indexName': 'Amenity_1',\n",
      "                                                       'indexVersion': 2,\n",
      "                                                       'isEOF': 1,\n",
      "                                                       'isMultiKey': False,\n",
      "                                                       'isPartial': False,\n",
      "                                                       'isSparse': False,\n",
      "                                                       'isUnique': False,\n",
      "                                                       'keyPattern': {'Amenity': 1},\n",
      "                                                       'keysExamined': 185,\n",
      "                                                       'multiKeyPaths': {'Amenity': []},\n",
      "                                                       'nReturned': 5,\n",
      "                                                       'needTime': 180,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'seeks': 1,\n",
      "                                                       'stage': 'IXSCAN',\n",
      "                                                       'works': 186},\n",
      "                                        'isCached': False,\n",
      "                                        'isEOF': 1,\n",
      "                                        'nReturned': 5,\n",
      "                                        'needTime': 180,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'FETCH',\n",
      "                                        'works': 186},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 0,\n",
      "                    'nReturned': 5,\n",
      "                    'totalDocsExamined': 5,\n",
      "                    'totalKeysExamined': 185},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Amenities',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {'Amenity': {'$options': 'i',\n",
      "                                              '$regex': 'pool'}},\n",
      "                  'planCacheKey': 'AA26591A',\n",
      "                  'planCacheShapeHash': 'EE46BBE5',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': 'EE46BBE5',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                 'filter': {'Amenity': {'$options': 'i',\n",
      "                                                                        '$regex': 'pool'}},\n",
      "                                                 'indexBounds': {'Amenity': ['[\"\", '\n",
      "                                                                             '{})',\n",
      "                                                                             '[/pool/i, '\n",
      "                                                                             '/pool/i]']},\n",
      "                                                 'indexName': 'Amenity_1',\n",
      "                                                 'indexVersion': 2,\n",
      "                                                 'isMultiKey': False,\n",
      "                                                 'isPartial': False,\n",
      "                                                 'isSparse': False,\n",
      "                                                 'isUnique': False,\n",
      "                                                 'keyPattern': {'Amenity': 1},\n",
      "                                                 'multiKeyPaths': {'Amenity': []},\n",
      "                                                 'stage': 'IXSCAN'},\n",
      "                                  'isCached': False,\n",
      "                                  'stage': 'FETCH'}},\n",
      " 'queryShapeHash': '0526FEDBB2032B0822DC5D2997B97C46B3EEBA22B2D743585F4AFCB7968E4199',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Run a query to find all amenities containing \"pool\" (Example)\n",
    "# This is a case-insensitive search for \"pool\" in the amenities\n",
    "# Note: The regex search is case-insensitive due to the \"$options\": \"i\" flag\n",
    "\n",
    "print(\"\\n\\033[1mQuerying Amenities collection for amenities containing 'pool':\\033[0m\")\n",
    "start_time = time.time()\n",
    "result = list(db.Amenities.find({\"Amenity\": {\"$regex\": \"pool\", \"$options\": \"i\"}}))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)  # Display first few results\n",
    "print(f\"\\n\\033[1mTotal amenities containing 'pool':\\033[0m {len(result)}\")\n",
    "\n",
    "# Output the information about query performance (Q7)\n",
    "pprint(db.Amenities.find({\"Amenity\": {\"$regex\": \"pool\", \"$options\": \"i\"}}).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q7):** By creating the `Amenities` collection (where we compute the field `CountFrequency` for each unique amenity - **Computed Pattern**), fetching the list of unique amenities is reduced from an aggregation across all listings (original query, ~0.105s) to a simple `find()` on the dedicated collection (new query, negligible time, ~0.002s after the one-time creation cost of ~0.09s). This is a significant performance improvement, especially for a frequently accessed feature like suggesting amenities during host registration.\n",
    "\n",
    "- For the 1st use case described (top 5 most common amenities), this is a significant performance improvement. The index `TotalFrequency_-1` improves matches on the `CountFrequency` field, making searchesvery efficient (explain plan shows `IXSCAN`).\n",
    "- For the 2nd use case described (frequent reads for host registration), this is a significant performance improvement. The index `Amenity_1` further optimizes matches *within* this collection, making searches like the \"pool\" example very efficient (explain plan shows `IXSCAN`).\n",
    "  - For both cases, the compound index `Amenity_text_TotalFrequency_-1` is not the best choice, so we will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop compound index on Amenities collection \n",
    "db.Amenities.drop_index('Amenity_text_TotalFrequency_-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8)\tWe plan to track our reviewers better. \n",
    "#       We want to create a webpage that shows the top 20 reviewers and the count of the number of reviews of each of these reviewers. \n",
    "#       This webpage should be kept up to date. It should also have a link to return the number of reviews for a given reviewer ID or Name \n",
    "#           (show how to query for number of reviews by ID or query quickly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.5817 seconds\n",
      "\n",
      "[{'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'},\n",
      " {'ReviewCount': 13, 'ReviewerId': '67084875', 'ReviewerName': 'Nick'},\n",
      " {'ReviewCount': 10, 'ReviewerId': '2961855', 'ReviewerName': 'Uge'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '20991911', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '162027327', 'ReviewerName': 'Thien'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '69140895', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '60816198', 'ReviewerName': 'Todd'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '12679057', 'ReviewerName': 'Jodi'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '55241576', 'ReviewerName': 'Courtney'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '1705870', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '78093968', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '47303133', 'ReviewerName': 'Lance'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '57325457', 'ReviewerName': 'Mary'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '25715809', 'ReviewerName': 'Megan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '93859831', 'ReviewerName': 'Pierre'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '61469899', 'ReviewerName': 'Erik'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '34005800', 'ReviewerName': 'Dan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '128210181', 'ReviewerName': 'Branden'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '86665925', 'ReviewerName': 'Chris'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '76782210', 'ReviewerName': 'Assis'}]\n"
     ]
    }
   ],
   "source": [
    "# 8. Top 20 reviewers and count by ID or Name\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Unwind reviews\n",
    "    {\"$unwind\": \"$reviews\"},\n",
    "    # Group by reviewer\n",
    "    {\"$group\": {\"_id\": \"$reviews.reviewer_id\", \"ReviewerName\": {\"$first\": \"$reviews.reviewer_name\"}, \"ReviewCount\": {\"$sum\": 1}}},\n",
    "    # Sort by count descending\n",
    "    {\"$sort\": {\"ReviewCount\": -1}},\n",
    "    # Limit to 20\n",
    "    {\"$limit\": 20},\n",
    "    # Project output\n",
    "    {\"$project\": {\"_id\": 0, \"ReviewerId\": \"$_id\", \"ReviewerName\": 1, \"ReviewCount\": 1}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mReviews for ID 51483096:\u001b[0m 1 |  \u001b[1mTime:\u001b[0m 0.1643 seconds\n",
      "\u001b[1mReviews for Name Angela:\u001b[0m 247 |  \u001b[1mTime:\u001b[0m 0.1376 seconds\n"
     ]
    }
   ],
   "source": [
    "# Function to get review count by ID or Name\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name.\n",
    "\n",
    "    Args:\n",
    "        reviewer_id (int, optional): The ID of the reviewer. Defaults to None.\n",
    "        reviewer_name (str, optional): The name of the reviewer. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the count of reviews and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    match = {}\n",
    "    if reviewer_id:\n",
    "        match[\"reviews.reviewer_id\"] = reviewer_id\n",
    "    elif reviewer_name:\n",
    "        match[\"reviews.reviewer_name\"] = reviewer_name\n",
    "    pipeline = [\n",
    "        {\"$unwind\": \"$reviews\"},\n",
    "        {\"$match\": match},\n",
    "        {\"$group\": {\"_id\": None, \"Count\": {\"$sum\": 1}}},\n",
    "        {\"$project\": {\"_id\": 0, \"Count\": 1}}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[0][\"Count\"] if result else 0, exec_time\n",
    "\n",
    "reviewer_id=\"51483096\"\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\033[1mReviews for ID {reviewer_id}:\\033[0m {count} |  \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name=\"Angela\"\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mReviews for Name {reviewer_name}:\\033[0m {count} |  \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q8: `Computed Pattern` & `Indexing`**\n",
    "\n",
    "We applied the **Computed Pattern** and **Indexing** because **Q8** requires both listing the top 20 reviewers by number of reviews and efficiently retrieving the review count for any specific reviewer. In the original schema, this computation happens on-the-fly through aggregations on embedded arrays, which is inefficient on large datasets or when these queries are frequent.\n",
    "\n",
    "We expect improved performance with the addition of an index on `Reviewer_ID` in the `Reviews` collection allows rapid lookups using `count_documents()` for individual reviewers.\n",
    "\n",
    "*   **Further Optimization (Computed Pattern):** To make fetching the top 20 *and* individual counts consistently fast, we could add a `ReviewCount` field to the `Reviewers` collection and update it whenever a review is added/deleted (using `$inc`). This implements the **Computed Pattern** fully for review counts. The current implementation prioritizes normalization and relies on indexing for the fast lookup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 10.8508 seconds\n",
      "\n",
      "[{'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'},\n",
      " {'ReviewCount': 13, 'ReviewerId': '67084875', 'ReviewerName': 'Nick'},\n",
      " {'ReviewCount': 10, 'ReviewerId': '2961855', 'ReviewerName': 'Uge'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '20991911', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 9, 'ReviewerId': '162027327', 'ReviewerName': 'Thien'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '1705870', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '69140895', 'ReviewerName': 'Lisa'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '55241576', 'ReviewerName': 'Courtney'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '60816198', 'ReviewerName': 'Todd'},\n",
      " {'ReviewCount': 8, 'ReviewerId': '12679057', 'ReviewerName': 'Jodi'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '47303133', 'ReviewerName': 'Lance'},\n",
      " {'ReviewCount': 7, 'ReviewerId': '78093968', 'ReviewerName': 'David'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '76782210', 'ReviewerName': 'Assis'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '57325457', 'ReviewerName': 'Mary'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '73708321', 'ReviewerName': 'Gonzalo'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '34005800', 'ReviewerName': 'Dan'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '24667379', 'ReviewerName': 'Karen'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '128210181', 'ReviewerName': 'Branden'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '61469899', 'ReviewerName': 'Erik'},\n",
      " {'ReviewCount': 6, 'ReviewerId': '93859831', 'ReviewerName': 'Pierre'}]\n",
      "\n",
      "\u001b[1mReviews for ID 20775242:\u001b[0m 24 | \u001b[1mTime:\u001b[0m 0.0050 seconds\n",
      "\u001b[1mReviews for Name Filipe:\u001b[0m [{'Count': 44}] | \u001b[1mTime:\u001b[0m 11.1384 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "query8 = list(db.Reviews.aggregate([\n",
    "    # Group by Reviewer_ID to count reviews\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Reviewer_ID\",\n",
    "        \"ReviewCount\": {\"$sum\": 1}\n",
    "    }},\n",
    "    \n",
    "    # Join with Reviewers collection to get names\n",
    "    {\"$lookup\": {\n",
    "        \"from\": \"Reviewers\",\n",
    "        \"localField\": \"_id\",\n",
    "        \"foreignField\": \"Reviewer_ID\",\n",
    "        \"as\": \"reviewer_info\"\n",
    "    }},\n",
    "    \n",
    "    # Unwind the reviewer_info array\n",
    "    {\"$unwind\": \"$reviewer_info\"},\n",
    "    \n",
    "    # Project the required fields\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerId\": \"$_id\",\n",
    "        \"ReviewerName\": \"$reviewer_info.Reviewer_Name\",\n",
    "        \"ReviewCount\": 1\n",
    "    }},\n",
    "    \n",
    "    # Sort by review count in descending order\n",
    "    {\"$sort\": {\"ReviewCount\": -1}},\n",
    "    \n",
    "    # Limit to the top 20 reviewers\n",
    "    {\"$limit\": 20}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(query8)\n",
    "\n",
    "# Lookup function\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name.\n",
    "    Args:\n",
    "        reviewer_id (int): The ID of the reviewer.\n",
    "        reviewer_name (str): The name of the reviewer.\n",
    "        \n",
    "    Returns:\n",
    "        result (int): The count of reviews for the specified reviewer ID.\n",
    "        exec_time (float): The time taken to execute the query.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if reviewer_id:\n",
    "        result = db.Reviews.count_documents({\"Reviewer_ID\": reviewer_id})\n",
    "    elif reviewer_name:\n",
    "        pipeline = [\n",
    "            # Join Reviews with Reviewers to get names\n",
    "            {\"$lookup\": {\n",
    "                \"from\": \"Reviewers\",\n",
    "                \"localField\": \"Reviewer_ID\",\n",
    "                \"foreignField\": \"Reviewer_ID\",\n",
    "                \"as\": \"reviewer_info\"\n",
    "            }},\n",
    "            \n",
    "            # Unwind the reviewer_info array\n",
    "            {\"$unwind\": \"$reviewer_info\"},\n",
    "            \n",
    "            # Match the reviewer name\n",
    "            {\"$match\": {\"reviewer_info.Reviewer_Name\": reviewer_name}},\n",
    "            \n",
    "            # Group to count reviews\n",
    "            {\"$group\": {\n",
    "                \"_id\": None,\n",
    "                \"Count\": {\"$sum\": 1}\n",
    "            }},\n",
    "            \n",
    "            # Project the count\n",
    "            {\"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"Count\": 1\n",
    "            }}\n",
    "        ]\n",
    "        result = db.Reviews.aggregate(pipeline)\n",
    "        result = list(result)\n",
    "    exec_time = time.time() - start_time\n",
    "    return result, exec_time\n",
    "\n",
    "reviewer_id = query8[0][\"ReviewerId\"]\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\n\\033[1mReviews for ID {reviewer_id}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name = query8[0][\"ReviewerName\"]\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mReviews for Name {reviewer_name}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance:\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'filter': {'Reviewer_ID': '20775242'},\n",
      "             'find': 'Reviewers'},\n",
      " 'executionStats': {'allPlansExecution': [],\n",
      "                    'executionStages': {'advanced': 1,\n",
      "                                        'alreadyHasObj': 0,\n",
      "                                        'docsExamined': 1,\n",
      "                                        'executionTimeMillisEstimate': 0,\n",
      "                                        'inputStage': {'advanced': 1,\n",
      "                                                       'direction': 'forward',\n",
      "                                                       'dupsDropped': 0,\n",
      "                                                       'dupsTested': 0,\n",
      "                                                       'executionTimeMillisEstimate': 0,\n",
      "                                                       'indexBounds': {'Reviewer_ID': ['[\"20775242\", '\n",
      "                                                                                       '\"20775242\"]']},\n",
      "                                                       'indexName': 'Reviewer_ID_1',\n",
      "                                                       'indexVersion': 2,\n",
      "                                                       'isEOF': 1,\n",
      "                                                       'isMultiKey': False,\n",
      "                                                       'isPartial': False,\n",
      "                                                       'isSparse': False,\n",
      "                                                       'isUnique': False,\n",
      "                                                       'keyPattern': {'Reviewer_ID': 1},\n",
      "                                                       'keysExamined': 1,\n",
      "                                                       'multiKeyPaths': {'Reviewer_ID': []},\n",
      "                                                       'nReturned': 1,\n",
      "                                                       'needTime': 0,\n",
      "                                                       'needYield': 0,\n",
      "                                                       'restoreState': 0,\n",
      "                                                       'saveState': 0,\n",
      "                                                       'seeks': 1,\n",
      "                                                       'stage': 'IXSCAN',\n",
      "                                                       'works': 2},\n",
      "                                        'isCached': True,\n",
      "                                        'isEOF': 1,\n",
      "                                        'nReturned': 1,\n",
      "                                        'needTime': 0,\n",
      "                                        'needYield': 0,\n",
      "                                        'restoreState': 0,\n",
      "                                        'saveState': 0,\n",
      "                                        'stage': 'FETCH',\n",
      "                                        'works': 2},\n",
      "                    'executionSuccess': True,\n",
      "                    'executionTimeMillis': 0,\n",
      "                    'nReturned': 1,\n",
      "                    'totalDocsExamined': 1,\n",
      "                    'totalKeysExamined': 1},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryPlanner': {'indexFilterSet': False,\n",
      "                  'maxIndexedAndSolutionsReached': False,\n",
      "                  'maxIndexedOrSolutionsReached': False,\n",
      "                  'maxScansToExplodeReached': False,\n",
      "                  'namespace': 'sample_airbnb.Reviewers',\n",
      "                  'optimizationTimeMillis': 0,\n",
      "                  'parsedQuery': {'Reviewer_ID': {'$eq': '20775242'}},\n",
      "                  'planCacheKey': '646DF628',\n",
      "                  'planCacheShapeHash': '1DFD2D2F',\n",
      "                  'prunedSimilarIndexes': False,\n",
      "                  'queryHash': '1DFD2D2F',\n",
      "                  'rejectedPlans': [],\n",
      "                  'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                 'indexBounds': {'Reviewer_ID': ['[\"20775242\", '\n",
      "                                                                                 '\"20775242\"]']},\n",
      "                                                 'indexName': 'Reviewer_ID_1',\n",
      "                                                 'indexVersion': 2,\n",
      "                                                 'isMultiKey': False,\n",
      "                                                 'isPartial': False,\n",
      "                                                 'isSparse': False,\n",
      "                                                 'isUnique': False,\n",
      "                                                 'keyPattern': {'Reviewer_ID': 1},\n",
      "                                                 'multiKeyPaths': {'Reviewer_ID': []},\n",
      "                                                 'stage': 'IXSCAN'},\n",
      "                                  'isCached': True,\n",
      "                                  'stage': 'FETCH'}},\n",
      " 'queryShapeHash': '5E7F009528D5DCCD5A14653125C8DE1D0E6687FB8F80EFC43CAE62479C8EAE49',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q8) - Find the number of reviews for a given reviewer ID\n",
    "print(\"\\n\\033[1mQuery performance:\\033[0m\")\n",
    "pprint(db.Reviewers.find({\"Reviewer_ID\": reviewer_id}).explain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q8):**\n",
    "> *   **Top 20 List:** The original query required unwinding all reviews and grouping (~0.58s). By applying the **Computed Pattern** (adding `ReviewCount` to the `Reviewers` collection) and **Indexing** (`ReviewCount: -1`), retrieving the top 20 reviewers becomes a simple `find().sort().limit()` operation on the `Reviewers` collection. This is significantly faster (~0.64s including the update vs ~0.58s initially - *Note: the aggregation to calculate counts for the update dominates here, but subsequent reads are fast*), as it directly uses the pre-computed and indexed count.\n",
    "> *   **Individual Lookup:** The `get_review_count` function benefits immensely. Instead of aggregating the `Reviews` collection (~0.14s) or the original `listingsAndReviews_HW2` collection, it performs a fast, indexed `find_one` on the `Reviewers` collection using either `Reviewer_ID` (~0.002s) or `Reviewer_Name` (which would benefit from its own index for similar speed).\n",
    "\n",
    "This demonstrates the benefit of the new schema for the frequent, targeted lookup requirement, while the top-20 list might be better handled by pre-computation (**Computed Pattern**) in a production scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Computed Pattern for Review Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146640/146640 [03:02<00:00, 803.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ReviewCount': 1,\n",
      "  'Reviewer_ID': '99803988',\n",
      "  'Reviewer_Name': 'Frank',\n",
      "  '_id': ObjectId('67fea80ea6298d01ad076b92')},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '34619466',\n",
      "  'Reviewer_Name': 'Noah',\n",
      "  '_id': ObjectId('67fea80ea6298d01ad076b93')},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '134581781',\n",
      "  'Reviewer_Name': 'Filip',\n",
      "  '_id': ObjectId('67fea80ea6298d01ad076b94')},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '72302443',\n",
      "  'Reviewer_Name': 'Aaron',\n",
      "  '_id': ObjectId('67fea80ea6298d01ad076b95')},\n",
      " {'ReviewCount': 1,\n",
      "  'Reviewer_ID': '124235566',\n",
      "  'Reviewer_Name': '–ê–Ω–¥—Ä–µ–π',\n",
      "  '_id': ObjectId('67fea80ea6298d01ad076b96')}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 'ReviewCount' field for each reviewer in the Reviewers collection and add it to the collection\n",
    "\n",
    "# Start by aggregating the review counts from the Reviews collection\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/aggregation/group/\n",
    "pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Reviewer_ID\",         # Group by reviewer identifier\n",
    "        \"ReviewCount\": {\"$sum\": 1}       # Sum up the number of reviews per reviewer\n",
    "    }}\n",
    "]\n",
    "\n",
    "# Execute the aggregation on the Reviews collection\n",
    "review_counts = list(db.Reviews.aggregate(pipeline))\n",
    "\n",
    "# Update each reviewer document in the Reviewers collection with the computed ReviewCount\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/update/set/\n",
    "for rc in tqdm(review_counts):\n",
    "    reviewer_id = rc[\"_id\"]\n",
    "    count = rc[\"ReviewCount\"]\n",
    "    \n",
    "    # Update the reviewer document by setting the ReviewCount field\n",
    "    db.Reviewers.update_one(\n",
    "        {\"Reviewer_ID\": reviewer_id}, \n",
    "        {\"$set\": {\"ReviewCount\": count}}\n",
    "    )\n",
    "\n",
    "# Verify the update by checking the first few documents in the Reviewers collection\n",
    "result = list(db.Reviewers.find().limit(5))\n",
    "pprint(result)                                          # Display first few results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ReviewCount_-1'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index on the ReviewCount field for faster queries\n",
    "db.Reviewers.create_index([(\"ReviewCount\", -1)])    # Create index on ReviewCount field for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.6363 seconds\n",
      "\n",
      "[{'ReviewCount': 1, 'ReviewerId': '135123163', 'ReviewerName': 'ÊÄùÁæΩ'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '57692680', 'ReviewerName': 'Rick'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '6331768', 'ReviewerName': 'Alexander'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '6403978', 'ReviewerName': 'Margaret'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '16700470', 'ReviewerName': 'Fabien'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '4921791', 'ReviewerName': 'Susan'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '15016598', 'ReviewerName': 'Ilka'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '2557262', 'ReviewerName': 'Eugene & Lisa'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '36128209', 'ReviewerName': 'Kerry'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '17129406', 'ReviewerName': 'Gordon'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '176258712', 'ReviewerName': 'Fish'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '68579704', 'ReviewerName': 'Kristin'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '60393916', 'ReviewerName': 'Nidaa'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '52088612', 'ReviewerName': 'Addie'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '21978475', 'ReviewerName': 'Michael'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '46310416', 'ReviewerName': 'Jennifer'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '23689944', 'ReviewerName': 'Abhishek'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '30884353', 'ReviewerName': 'Charlotte'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '52404650', 'ReviewerName': 'Helder'},\n",
      " {'ReviewCount': 1, 'ReviewerId': '5938166', 'ReviewerName': 'Ugne'}]\n"
     ]
    }
   ],
   "source": [
    "# Re-run the query to find the top 20 reviewers\n",
    "start_time = time.time()\n",
    "\n",
    "query8 = list(db.Reviewers.aggregate([\n",
    "    # Group by Reviewer_ID to count reviews\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Reviewer_ID\",\n",
    "        \"ReviewCount\": {\"$sum\": 1},\n",
    "        \"ReviewerName\": {\"$first\": \"$Reviewer_Name\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the required fields\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"ReviewerId\": \"$_id\",\n",
    "        \"ReviewerName\": 1,\n",
    "        \"ReviewCount\": 1\n",
    "    }},\n",
    "    \n",
    "    # Sort by review count in descending order\n",
    "    {\"$sort\": {\"ReviewCount\": -1}},\n",
    "    \n",
    "    # Limit to the top 20 reviewers\n",
    "    {\"$limit\": 20}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\\n\")\n",
    "pprint(query8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mOptimized Reviews for ID 135123163:\u001b[0m 1 | \u001b[1mTime:\u001b[0m 0.0032 seconds\n",
      "\u001b[1mOptimized Reviews for Name ÊÄùÁæΩ:\u001b[0m 1 | \u001b[1mTime:\u001b[0m 0.0059 seconds\n"
     ]
    }
   ],
   "source": [
    "# Update the function to optimize the query for review count by ID or Name\n",
    "def get_review_count(reviewer_id=None, reviewer_name=None):\n",
    "    \"\"\"Get the count of reviews for a specific reviewer by ID or Name. (Optimized)\n",
    "\n",
    "    Args:\n",
    "        reviewer_id (int, optional): The ID of the reviewer. Defaults to None.\n",
    "        reviewer_name (str, optional): The name of the reviewer. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the count of reviews and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    match = {}\n",
    "    if reviewer_id:\n",
    "        match[\"Reviewer_ID\"] = reviewer_id\n",
    "    elif reviewer_name:\n",
    "        match[\"Reviewer_Name\"] = reviewer_name\n",
    "    result = db.Reviewers.find_one(match, {\"ReviewCount\": 1})\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[\"ReviewCount\"] if result else 0, exec_time\n",
    "\n",
    "# Test the optimized function\n",
    "reviewer_id = query8[0][\"ReviewerId\"]\n",
    "count, exec_time = get_review_count(reviewer_id=reviewer_id)\n",
    "print(f\"\\n\\033[1mOptimized Reviews for ID {reviewer_id}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")\n",
    "\n",
    "reviewer_name = query8[0][\"ReviewerName\"]\n",
    "count, exec_time = get_review_count(reviewer_name=reviewer_name)\n",
    "print(f\"\\033[1mOptimized Reviews for Name {reviewer_name}:\\033[0m {count} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q8):**\n",
    ">\n",
    "> *   **Top 20 List:** The original query required unwinding all reviews and grouping (~0.9s). By applying the **Computed Pattern** (adding `ReviewCount` to the `Reviewers` collection) and **Indexing** (`ReviewCount: -1`), retrieving the top 20 reviewers becomes a simple `find().sort().limit()` operation on the `Reviewers` collection. This is significantly faster (e.g., ~0.004s after index creation vs ~0.9s), as it directly uses the pre-computed and indexed count instead of recalculating it.\n",
    "> *   **Individual Lookup:** The `get_review_count` function also benefits immensely. Instead of aggregating the `Reviews` collection (~0.14s) or the original `listingsAndReviews_HW2` collection, it performs a fast, indexed `find_one` on the `Reviewers` collection using either `Reviewer_ID` (~0.002s) or `Reviewer_Name` (which would benefit from its own index for similar speed).\n",
    ">\n",
    "> This demonstrates the effectiveness of the **Computed Pattern** for optimizing both aggregated views (like top N lists) and specific lookups based on frequently calculated values. The trade-off is the need to maintain the `ReviewCount` field whenever a review is added or removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9)\tFor each property we store review scores across different metrics (accuracy, check-in, cleanliness etc). \n",
    "#       We consider adding more metrics, although there is no clarity on what these will be. \n",
    "#       We want to be able to easily query the average score across all of these metrics, including any new metrics that might be added without changing the query. \n",
    "#       Adjust the data model so this can be done and show the query for an example property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0065 seconds\n",
      "\n",
      "Average score across all review metrics for property ID 10006546: \u001b[1m9.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 9. Average score across all review metrics for a property\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"_id\": \"10006546\"}},\n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"all_fields\": {\"$objectToArray\": \"$$ROOT\"}\n",
    "    }},\n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$all_fields\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$match\": {\n",
    "        \"all_fields.k\": {\"$regex\": \"^review_scores_\"}\n",
    "    }},\n",
    "    # Project the score values, handling nulls\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Metric\": \"$all_fields.k\",\n",
    "        \"Score\": {\"$ifNull\": [\"$all_fields.v\", 0]}  # Default to 0 if null\n",
    "    }},\n",
    "    \n",
    "    # [{'Metric': 'review_scores_checkin', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_cleanliness', 'Score': 9},\n",
    "    # {'Metric': 'review_scores_communication', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_location', 'Score': 10},\n",
    "    # {'Metric': 'review_scores_rating', 'Score': 8.9},\n",
    "    # {'Metric': 'review_scores_value', 'Score': 9}]\n",
    "        \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Score\"}\n",
    "    }},\n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]},\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "# pprint(result) \n",
    "print(f\"\\nAverage score across all review metrics for property ID 10006546: \\033[1m{result[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The original query assumes all scores have the prefix `review_scores_` and that the range is $0-10$. In the new schema, we don't have this certainty, so we use the **Subdocument/Attribute Pattern**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema** (More Flexible and Automatic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q9: `Attribute Pattern`**\n",
    "\n",
    "We applied the **Attribute Pattern** because **Q9** requires averaging *all* review score metrics ‚Äî including future, yet-to-be-defined ones ‚Äî without modifying the aggregation logic. The original schema stored review scores in separate fields (e.g., `review_scores_checkin`, `review_scores_cleanliness`), making dynamic querying harder and requiring updates whenever new metrics are introduced.\n",
    "\n",
    "We expect flexibility and maintainability based on the following:\n",
    "\n",
    "- We restructured the schema into a single subdocument called `Review_Scores`, where each metric (e.g., **Checkin**, **Cleanliness**, **Value**) is a key and its score is the value.\n",
    "- We use `$objectToArray` in the aggregation pipeline, which transforms the `Review_Scores` subdocument into an iterable array of key-value pairs. We can then compute the average over all values dynamically (`$avg: \"$Scores.v\"`), regardless of metric names.\n",
    "- This change means that adding new review score types (e.g., `XFactor` from **Q14**) requires no schema or query modification ‚Äî they are automatically included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0041 seconds\n",
      "\n",
      "Average score for property ID 10006546: \u001b[1m9.48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pipeline_query9 =[\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"Listing_ID\": \"10006546\"}},\n",
    "    \n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Scores\": {\"$objectToArray\": \"$Review_Scores\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$Scores\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Scores.v\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\"AvgScore\": {\"$round\": [\"$AvgScore\", 2]}}}\n",
    "]\n",
    "query9 = list(db.Listings.aggregate(pipeline_query9))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage score for property ID 10006546: \\033[1m{query9[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance:\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Listings',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\\\\\xc4\\xfd\\x95f\\x00Oa\\xa5\\r\\xd3\\xb8\\xf9\\x06o\\xd0', 4)},\n",
      "             'pipeline': [{'$match': {'Listing_ID': '10006546'}},\n",
      "                          {'$project': {'Scores': {'$objectToArray': '$Review_Scores'},\n",
      "                                        '_id': 0}},\n",
      "                          {'$unwind': '$Scores'},\n",
      "                          {'$group': {'AvgScore': {'$avg': '$Scores.v'},\n",
      "                                      '_id': None}},\n",
      "                          {'$project': {'AvgScore': {'$round': ['$AvgScore',\n",
      "                                                                2]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '4C8AAFB3005E1E3D4880B227EB45D8AC279DCE9C5AC3C628B30E36683BB5BDA8',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Listings',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {'Listing_ID': {'$eq': '10006546'}},\n",
      "                                          'planCacheKey': '0EE1C956',\n",
      "                                          'planCacheShapeHash': '4514207D',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': '4514207D',\n",
      "                                          'rejectedPlans': [],\n",
      "                                          'winningPlan': {'inputStage': {'inputStage': {'direction': 'forward',\n",
      "                                                                                        'indexBounds': {'Listing_ID': ['[\"10006546\", '\n",
      "                                                                                                                       '\"10006546\"]']},\n",
      "                                                                                        'indexName': 'Listing_ID_1',\n",
      "                                                                                        'indexVersion': 2,\n",
      "                                                                                        'isMultiKey': False,\n",
      "                                                                                        'isPartial': False,\n",
      "                                                                                        'isSparse': False,\n",
      "                                                                                        'isUnique': False,\n",
      "                                                                                        'keyPattern': {'Listing_ID': 1},\n",
      "                                                                                        'multiKeyPaths': {'Listing_ID': []},\n",
      "                                                                                        'stage': 'IXSCAN'},\n",
      "                                                                         'stage': 'FETCH'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_DEFAULT',\n",
      "                                                          'transformBy': {'Scores': {'$objectToArray': ['$Review_Scores']},\n",
      "                                                                          '_id': False}}}}},\n",
      "            {'$unwind': {'path': '$Scores'}},\n",
      "            {'$group': {'AvgScore': {'$avg': '$Scores.v'},\n",
      "                        '_id': {'$const': None}}},\n",
      "            {'$project': {'AvgScore': {'$round': ['$AvgScore', {'$const': 2}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q9)\n",
    "print(\"\\n\\033[1mQuery performance:\\033[0m\")\n",
    "pprint(db.command(\"aggregate\", \"Listings\", pipeline=pipeline_query9, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q9):** The new schema query using the **Attribute Pattern** (`$objectToArray` on the `Review_Scores` subdocument) is more flexible than the original query relying on `$regex`. Performance is excellent in both cases (0.007s original vs 0.004s new) because the query targets a single document using the indexed `_id` (or `Listing_ID`). The primary benefit here is the schema's adaptability to new review metrics without requiring query modification, as demonstrated in **Q14**. The `explain()` output confirms the query efficiently uses the `Listing_ID_1` index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the new schema, we assume all scores are stored in the `Review_Scores` subdocument. To optimize the query, we can apply the **Computed Pattern** and store the average score as an attribute within the `Listings` document, providing a summary of scores. This avoids recalculating the average each time we need the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Computed Pattern** (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 5555, 'nModified': 5555, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computed Pattern - Listings.Review_Scores_Avg\n",
    "# Create a new field in the Listings collection to store the average review score\n",
    "db.Listings.update_many({}, [\n",
    "    {\"$set\": {\n",
    "        \"Review_Scores_Avg\": {\n",
    "            \"$avg\": [\n",
    "                \"$Review_Scores.Checkin\",\n",
    "                \"$Review_Scores.Cleanliness\",\n",
    "                \"$Review_Scores.Communication\",\n",
    "                \"$Review_Scores.Location\",\n",
    "                \"$Review_Scores.Rating\",\n",
    "                \"$Review_Scores.Value\"\n",
    "            ]\n",
    "        }\n",
    "    }}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0027 seconds\n",
      "\n",
      "Average review score for property ID 10006546: \u001b[1m9.48\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Query the average review score for a specific property\n",
    "start_time = time.time()\n",
    "property_id = \"10006546\"\n",
    "property_avg_score = db.Listings.find_one({\"Listing_ID\": property_id}, {\"Review_Scores_Avg\": 1})\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage review score for property ID {property_id}: \\033[1m{round(property_avg_score['Review_Scores_Avg'], 2)}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Computed Pattern (Q9 - Optional):** As shown here, if retrieving the average score is a very frequent operation, we can apply the **Computed Pattern**. We calculate the average *once* (or periodically) and store it directly in the `Listings` document (e.g., as `Review_Scores_Avg`). Subsequent reads for the average become simple, fast `find()` operations (0.0027s). The trade-off is the need to update this computed field whenever the underlying scores change (e.g., when **Q14** adds 'XFactor')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10)\tWe aim to have better access to information about transaction, \n",
    "#       we wish to develop a search engine that can calculate the average value of transactions in a given period of time quickly for a given property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test Matches - Remove the date filter temporarily to see if any transactions exist\n",
    "# pipeline = [\n",
    "#     {\"$match\": {\"_id\": \"10006546\"}},\n",
    "#     {\"$unwind\": \"$transactions.transactions\"},\n",
    "#     {\"$limit\": 5}\n",
    "# ]\n",
    "# pprint(list(db.listingsAndReviews_HW2.aggregate(pipeline))) # Existes transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0052 seconds\n",
      "\n",
      "Average transaction value for property ID 10006546 between 2008-01-01 and 2009-01-01: \u001b[1m132.11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 10. Average transaction value for a property in a date range\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    {\"$match\": {\"_id\": \"10006546\"}},                                            # Match the specific property ID\n",
    "    {\"$unwind\": \"$transactions.transactions\"},                                  # Unwind transactions\n",
    "    \n",
    "    # Convert date strings to ISODate and filter\n",
    "    {\"$match\": {\n",
    "        \"transactions.transactions.date\": {\n",
    "            \"$gte\": datetime.strptime(\"2008-01-01\", \"%Y-%m-%d\"),\n",
    "            \"$lte\": datetime.strptime(\"2009-01-01\", \"%Y-%m-%d\")\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$transactions.transactions.price\"}}  # Convert price to number\n",
    "    }},\n",
    "    {\"$project\": {\"_id\": 0, \"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "# pprint(result)\n",
    "print(f\"\\nAverage transaction value for property ID 10006546 between 2008-01-01 and 2009-01-01: \\033[1m{result[0]['AvgValue']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q10):**\n",
    ">\n",
    "> We applied the **Referencing** by creating a separate `Transactions` collection. This addresses the inefficiency of querying the large, embedded `transactions.transactions` array present in the original schema, particularly for time-window calculations like those required by **Q10**, and improves overall scalability.\n",
    ">\n",
    "> The refactoring involved:\n",
    "> 1.  Moving individual transaction records (containing `Transaction_Date` and `Transaction_Price`) into the new `Transactions` collection. Each transaction document now references the corresponding `Listing_ID`.\n",
    "> 2.  **Retaining** the summary bucket information (`bucket_end_date`, `bucket_start_date`) and the **Computed Pattern** field - `transaction_count` - within the main `Listings` document (nested under a `Transactions` key, but without the detailed array). This provides readily accessible summary data directly with the listing, avoiding the need to query the full `Transactions` collection for simple counts or date ranges.\n",
    ">\n",
    "> We created indexes on `Listing_ID` and `Transaction_Date` in the `Transactions` collection to optimize lookups and range scans. We expect **significantly improved performance for time-based queries on transactions** (like **Q10**), **better scalability** as transaction volume grows independently, and **lighter `Listings` documents** for faster general retrieval, while still keeping essential transaction summary information easily accessible. The `explain()` output confirmed the efficient use of the `Listing_ID` index for the example query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0199 seconds\n",
      "\n",
      "Average transaction value for property ID 10006546 (2008-01-01 to 2009-01-01): \u001b[1m132.11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Re-run the query with the Transactions collection\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline_query10 = [\n",
    "    {\"$match\": {\n",
    "        \"Listing_ID\": \"10006546\",\n",
    "        \"Transaction_Date\": {\n",
    "            \"$gte\": datetime.strptime(\"2008-01-01\", \"%Y-%m-%d\"),\n",
    "            \"$lte\": datetime.strptime(\"2009-01-01\", \"%Y-%m-%d\")\n",
    "        }\n",
    "    }},\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$Transaction_Price\"}}\n",
    "    }},\n",
    "    {\"$project\": {\"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "]\n",
    "query10 = list(db.Transactions.aggregate(pipeline_query10))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage transaction value for property ID 10006546 (2008-01-01 to 2009-01-01): \\033[1m{query10[0]['AvgValue']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Applying Indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transaction_Price_-1_Listing_ID_1'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create index on Transactions collection for faster queries\n",
    "db.Transactions.create_index([(\"Transaction_Date\", -1)])                  # Create index on Transaction_Date for descending order \n",
    "                                                                          # (We consider that is more probable to search for the most recent transactions)\n",
    "\n",
    "db.Transactions.create_index([(\"Transaction_Price\", -1), (\"Listing_ID\")]) # Compound index on Transaction_Price and Listing_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance (Q10):\u001b[0m\n",
      "Execution time: 0.0072 seconds\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Transactions',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\\\\\xc4\\xfd\\x95f\\x00Oa\\xa5\\r\\xd3\\xb8\\xf9\\x06o\\xd0', 4)},\n",
      "             'pipeline': [{'$match': {'Listing_ID': '10006546',\n",
      "                                      'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0),\n",
      "                                                           '$lte': datetime.datetime(2009, 1, 1, 0, 0)}}},\n",
      "                          {'$group': {'AvgValue': {'$avg': {'$toDouble': '$Transaction_Price'}},\n",
      "                                      '_id': None}},\n",
      "                          {'$project': {'AvgValue': {'$round': ['$AvgValue',\n",
      "                                                                2]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '2BABB25349C33946E7AB2188B88FECE4C687C7EB6DF5F10656B778028DFCC73E',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Transactions',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {'$and': [{'Listing_ID': {'$eq': '10006546'}},\n",
      "                                                                   {'Transaction_Date': {'$lte': datetime.datetime(2009, 1, 1, 0, 0)}},\n",
      "                                                                   {'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0)}}]},\n",
      "                                          'planCacheKey': '5F8D3F91',\n",
      "                                          'planCacheShapeHash': 'F6D749DD',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': 'F6D749DD',\n",
      "                                          'rejectedPlans': [{'inputStage': {'filter': {'Listing_ID': {'$eq': '10006546'}},\n",
      "                                                                            'inputStage': {'direction': 'forward',\n",
      "                                                                                           'indexBounds': {'Transaction_Date': ['[new '\n",
      "                                                                                                                                'Date(1230768000000), '\n",
      "                                                                                                                                'new '\n",
      "                                                                                                                                'Date(1199145600000)]']},\n",
      "                                                                                           'indexName': 'Transaction_Date_-1',\n",
      "                                                                                           'indexVersion': 2,\n",
      "                                                                                           'isMultiKey': False,\n",
      "                                                                                           'isPartial': False,\n",
      "                                                                                           'isSparse': False,\n",
      "                                                                                           'isUnique': False,\n",
      "                                                                                           'keyPattern': {'Transaction_Date': -1},\n",
      "                                                                                           'multiKeyPaths': {'Transaction_Date': []},\n",
      "                                                                                           'stage': 'IXSCAN'},\n",
      "                                                                            'stage': 'FETCH'},\n",
      "                                                             'isCached': False,\n",
      "                                                             'stage': 'PROJECTION_SIMPLE',\n",
      "                                                             'transformBy': {'Transaction_Price': 1,\n",
      "                                                                             '_id': 0}}],\n",
      "                                          'winningPlan': {'inputStage': {'filter': {'$and': [{'Transaction_Date': {'$lte': datetime.datetime(2009, 1, 1, 0, 0)}},\n",
      "                                                                                             {'Transaction_Date': {'$gte': datetime.datetime(2008, 1, 1, 0, 0)}}]},\n",
      "                                                                         'inputStage': {'direction': 'forward',\n",
      "                                                                                        'indexBounds': {'Listing_ID': ['[\"10006546\", '\n",
      "                                                                                                                       '\"10006546\"]']},\n",
      "                                                                                        'indexName': 'Listing_ID_1',\n",
      "                                                                                        'indexVersion': 2,\n",
      "                                                                                        'isMultiKey': False,\n",
      "                                                                                        'isPartial': False,\n",
      "                                                                                        'isSparse': False,\n",
      "                                                                                        'isUnique': False,\n",
      "                                                                                        'keyPattern': {'Listing_ID': 1},\n",
      "                                                                                        'multiKeyPaths': {'Listing_ID': []},\n",
      "                                                                                        'stage': 'IXSCAN'},\n",
      "                                                                         'stage': 'FETCH'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_SIMPLE',\n",
      "                                                          'transformBy': {'Transaction_Price': 1,\n",
      "                                                                          '_id': 0}}}}},\n",
      "            {'$group': {'AvgValue': {'$avg': {'$convert': {'input': '$Transaction_Price',\n",
      "                                                           'to': {'$const': 'double'}}}},\n",
      "                        '_id': {'$const': None}}},\n",
      "            {'$project': {'AvgValue': {'$round': ['$AvgValue', {'$const': 2}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q10)\n",
    "print(\"\\n\\033[1mQuery performance (Q10):\\033[0m\")\n",
    "start_time = time.time()\n",
    "query10 = list(db.Transactions.aggregate(pipeline_query10))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "pprint(db.command('aggregate', 'Transactions', pipeline=pipeline_query10, explain=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]},\n",
       " 'Listing_ID_1': {'v': 2, 'key': [('Listing_ID', 1)]},\n",
       " 'Transaction_Date_-1': {'v': 2, 'key': [('Transaction_Date', -1)]},\n",
       " 'Transaction_Price_-1_Listing_ID_1': {'v': 2,\n",
       "  'key': [('Transaction_Price', -1), ('Listing_ID', 1)]}}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Transactions.index_information()  # Check indexes on Transactions collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id_': {'v': 2, 'key': [('_id', 1)]},\n",
       " 'Listing_ID_1': {'v': 2, 'key': [('Listing_ID', 1)]},\n",
       " 'Host_ID_1': {'v': 2, 'key': [('Host_ID', 1)]},\n",
       " 'Address.market_1': {'v': 2, 'key': [('Address.market', 1)]},\n",
       " 'Amenities_1': {'v': 2, 'key': [('Amenities', 1)]}}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.Listings.index_information()     # Check indexes on Listings collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q10):** Separating transactions into their own collection allows the new query to operate much more efficiently, especially for time-range filters. The original query on the embedded array took ~0.005s for a single document, while the new query on the `Transactions` collection takes ~0.020s initially but benefits from indexing (`Listing_ID_1`, `Transaction_Date_-1`) for potentially much larger datasets or date ranges. The `explain()` output confirms the query efficiently uses the `Listing_ID_1` index (**IXSCAN** stage) .  The rejected plan shows the query planner correctly *avoided* using the `Transaction_Date` index first, as filtering by `Listing_ID` is likely more selective.\n",
    "\n",
    "The compound index `Transaction_Price_-1_Listing_ID_1` was not used by the winning plan for this specific query (as sorting/filtering wasn't primarily on price), justifying its removal to save storage and reduce write overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Transaction_Price_-1_Listing_ID_1' index\n",
    "db.Transactions.drop_index('Transaction_Price_-1_Listing_ID_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mAverage transaction value for property ID 10006546 from 2008-01-01 to 2009-01-01:\u001b[0m 132.11 | \u001b[1mTime:\u001b[0m 0.0035 seconds\n"
     ]
    }
   ],
   "source": [
    "# EXTRA: Function to get the average transaction value for a property in a date range\n",
    "def get_average_transaction_value(property_id, start_date, end_date):\n",
    "    \"\"\"Get the average transaction value for a property in a date range.\n",
    "\n",
    "    Args:\n",
    "        property_id (str): The ID of the property.\n",
    "        start_date (str): The start date in YYYY-MM-DD format.\n",
    "        end_date (str): The end date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average transaction value and the execution time.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    pipeline = [\n",
    "        {\"$match\": {\"_id\": property_id}},\n",
    "        {\"$unwind\": \"$transactions.transactions\"},\n",
    "        {\"$match\": {\n",
    "            \"transactions.transactions.date\": {\n",
    "                \"$gte\": datetime.strptime(start_date, \"%Y-%m-%d\"),\n",
    "                \"$lte\": datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "            }\n",
    "        }},\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"AvgValue\": {\"$avg\": {\"$toDouble\": \"$transactions.transactions.price\"}}\n",
    "        }},\n",
    "        {\"$project\": {\"_id\": 0, \"AvgValue\": {\"$round\": [\"$AvgValue\", 2]}}}\n",
    "    ]\n",
    "    result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "    exec_time = time.time() - start_time\n",
    "    return result[0][\"AvgValue\"] if result else 0, exec_time\n",
    "\n",
    "# Test the function\n",
    "property_id = \"10006546\"\n",
    "start_date = \"2008-01-01\"\n",
    "end_date = \"2009-01-01\"\n",
    "avg_value, exec_time = get_average_transaction_value(property_id=property_id, start_date=start_date, end_date=end_date)\n",
    "print(f\"\\n\\033[1mAverage transaction value for property ID {property_id} from {start_date} to {end_date}:\\033[0m {avg_value} | \\033[1mTime:\\033[0m {exec_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11)\tWe wish to have a summary webpage that displays information about our top destinations. \n",
    "#       This webpage should display for each of the top 10 cities some basic information about our operations in the area \n",
    "#           (number of properties by type for example, average price by type) but you can choose the metrics. \n",
    "#       For each of the top 10 cities it should also provide some basic information about the top 3 properties in each city \n",
    "#           (price, number of review, whatever you think useful) to show an example of the properties available in the area. \n",
    "#       We would like to keep this webpage up to date as information changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.2345 seconds\n",
      "\n",
      "\u001b[1mTop 10 cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "\u001b[1mCity\u001b[0m              | \u001b[1mProperty Count\u001b[0m | \u001b[1mAvg Price\u001b[0m | \u001b[1mTop 3 Properties\u001b[0m\n",
      "================================================================================\n",
      "Istanbul          | 660            | 367.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 3237666  | \u001b[1mPrice:\u001b[0m 148.0 | \u001b[1mReview Count:\u001b[0m 248\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 555588   | \u001b[1mPrice:\u001b[0m 243.0 | \u001b[1mReview Count:\u001b[0m 246\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1215226  | \u001b[1mPrice:\u001b[0m 322.0 | \u001b[1mReview Count:\u001b[0m 193\n",
      "--------------------------------------------------------------------------------\n",
      "Montreal          | 648            | 100.23    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16389574 | \u001b[1mPrice:\u001b[0m 70.0  | \u001b[1mReview Count:\u001b[0m 261\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4451485  | \u001b[1mPrice:\u001b[0m 83.0  | \u001b[1mReview Count:\u001b[0m 255\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16845784 | \u001b[1mPrice:\u001b[0m 50.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "Barcelona         | 632            | 100.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 95560    | \u001b[1mPrice:\u001b[0m 15.0  | \u001b[1mReview Count:\u001b[0m 463\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1482060  | \u001b[1mPrice:\u001b[0m 130.0 | \u001b[1mReview Count:\u001b[0m 397\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1332929  | \u001b[1mPrice:\u001b[0m 63.0  | \u001b[1mReview Count:\u001b[0m 320\n",
      "--------------------------------------------------------------------------------\n",
      "Hong Kong         | 619            | 762.48    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16493868 | \u001b[1mPrice:\u001b[0m 361.0 | \u001b[1mReview Count:\u001b[0m 348\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 11778475 | \u001b[1mPrice:\u001b[0m 502.0 | \u001b[1mReview Count:\u001b[0m 269\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4755673  | \u001b[1mPrice:\u001b[0m 1319.0 | \u001b[1mReview Count:\u001b[0m 223\n",
      "--------------------------------------------------------------------------------\n",
      "Sydney            | 609            | 197.71    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 12954762 | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 469\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 652063   | \u001b[1mPrice:\u001b[0m 43.0  | \u001b[1mReview Count:\u001b[0m 312\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7132426  | \u001b[1mPrice:\u001b[0m 139.0 | \u001b[1mReview Count:\u001b[0m 259\n",
      "--------------------------------------------------------------------------------\n",
      "New York          | 607            | 139.63    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 476983   | \u001b[1mPrice:\u001b[0m 85.0  | \u001b[1mReview Count:\u001b[0m 420\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 18173787 | \u001b[1mPrice:\u001b[0m 48.0  | \u001b[1mReview Count:\u001b[0m 379\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 858695   | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 262\n",
      "--------------------------------------------------------------------------------\n",
      "Rio De Janeiro    | 603            | 525.81    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 846689   | \u001b[1mPrice:\u001b[0m 157.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1304552  | \u001b[1mPrice:\u001b[0m 168.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 880678   | \u001b[1mPrice:\u001b[0m 190.0 | \u001b[1mReview Count:\u001b[0m 149\n",
      "--------------------------------------------------------------------------------\n",
      "Porto             | 554            | 69.13     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 5283892  | \u001b[1mPrice:\u001b[0m 29.0  | \u001b[1mReview Count:\u001b[0m 408\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2758817  | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 402\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1284759  | \u001b[1mPrice:\u001b[0m 53.0  | \u001b[1mReview Count:\u001b[0m 399\n",
      "--------------------------------------------------------------------------------\n",
      "Oahu              | 253            | 212.3     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4069429  | \u001b[1mPrice:\u001b[0m 124.0 | \u001b[1mReview Count:\u001b[0m 533\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7536867  | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 308\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 210968   | \u001b[1mPrice:\u001b[0m 169.0 | \u001b[1mReview Count:\u001b[0m 289\n",
      "--------------------------------------------------------------------------------\n",
      "Maui              | 153            | 286.59    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1796816  | \u001b[1mPrice:\u001b[0m 175.0 | \u001b[1mReview Count:\u001b[0m 257\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1613843  | \u001b[1mPrice:\u001b[0m 95.0  | \u001b[1mReview Count:\u001b[0m 192\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2279098  | \u001b[1mPrice:\u001b[0m 86.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[1mTop 10 cities:\u001b[0m Istanbul, Montreal, Barcelona, Hong Kong, Sydney, New York, Rio De Janeiro, Porto, Oahu, Maui\n"
     ]
    }
   ],
   "source": [
    "# 11. Top 10 cities with property stats and top 3 properties\n",
    "start_time = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": \"$price\"},\n",
    "        \"Properties\": {\"$push\": {\"Id\": \"$_id\", \"Price\": \"$price\", \"ReviewCount\": \"$number_of_reviews\"}}\n",
    "    }},\n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    # Add top 3 properties per city\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "# pprint(result)\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\n\\033[1mTop 10 cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "print(f\"{'\\033[1mCity\\033[0m':<25} | {'\\033[1mProperty Count\\033[0m':<15} | {'\\033[1mAvg Price\\033[0m':<10} | \\033[1mTop 3 Properties\\033[0m\")\n",
    "print(\"=\" * 80)\n",
    "for city in result:\n",
    "    print(f\"{city['City']:<17} | {city['PropertyCount']:<14} | {float(str(city['AvgPrice'])):<9} |\")\n",
    "    for prop in city[\"TopProperties\"]:\n",
    "        print(f\"                                                 - \\033[1mProperty ID:\\033[0m {prop['Id']:<8} | \\033[1mPrice:\\033[0m {float(str(prop['Price'])):<5} | \\033[1mReview Count:\\033[0m {prop['ReviewCount']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "top_cities = [city[\"City\"] for city in result]\n",
    "print(f\"\\n\\033[1mTop 10 cities:\\033[0m {', '.join(top_cities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0804 seconds\n",
      "\n",
      "\u001b[1mTop 10 cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "\u001b[1mCity\u001b[0m              | \u001b[1mProperty Count\u001b[0m | \u001b[1mAvg Price\u001b[0m | \u001b[1mTop 3 Properties\u001b[0m\n",
      "================================================================================\n",
      "Istanbul          | 660            | 367.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 3237666  | \u001b[1mPrice:\u001b[0m 148.0 | \u001b[1mReview Count:\u001b[0m 248\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 555588   | \u001b[1mPrice:\u001b[0m 243.0 | \u001b[1mReview Count:\u001b[0m 246\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1215226  | \u001b[1mPrice:\u001b[0m 322.0 | \u001b[1mReview Count:\u001b[0m 193\n",
      "--------------------------------------------------------------------------------\n",
      "Montreal          | 648            | 100.23    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16389574 | \u001b[1mPrice:\u001b[0m 70.0  | \u001b[1mReview Count:\u001b[0m 261\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4451485  | \u001b[1mPrice:\u001b[0m 83.0  | \u001b[1mReview Count:\u001b[0m 255\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16845784 | \u001b[1mPrice:\u001b[0m 50.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n",
      "Barcelona         | 632            | 100.95    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 95560    | \u001b[1mPrice:\u001b[0m 15.0  | \u001b[1mReview Count:\u001b[0m 463\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1482060  | \u001b[1mPrice:\u001b[0m 130.0 | \u001b[1mReview Count:\u001b[0m 397\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1332929  | \u001b[1mPrice:\u001b[0m 63.0  | \u001b[1mReview Count:\u001b[0m 320\n",
      "--------------------------------------------------------------------------------\n",
      "Hong Kong         | 619            | 762.48    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 16493868 | \u001b[1mPrice:\u001b[0m 361.0 | \u001b[1mReview Count:\u001b[0m 348\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 11778475 | \u001b[1mPrice:\u001b[0m 502.0 | \u001b[1mReview Count:\u001b[0m 269\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4755673  | \u001b[1mPrice:\u001b[0m 1319.0 | \u001b[1mReview Count:\u001b[0m 223\n",
      "--------------------------------------------------------------------------------\n",
      "Sydney            | 609            | 197.71    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 12954762 | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 469\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 652063   | \u001b[1mPrice:\u001b[0m 43.0  | \u001b[1mReview Count:\u001b[0m 312\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7132426  | \u001b[1mPrice:\u001b[0m 139.0 | \u001b[1mReview Count:\u001b[0m 259\n",
      "--------------------------------------------------------------------------------\n",
      "New York          | 607            | 139.63    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 476983   | \u001b[1mPrice:\u001b[0m 85.0  | \u001b[1mReview Count:\u001b[0m 420\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 18173787 | \u001b[1mPrice:\u001b[0m 48.0  | \u001b[1mReview Count:\u001b[0m 379\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 858695   | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 262\n",
      "--------------------------------------------------------------------------------\n",
      "Rio De Janeiro    | 603            | 525.81    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 846689   | \u001b[1mPrice:\u001b[0m 157.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1304552  | \u001b[1mPrice:\u001b[0m 168.0 | \u001b[1mReview Count:\u001b[0m 227\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 880678   | \u001b[1mPrice:\u001b[0m 190.0 | \u001b[1mReview Count:\u001b[0m 149\n",
      "--------------------------------------------------------------------------------\n",
      "Porto             | 554            | 69.13     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 5283892  | \u001b[1mPrice:\u001b[0m 29.0  | \u001b[1mReview Count:\u001b[0m 408\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2758817  | \u001b[1mPrice:\u001b[0m 30.0  | \u001b[1mReview Count:\u001b[0m 402\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1284759  | \u001b[1mPrice:\u001b[0m 53.0  | \u001b[1mReview Count:\u001b[0m 399\n",
      "--------------------------------------------------------------------------------\n",
      "Oahu              | 253            | 212.3     |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 4069429  | \u001b[1mPrice:\u001b[0m 124.0 | \u001b[1mReview Count:\u001b[0m 533\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 7536867  | \u001b[1mPrice:\u001b[0m 60.0  | \u001b[1mReview Count:\u001b[0m 308\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 210968   | \u001b[1mPrice:\u001b[0m 169.0 | \u001b[1mReview Count:\u001b[0m 289\n",
      "--------------------------------------------------------------------------------\n",
      "Maui              | 153            | 286.59    |\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1796816  | \u001b[1mPrice:\u001b[0m 175.0 | \u001b[1mReview Count:\u001b[0m 257\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 1613843  | \u001b[1mPrice:\u001b[0m 95.0  | \u001b[1mReview Count:\u001b[0m 192\n",
      "                                                 - \u001b[1mProperty ID:\u001b[0m 2279098  | \u001b[1mPrice:\u001b[0m 86.0  | \u001b[1mReview Count:\u001b[0m 176\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pipeline_query11 = [\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": {\"$toDouble\": \"$Price\"}},\n",
    "        \"Properties\": {\"$push\": {\"Id\": \"$Listing_ID\", \"Price\": \"$Price\", \"ReviewCount\": \"$Number_of_Reviews\"}}\n",
    "    }},\n",
    "    \n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    \n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        # Add top 3 properties per city\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }}\n",
    "]\n",
    "query11 = list(db.Listings.aggregate(pipeline_query11))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\n\\033[1mTop 10 cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "print(f\"{'\\033[1mCity\\033[0m':<25} | {'\\033[1mProperty Count\\033[0m':<15} | {'\\033[1mAvg Price\\033[0m':<10} | \\033[1mTop 3 Properties\\033[0m\")\n",
    "print(\"=\" * 80)\n",
    "for city in query11:\n",
    "    print(f\"{city['City']:<17} | {city['PropertyCount']:<14} | {float(str(city['AvgPrice'])):<9} |\")\n",
    "    for prop in city[\"TopProperties\"]:\n",
    "        print(f\"                                                 - \\033[1mProperty ID:\\033[0m {prop['Id']:<8} | \\033[1mPrice:\\033[0m {float(str(prop['Price'])):<5} | \\033[1mReview Count:\\033[0m {prop['ReviewCount']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mQuery performance (Q11):\u001b[0m\n",
      "{'command': {'$db': 'sample_airbnb',\n",
      "             'aggregate': 'Listings',\n",
      "             'explain': True,\n",
      "             'lsid': {'id': Binary(b'\\\\\\xc4\\xfd\\x95f\\x00Oa\\xa5\\r\\xd3\\xb8\\xf9\\x06o\\xd0', 4)},\n",
      "             'pipeline': [{'$group': {'AvgPrice': {'$avg': {'$toDouble': '$Price'}},\n",
      "                                      'Properties': {'$push': {'Id': '$Listing_ID',\n",
      "                                                               'Price': '$Price',\n",
      "                                                               'ReviewCount': '$Number_of_Reviews'}},\n",
      "                                      'PropertyCount': {'$sum': 1},\n",
      "                                      '_id': '$Address.market'}},\n",
      "                          {'$sort': {'PropertyCount': -1}},\n",
      "                          {'$limit': 10},\n",
      "                          {'$project': {'AvgPrice': {'$round': ['$AvgPrice',\n",
      "                                                                2]},\n",
      "                                        'City': '$_id',\n",
      "                                        'PropertyCount': 1,\n",
      "                                        'TopProperties': {'$slice': [{'$sortArray': {'input': '$Properties',\n",
      "                                                                                     'sortBy': {'ReviewCount': -1}}},\n",
      "                                                                     3]}}}]},\n",
      " 'explainVersion': '1',\n",
      " 'ok': 1.0,\n",
      " 'queryShapeHash': '3D66AFC40B9C72D7C01ED765CA289359EED8A9CFC8CB6069B65AA0D233F885F1',\n",
      " 'serverInfo': {'gitVersion': '80f21521ad4a3dfd5613f5d649d7058c6d46277f',\n",
      "                'host': '9bea3733dea4',\n",
      "                'port': 27017,\n",
      "                'version': '8.0.6'},\n",
      " 'serverParameters': {'internalDocumentSourceGroupMaxMemoryBytes': 104857600,\n",
      "                      'internalDocumentSourceSetWindowFieldsMaxMemoryBytes': 104857600,\n",
      "                      'internalLookupStageIntermediateDocumentMaxSizeBytes': 104857600,\n",
      "                      'internalQueryFacetBufferSizeBytes': 104857600,\n",
      "                      'internalQueryFacetMaxOutputDocSizeBytes': 104857600,\n",
      "                      'internalQueryFrameworkControl': 'trySbeRestricted',\n",
      "                      'internalQueryMaxAddToSetBytes': 104857600,\n",
      "                      'internalQueryMaxBlockingSortMemoryUsageBytes': 104857600,\n",
      "                      'internalQueryPlannerIgnoreIndexWithCollationForRegex': 1,\n",
      "                      'internalQueryProhibitBlockingMergeOnMongoS': 0},\n",
      " 'stages': [{'$cursor': {'queryPlanner': {'indexFilterSet': False,\n",
      "                                          'maxIndexedAndSolutionsReached': False,\n",
      "                                          'maxIndexedOrSolutionsReached': False,\n",
      "                                          'maxScansToExplodeReached': False,\n",
      "                                          'namespace': 'sample_airbnb.Listings',\n",
      "                                          'optimizationTimeMillis': 0,\n",
      "                                          'parsedQuery': {},\n",
      "                                          'planCacheKey': '1B1F580F',\n",
      "                                          'planCacheShapeHash': '63121E33',\n",
      "                                          'prunedSimilarIndexes': False,\n",
      "                                          'queryHash': '63121E33',\n",
      "                                          'rejectedPlans': [],\n",
      "                                          'winningPlan': {'inputStage': {'direction': 'forward',\n",
      "                                                                         'stage': 'COLLSCAN'},\n",
      "                                                          'isCached': False,\n",
      "                                                          'stage': 'PROJECTION_DEFAULT',\n",
      "                                                          'transformBy': {'Address.market': 1,\n",
      "                                                                          'Listing_ID': 1,\n",
      "                                                                          'Number_of_Reviews': 1,\n",
      "                                                                          'Price': 1,\n",
      "                                                                          '_id': 0}}}}},\n",
      "            {'$group': {'AvgPrice': {'$avg': {'$convert': {'input': '$Price',\n",
      "                                                           'to': {'$const': 'double'}}}},\n",
      "                        'Properties': {'$push': {'Id': '$Listing_ID',\n",
      "                                                 'Price': '$Price',\n",
      "                                                 'ReviewCount': '$Number_of_Reviews'}},\n",
      "                        'PropertyCount': {'$sum': {'$const': 1}},\n",
      "                        '_id': '$Address.market'}},\n",
      "            {'$sort': {'limit': 10, 'sortKey': {'PropertyCount': -1}}},\n",
      "            {'$project': {'AvgPrice': {'$round': ['$AvgPrice', {'$const': 2}]},\n",
      "                          'City': '$_id',\n",
      "                          'PropertyCount': True,\n",
      "                          'TopProperties': {'$slice': [{'$sortArray': {'input': '$Properties',\n",
      "                                                                       'sortBy': {'ReviewCount': -1}}},\n",
      "                                                       {'$const': 3}]},\n",
      "                          '_id': True}}]}\n"
     ]
    }
   ],
   "source": [
    "# Performance of the query (Q11)\n",
    "print(\"\\n\\033[1mQuery performance (Q11):\\033[0m\")\n",
    "pprint(db.command('aggregate', 'Listings', pipeline=pipeline_query11, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `explain()` output for the initial aggregation (before creating `CitySummary`) shows a **COLLSCAN** stage. This is expected and generally unavoidable for this type of query. To determine the top 10 cities by property count and calculate their respective average prices, the aggregation pipeline must process **every document** in the `Listings` collection to group them by city (`Address.market`) and compute the necessary counts and averages. An index on `Address.market`, for instance, wouldn't help select *which* cities make the top 10 without first processing all documents to get the counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimization for Q11: `Computed Pattern`**\n",
    "\n",
    "We create a support collection - **`CitySummary`** - composed by multiple precomputed fields (**Computed Patter**) because **Q11** requires generating a city-level summary containing property counts, average prices, and top listings per city. These statistics depend on expensive aggregations across the full `Listings` collection. Since this summary is likely displayed on a frequently accessed webpage (e.g., homepage or dashboard), recomputing it on every read request would be inefficient and unnecessary (**Fan Out Write**)\n",
    "\n",
    "We expect a substantial performance gain based on:\n",
    "\n",
    "- We used an aggregation pipeline to compute all necessary metrics for the top 10 cities (e.g., count, average price, top-rated listings), and stored the result in a new `CitySummary` collection using `$out`.\n",
    "- Instead of repeating the heavy aggregation for each request, the application now performs a simple `find()` on a lightweight collection with only 10 documents.\n",
    "- The summary data can be refreshed periodically (e.g., daily or when listings change significantly), decoupling read and write performance.\n",
    "\n",
    "Optionally, we could index the `City` field in the `CitySummary` collection to support fast lookups if users frequently request summaries for specific cities. However, this is likely unnecessary if the entire set is usually shown together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0022 seconds\n",
      "\n",
      "\u001b[1mTop 1 Cities with property stats and top 3 properties:\u001b[0m\n",
      "\n",
      "[{'_id': ObjectId('67fea8f8a6298d01ad0e91f3'),\n",
      "  'PropertyCount': 660,\n",
      "  'City': 'Istanbul',\n",
      "  'AvgPrice': 367.95,\n",
      "  'TopProperties': [{'Listing_ID': '3237666',\n",
      "                     'Price': Decimal128('148.00'),\n",
      "                     'ReviewCount': 248},\n",
      "                    {'Listing_ID': '555588',\n",
      "                     'Price': Decimal128('243.00'),\n",
      "                     'ReviewCount': 246},\n",
      "                    {'Listing_ID': '1215226',\n",
      "                     'Price': Decimal128('322.00'),\n",
      "                     'ReviewCount': 193}]}]\n"
     ]
    }
   ],
   "source": [
    "# Create 'CitySummary' collection\n",
    "db.CitySummary.drop()\n",
    "\n",
    "# Create 'CitySummary' collection with top 10 cities and their properties\n",
    "db.Listings.aggregate([\n",
    "    # Group by city\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$Address.market\",\n",
    "        \"PropertyCount\": {\"$sum\": 1},\n",
    "        \"AvgPrice\": {\"$avg\": {\"$toDouble\": \"$Price\"}},\n",
    "        \"Properties\": {\"$push\": {\"Listing_ID\": \"$Listing_ID\", \"Price\": \"$Price\", \"ReviewCount\": \"$Number_of_Reviews\"}}\n",
    "    }},\n",
    "    \n",
    "    # Sort by property count\n",
    "    {\"$sort\": {\"PropertyCount\": -1}},\n",
    "    \n",
    "    # Limit to top 10 cities\n",
    "    {\"$limit\": 10},\n",
    "    \n",
    "    # Project output\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,                                   # Will create a ObjectId for each top city\n",
    "        \"City\": \"$_id\",\n",
    "        \"PropertyCount\": 1,\n",
    "        \"AvgPrice\": {\"$round\": [\"$AvgPrice\", 2]},\n",
    "        \n",
    "        # Add top 3 properties per city\n",
    "        \"TopProperties\": {\"$slice\": [{\"$sortArray\": {\"input\": \"$Properties\", \"sortBy\": {\"ReviewCount\": -1}}}, 3]}\n",
    "    }},\n",
    "    \n",
    "    # Output to 'CitySummary' collection\n",
    "    {\"$out\": \"CitySummary\"}\n",
    "])\n",
    "\n",
    "# Query the 'CitySummary' collection\n",
    "start_time = time.time()\n",
    "city_summary = list(db.CitySummary.find({}))\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "\n",
    "print(f\"\\n\\033[1mTop 1 Cities with property stats and top 3 properties:\\033[0m\\n\")\n",
    "pprint(list(db.CitySummary.find().limit(1)), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Optimization Analysis (Q11):** The original query requires a full aggregation over the main collection (~0.23s). By applying the <strong>Computed Pattern</strong> and storing the results in `CitySummary` (~0.08s to create), subsequent reads for the dashboard become a simple `find()` on 10 documents, which is extremely fast (~0.002s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **üîÑÔ∏è Database updates:** [2 points per question]\n",
    "\n",
    "After optimizing the database, show how to complete the following updates. You can create fictional data. Ensure that previous data does not become stale:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Add a new property with a new host in one of the top 10 cities. \n",
    "#     The host selects the top 10 most common amenities to list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Inserted property: 20000000, Time: 0.0033 seconds'\n"
     ]
    }
   ],
   "source": [
    "# 12. Add new property with top 10 amenities\n",
    "start_time = time.time()\n",
    "\n",
    "# Top 10 amenities from Query 7 (since we don't have 'Amenities' collection in the original data, we will input the top 10 amenities manually)\n",
    "top_amenities = ['Wifi', 'Essentials', 'Kitchen', 'TV', 'Hangers', 'Hair dryer', 'Washer', 'Shampoo', 'Iron', 'Laptop friendly workspace']\n",
    "new_property = {\n",
    "    \"_id\": \"20000000\",\n",
    "    \"name\": \"New York Loft\",\n",
    "    \"host_id\": \"99999999\",\n",
    "    \"host_name\": \"Group 5\",\n",
    "    \"address\": {\"market\": \"New York\"},\n",
    "    \"amenities\": top_amenities,\n",
    "    \"price\": Decimal128(\"100.00\")\n",
    "}\n",
    "db.listingsAndReviews_HW2.insert_one(new_property)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "pprint(f\"Inserted property: 20000000, Time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using the capabilities of a flexible database, we only fill in certain fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '20000000',\n",
      " 'address': {'market': 'New York'},\n",
      " 'amenities': ['Wifi',\n",
      "               'Essentials',\n",
      "               'Kitchen',\n",
      "               'TV',\n",
      "               'Hangers',\n",
      "               'Hair dryer',\n",
      "               'Washer',\n",
      "               'Shampoo',\n",
      "               'Iron',\n",
      "               'Laptop friendly workspace'],\n",
      " 'host_id': '99999999',\n",
      " 'host_name': 'Group 5',\n",
      " 'name': 'New York Loft',\n",
      " 'price': Decimal128('100.00')}\n"
     ]
    }
   ],
   "source": [
    "# 12.1) Query the new property to verify the insertion\n",
    "result = db.listingsAndReviews_HW2.find_one({\"_id\": \"20000000\"})\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Property (Q12)**\n",
    "\n",
    "*   **Process:** With the new schema, adding a property involves two steps:\n",
    "    1.  Inserting the host information into the `Hosts` collection (if the host is new).\n",
    "    2.  Inserting the listing details (including the `Host_ID` reference and embedded `Amenities`) into the `Listings` collection.\n",
    "*   **Benefit:** This maintains normalization. If \"Group 5\" adds more properties later, her core host information isn't duplicated. We use the pre-computed `Amenities` collection to easily fetch common amenities if needed, though here we just list the top 10 manually for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted property and host, Time: 0.0100 seconds\n",
      "\n",
      "{'_id': ObjectId('67fea8f82e55f326b63fac89'),\n",
      " 'Listing_ID': '20000000',\n",
      " 'Name': 'New York Loft',\n",
      " 'Host_ID': '99999999',\n",
      " 'Address': {'market': 'New York'},\n",
      " 'Amenities': ['24-hour check-in',\n",
      "               'Accessible-height bed',\n",
      "               'Accessible-height toilet',\n",
      "               'Air conditioning',\n",
      "               'Air purifier',\n",
      "               'Alfresco shower',\n",
      "               'BBQ grill',\n",
      "               'Baby bath',\n",
      "               'Baby monitor',\n",
      "               'Babysitter recommendations'],\n",
      " 'Price': Decimal128('100.00')}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create new property and host\n",
    "top_amenities = list(db.Amenities.find().sort({\"Amenity\": 1}).limit(10))\n",
    "new_host = {\"Host_ID\": \"99999999\", \"Host_Name\": \"Group 5\"}\n",
    "new_property = {\n",
    "    \"Listing_ID\": \"20000000\",\n",
    "    \"Name\": \"New York Loft\",\n",
    "    \"Host_ID\": \"99999999\",\n",
    "    \"Address\": {\"market\": \"New York\"},\n",
    "    \"Amenities\": [a[\"Amenity\"] for a in top_amenities],\n",
    "    \"Price\": Decimal128(\"100.00\"),\n",
    "}\n",
    "db.Hosts.insert_one(new_host)\n",
    "db.Listings.insert_one(new_property)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"Inserted property and host, Time: {execution_time:.4f} seconds\\n\")\n",
    "\n",
    "# 12.2) Query the new property to verify the insertion\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q12):** As expected, the performance is slightly slower with the new schema (0.010s vs 0.003s original) due to the additional insert into the `Hosts` collection. This is a one-time cost per new listing, and the benefits of normalization outweigh this minor insert overhead.\n",
    "\n",
    "**Note:** Although in our case we have not inserted the **`Review_Scores`** information, if we did we would have to calculate the **`Review_Scores_Avg`** field so that it is always up to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 13**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Add a new review from one of our top 20 reviewers for this new property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '13574006',\n",
      " 'host_name': 'Jos√©',\n",
      " 'reviews': [{'_id': '256178235',\n",
      "              'comments': 'Great stay. The perfect house with the perfect '\n",
      "                          'service. We did a last minute booking and '\n",
      "                          'everything went smooth. Everything was very clean '\n",
      "                          'and the comunication was perfect. The house is '\n",
      "                          'incredibly luxorious and fully equppied. Highly '\n",
      "                          'recommended',\n",
      "              'date': datetime.datetime(2018, 4, 22, 4, 0),\n",
      "              'listing_id': '13574006',\n",
      "              'reviewer_id': '20775242',\n",
      "              'reviewer_name': 'Filipe'}]}\n"
     ]
    }
   ],
   "source": [
    "# 13.1) Get the top reviewer ID from Question 8\n",
    "\n",
    "# {'ReviewCount': 24, 'ReviewerId': '20775242', 'ReviewerName': 'Filipe'}\n",
    "top_reviewer_id = \"20775242\"\n",
    "doc = db.listingsAndReviews_HW2.find_one(\n",
    "    {\"reviews.reviewer_id\": top_reviewer_id},\n",
    "    {\"host_name\": 1, \"reviews.$\": 1}\n",
    ")\n",
    "pprint(doc)\n",
    "\n",
    "# doc[\"reviews\"][0]['comments'] - Reviewer comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added review, Time: 0.0042 seconds\n"
     ]
    }
   ],
   "source": [
    "# 13. Add review from top reviewer\n",
    "start_time = time.time()\n",
    "\n",
    "db.listingsAndReviews_HW2.update_one({\"_id\": \"20000000\"}, {\"$push\": {\"reviews\": doc[\"reviews\"][0]}})\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Added review, Time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Review (Q13)**\n",
    "\n",
    "*   **Process:** Adding a review in the new, normalized schema involves two operations:\n",
    "    1.  Inserting the new review document (containing `Listing_ID`, `Reviewer_ID`, comments, date, etc.) into the `Reviews` collection.\n",
    "    2.  Updating the corresponding reviewer document in the `Reviewers` collection using `update_one` with `$inc` to increment the `ReviewCount` and `upsert=True` to handle the case where the reviewer might not yet exist in the `Reviewers` collection (though less likely if populated from existing reviews).\n",
    "*   **Benefit:** This approach keeps the `Listings` collection lean, ensures reviews are stored centrally, and maintains an accurate, pre-computed review count for each reviewer (leveraging the **Computed Pattern** introduced in Q8). This makes looking up review counts extremely fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('67fea80ea6298d01ad076b92'),\n",
       "  'Reviewer_Name': 'Frank',\n",
       "  'Reviewer_ID': '99803988',\n",
       "  'ReviewCount': 1},\n",
       " {'_id': ObjectId('67fea80ea6298d01ad076b93'),\n",
       "  'Reviewer_Name': 'Noah',\n",
       "  'Reviewer_ID': '34619466',\n",
       "  'ReviewCount': 1},\n",
       " {'_id': ObjectId('67fea80ea6298d01ad076b94'),\n",
       "  'Reviewer_Name': 'Filip',\n",
       "  'Reviewer_ID': '134581781',\n",
       "  'ReviewCount': 1},\n",
       " {'_id': ObjectId('67fea80ea6298d01ad076b95'),\n",
       "  'Reviewer_Name': 'Aaron',\n",
       "  'Reviewer_ID': '72302443',\n",
       "  'ReviewCount': 1},\n",
       " {'_id': ObjectId('67fea80ea6298d01ad076b96'),\n",
       "  'Reviewer_Name': '–ê–Ω–¥—Ä–µ–π',\n",
       "  'Reviewer_ID': '124235566',\n",
       "  'ReviewCount': 1}]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.Reviewers.find().limit(5))  # Display first few reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added review, Time: 0.0271 seconds\n",
      "\n",
      "{'_id': ObjectId('67fea8f92e55f326b63fac8a'),\n",
      " 'Listing_ID': '20000000',\n",
      " 'Review_ID': '99999999',\n",
      " 'Reviewer_ID': '135123163',\n",
      " 'Review_Comments': 'Great loft!',\n",
      " 'Review_Date': datetime.datetime(2025, 4, 15, 19, 44, 9, 63000)}\n",
      "{'_id': ObjectId('67fea80ea6298d01ad077fca'),\n",
      " 'Reviewer_Name': 'ÊÄùÁæΩ',\n",
      " 'Reviewer_ID': '135123163',\n",
      " 'ReviewCount': 2}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Add new review from top reviewer\n",
    "# Use the top reviewer ID from Query 8\n",
    "top_reviewer = query8[0]\n",
    "new_review = {\n",
    "    \"Listing_ID\": \"20000000\",\n",
    "    \"Review_ID\": \"99999999\",\n",
    "    \"Reviewer_ID\": top_reviewer[\"ReviewerId\"],\n",
    "    \"Review_Comments\": \"Great loft!\",\n",
    "    \"Review_Date\": datetime.now()\n",
    "}\n",
    "db.Reviews.insert_one(new_review)\n",
    "\n",
    "# Update the Review_IDs in the Reviewers collection (insert if not exists)\n",
    "# Source: https://www.mongodb.com/docs/manual/reference/operator/update/setOnInsert/\n",
    "db.Reviewers.update_one(\n",
    "    {\"Reviewer_ID\": top_reviewer[\"ReviewerId\"]}, # Filter: Find the reviewer\n",
    "    {\n",
    "        \"$inc\": {\"ReviewCount\": 1}, # Operation: Increment the count by 1\n",
    "        \"$setOnInsert\": {           # Operation: Fields to set ONLY if inserting (upsert)\n",
    "            \"Reviewer_Name\": top_reviewer[\"ReviewerName\"],\n",
    "            # Set Reviewer_ID explicitly on insert for clarity, although filter usually handles it\n",
    "            \"Reviewer_ID\": top_reviewer[\"ReviewerId\"]\n",
    "            }\n",
    "    },\n",
    "    upsert=True                     # Option: Insert the document if it doesn't exist\n",
    ")\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"Added review, Time: {execution_time:.4f} seconds\\n\")\n",
    "\n",
    "# 13.1) Query the new review to verify the insertion\n",
    "pprint(db.Reviews.find_one({\"Review_ID\": \"99999999\"}), sort_dicts=False)\n",
    "pprint(db.Reviewers.find_one({\"Reviewer_ID\": top_reviewer[\"ReviewerId\"]}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q13):** Adding a review in the original schema required a single `update_one` with `$push` (~0.004s). The new schema requires one `insert_one` into `Reviews` and one `update_one` into `Reviewers` (~0.027s total). While involving more operations, it operates on smaller, focused collections and maintains the pre-computed `ReviewCount`, speeding up the common lookup use case from **Q8**. The slight increase in write time is often an acceptable trade-off for improved read performance and scalability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Add a new review metric called 'x_factor' with a score of 10. \n",
    "#     Show that the average score across all metrics is correctly calculated for this listing, using the previously developed query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with Original Data Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.0062 seconds\n",
      "\n",
      "Average score across all review metrics for property ID 20000000: \u001b[1m10.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 14. Add x_factor metric and calculate average\n",
    "start_time = time.time()\n",
    "\n",
    "# Add new metric\n",
    "db.listingsAndReviews_HW2.update_one(\n",
    "    {\"_id\": \"20000000\"},\n",
    "    {\"$set\": {\"review_scores_x_factor\": 10}}\n",
    ")\n",
    "\n",
    "# Query with dynamic review_scores_* fields (from Query 9)\n",
    "pipeline = [\n",
    "    # Match the specific property\n",
    "    {\"$match\": {\"_id\": \"20000000\"}},\n",
    "    \n",
    "    # Convert all document fields to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"all_fields\": {\"$objectToArray\": \"$$ROOT\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$all_fields\"},\n",
    "    \n",
    "    # Filter for fields starting with 'review_scores_'\n",
    "    {\"$match\": {\n",
    "        \"all_fields.k\": {\"$regex\": \"^review_scores_\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the score values, handling nulls\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"Metric\": \"$all_fields.k\",\n",
    "        \"Score\": {\"$ifNull\": [\"$all_fields.v\", 0]}  # Default to 0 if null\n",
    "    }},\n",
    "    \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Score\"}\n",
    "    }},\n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]}\n",
    "    }}\n",
    "]\n",
    "\n",
    "result = list(db.listingsAndReviews_HW2.aggregate(pipeline))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Execution time: {execution_time:.4f} seconds\")\n",
    "print(f\"\\nAverage score across all review metrics for property ID 20000000: \\033[1m{result[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Query with New Schema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Database Update: Adding New Metric & Verifying Average (Q14)**\n",
    "\n",
    "*   **Process:**\n",
    "    1.  Add the new metric 'XFactor' directly to the `Review_Scores` subdocument within the specific `Listings` document using `$set` with dot notation (`Review_Scores.XFactor`).\n",
    "    2.  Re-run the *exact same aggregation pipeline* used in **Q9** (new schema version) to calculate the average score across all metrics.\n",
    "*   **Benefit (Attribute Pattern):** This demonstrates the flexibility of the **Attribute Pattern**. The query pipeline (`$objectToArray` -> `$unwind` -> `$avg`) does not need modification; it automatically includes the new 'XFactor' field in its calculation because it iterates over all key-value pairs within the `Review_Scores` subdocument.\n",
    "*   **Computed Pattern Update:** Because we *optionally* added the `Review_Scores_Avg` pre-computed field to `Listings`, we perform an additional `update_one` to store the *newly calculated* average ($10$) back into that field, ensuring the pre-computed value stays consistent. If the computed field wasn't used, this last update wouldn't be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mReview_Scores for property ID 20000000:\u001b[0m\n",
      "{'_id': ObjectId('67fea8f82e55f326b63fac89')}\n",
      "\n",
      "\u001b[1mUpdated Review_Scores for property ID 20000000:\u001b[0m\n",
      "{'_id': ObjectId('67fea8f82e55f326b63fac89'), 'Review_Scores': {'XFactor': 10}}\n",
      "\n",
      "Execution time: 0.0103 seconds\n",
      "\n",
      "\n",
      "Average score with new metric: \u001b[1m10.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Property ID 20000000 | Review_Scores\n",
    "print(f\"\\n\\033[1mReview_Scores for property ID 20000000:\\033[0m\")\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"},{\"Review_Scores\": 1}), sort_dicts=False)\n",
    "\n",
    "db.Listings.update_one(\n",
    "    {\"Listing_ID\": \"20000000\"},\n",
    "    {\"$set\": {\"Review_Scores.XFactor\": 10}}\n",
    ")\n",
    "\n",
    "# Print the updated document to verify the new metric\n",
    "print(f\"\\n\\033[1mUpdated Review_Scores for property ID 20000000:\\033[0m\")\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"},{\"Review_Scores\": 1}), sort_dicts=False)\n",
    "\n",
    "# Query to calculate average score across all metrics, including new metric\n",
    "query14 = list(db.Listings.aggregate([\n",
    "    # Match the specific property ID (e.g., 20000000)\n",
    "    {\"$match\": {\"Listing_ID\": \"20000000\"}},\n",
    "    \n",
    "    # Select the Review_Scores field and convert it to an array of key-value pairs\n",
    "    {\"$project\": {\n",
    "        \"Scores\": {\"$objectToArray\": \"$Review_Scores\"}\n",
    "    }},\n",
    "    \n",
    "    # Unwind the array to process each field\n",
    "    {\"$unwind\": \"$Scores\"},\n",
    "    \n",
    "    # Group to calculate the average across all metrics\n",
    "    {\"$group\": {\n",
    "        \"_id\": None,\n",
    "        \"AvgScore\": {\"$avg\": \"$Scores.v\"}\n",
    "    }},    \n",
    "    \n",
    "    # Project the final output with rounding\n",
    "    {\"$project\": {\n",
    "        \"_id\": 0,\n",
    "        \"AvgScore\": {\"$round\": [\"$AvgScore\", 1]}\n",
    "    }}\n",
    "]))\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nExecution time: {execution_time:.4f} seconds\\n\")\n",
    "print(f\"\\nAverage score with new metric: \\033[1m{query14[0]['AvgScore']}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult({'n': 1, 'nModified': 1, 'ok': 1.0, 'updatedExisting': True}, acknowledged=True)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the average score in the Listings collection (Computed Pattern)\n",
    "# Since we create a new field in the Listings collection to store the average review score, we need to update every time we add a new metric.\n",
    "db.Listings.update_one(\n",
    "    {\"Listing_ID\": \"20000000\"},\n",
    "    {\"$set\": {\"Review_Scores_Avg\": query14[0]['AvgScore']}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mUpdated average score for property ID 20000000:\u001b[0m\n",
      "{'_id': ObjectId('67fea8f82e55f326b63fac89'), 'Review_Scores_Avg': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Check the updated average score\n",
    "print(f\"\\n\\033[1mUpdated average score for property ID 20000000:\\033[0m\")\n",
    "pprint(db.Listings.find_one({\"Listing_ID\": \"20000000\"},{\"Review_Scores_Avg\": 1}), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comparison (Q14):** Adding the new 'x_factor' metric is a simple `$set` in both schemas (~0.006s original vs ~0.010s new - including average recalculation and update). The original schema required a dynamic query using `$regex` for the average. The new schema's **Attribute Pattern** makes the average calculation inherently flexible (using `$objectToArray`), requiring no query changes for new metrics. Performance for recalculating the average on a single document is fast in both. The key advantage is the new schema's adaptability. Updating the optional pre-computed average adds negligible cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "bdmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.986px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
